{
  "language_name": "Schwiizerdütsch",
  "activations": {
    "not_supported": "Aktivierung nit unterstützt: {activation}. Verfügbari Optione: {available}",
    "created": "Aktivierungsfunktion erfolgrich erstellt: {activation} mit Parameter {params}",
    "creation_failed": "Fehler bim Erstelle vo dr Aktivierungsfunktion: {error}",
    "invalid_params": "Ungültigi Parameter für Aktivierungsfunktion: {error}",
    "config_missing_type": "Typ fählt in Aktivierungskonfiguration",
    "recommendations_removed": "Aktivierungsempfehlunge us em System entfernt"
  },
  "augmentation": {
    "not_supported": "Augmentierung nit unterstützt: {aug}. Verfügbari Optione: {available}",
    "created": "Augmentierung erfolgrich erstellt: {aug} mit Parameter {params}",
    "creation_failed": "Fehler bim Erstelle vo dr Augmentierung: {error}",
    "invalid_params": "Ungültigi Parameter für Augmentierung: {error}",
    "config_missing_type": "Typ fählt in Augmentierungskonfiguration",
    "preview_invalid_phase": "Ungültigi Augmentierungsphas: {phase}",
    "preview_no_images": "Kei Bilder verfügbar für Augmentierungsvorschau im Projekt {project}.",
    "preview_failed": "Fehler bim Generiere vo dr Augmentierungsvorschau: {error}",
    "preview_generated": "Augmentierungsvorschau generiert für Phas {phase}"
  },
  "coordinator_settings": {
    "user_settings_saved": "Benutzerinställige gspeicheret in {path}",
    "user_settings_save_failed": "Fehler bim Speichere vo dr Benutzerinställige: {error}"
  },
  "recommendations": {
    "critical_shortage": "Kritischi Datemangel entdeckt in: {labels}",
    "reduce_oversampled": "Überleg dir, übersamplti Labels z reduziere: {labels}",
    "augment_undersampled": "Überleg dir, untersamplti Labels z augmentiere: {labels}",
    "weighted_loss": "Überleg dir, gwichteti Verlustfunktione z verwende",
    "stratified_sampling": "Überleg dir, stratifizierts Sampling z verwende",
    "hierarchical_imbalance": "Hierarchischi Unbalance entdeckt in: {categories}",
    "small_dataset": "Chleins Dataset entdeckt - überleg dir Data Augmentation",
    "tiny_dataset": "Sehr chleins Dataset - hohes Risiko für Overfitting"
  },
  "losses": {
    "not_supported": "Verlustfunktion nit unterstützt: {loss}. Verfügbari Optione: {available}",
    "created": "Verlustfunktion erfolgrich erstellt: {loss} mit Parameter {params}",
    "creation_failed": "Fehler bim Erstelle vo dr Verlustfunktion: {error}",
    "invalid_params": "Ungültigi Parameter für Verlustfunktion: {error}",
    "config_missing_type": "Typ fählt in Verlustkonfiguration",
    "recommendations_removed": "Verlustempfehlunge us em System entfernt"
  },
  "normalization": {
    "not_supported": "Normalisierung nit unterstützt: {norm}. Verfügbari Optione: {available}",
    "missing_num_features": "Parameter 'num_features' fählt für {norm}",
    "missing_num_channels": "Parameter 'num_channels' fählt für {norm}",
    "missing_normalized_shape": "Parameter 'normalized_shape' fählt für {norm}",
    "created": "Normalisierungsschicht erfolgrich erstellt: {norm} mit Parameter {params}",
    "creation_failed": "Fehler bim Erstelle vo dr Normalisierungsschicht: {error}",
    "invalid_params": "Ungültigi Parameter für Normalisierungsschicht: {error}",
    "config_missing_type": "Typ fählt in Normalisierungskonfiguration",
    "recommendations_removed": "Normalisierungsempfehlunge us em System entfernt"
  },
  "optimizers": {
    "not_supported": "Optimizer nit unterstützt: {optimizer}. Verfügbari Optione: {available}",
    "created": "Optimizer erfolgrich erstellt: {optimizer} mit Parameter {params}",
    "creation_failed": "Fehler bim Erstelle vom Optimizer: {error}",
    "invalid_params": "Ungültigi Parameter für Optimizer: {error}",
    "config_missing_type": "Typ fählt in Optimizerkonfiguration",
    "recommendations_removed": "Optimizerempfehlunge us em System entfernt"
  },
  "pooling": {
    "not_supported": "Pooling-Schicht nit unterstützt: {pool}. Verfügbari Optione: {available}",
    "created": "Pooling-Schicht erfolgrich erstellt: {pool} mit Parameter {params}",
    "creation_failed": "Fehler bim Erstelle vo dr Pooling-Schicht: {error}",
    "invalid_params": "Ungültigi Parameter für Pooling-Schicht: {error}",
    "config_missing_type": "Typ fählt in Poolingkonfiguration",
    "recommendations_removed": "Poolingempfehlunge us em System entfernt"
  },
  "regularization": {
    "not_supported": "Regularisierung nit unterstützt: {reg}. Verfügbari Optione: {available}",
    "created": "Regularisierungsschicht erfolgrich erstellt: {reg} mit Parameter {params}",
    "creation_failed": "Fehler bim Erstelle vo dr Regularisierungsschicht: {error}",
    "invalid_params": "Ungültigi Parameter für Regularisierungsschicht: {error}",
    "config_missing_type": "Typ fählt in Regularisierungskonfiguration",
    "recommendations_removed": "Regularisierungsempfehlunge us em System entfernt"
  },
  "schedulers": {
    "not_supported": "Scheduler nit unterstützt: {scheduler}. Verfügbari Optione: {available}",
    "created": "Scheduler erfolgrich erstellt: {scheduler} mit Parameter {params}",
    "creation_failed": "Fehler bim Erstelle vom Scheduler: {error}",
    "invalid_params": "Ungültigi Parameter für Scheduler: {error}",
    "config_missing_type": "Typ fählt in Schedulerkonfiguration",
    "recommendations_removed": "Schedulerempfehlunge us em System entfernt"
  },
  "weight_init": {
    "not_supported": "Gewichtsinit nit unterstützt: {init}. Verfügbari Optione: {available}",
    "applied": "Gewichtsinit erfolgrich aagwendet: {init} uf {module} mit Parameter {params}",
    "application_failed": "Fehler bim Aawende vo dr Gewichtsinit: {error}",
    "invalid_params": "Ungültigi Parameter für Gewichtsinit: {error}",
    "recommendations_removed": "Gewichtsinit-Empfehlunge us em System entfernt"
  },
  "heatmap": {
    "no_images": "Kei Bilder gfunde für Projekt {project}",
    "checkpoint_missing": "Model-Checkpoint nit gfunde im Verzeichnis: {dir}",
    "project_or_dataset_missing": "Projekt {project} oder sis Dataset nit gfunde",
    "generated": "Heatmap generiert für {project} mit Bild {image} (Klass {clazz})"
  },
  "app": {
    "brand": "Hootsight"
  },
  "nav": {
    "training_group": "Training",
    "projects": "Projekte",
    "dataset": "Dataset",
    "training_setup": "Training-Setup",
    "augmentation": "Augmentierung",
    "status_group": "Status",
    "status": "Status",
    "heatmap": "Heatmap",
    "memory": "Speicher",
    "system_group": "System",
    "updates": "Updates",
    "about": "Über"
  },
  "page": {
    "projects": "Projekte",
    "dataset": "Dataset",
    "training": "Training-Setup",
    "augmentation": "Augmentierung",
    "status": "Status",
    "heatmap": "Heatmap",
    "memory": "Speicher",
    "updates": "Updates",
    "about": "Über"
  },
  "config": {
    "sections": {
      "training": "Training",
      "optimizers": "Optimizer",
      "schedulers": "Scheduler",
      "losses": "Verluste",
      "models": "Modelle"
    },
    "entities": {
      "optimizers": {
        "sgd": "SGD (Stochastic Gradient Descent)",
        "adam": "Adam Optimizer",
        "adamw": "AdamW Optimizer",
        "adamax": "AdaMax",
        "nadam": "Nesterov Adam",
        "radam": "Rectified Adam",
        "rmsprop": "RMSprop",
        "rprop": "Resilient Backpropagation",
        "adagrad": "AdaGrad",
        "adadelta": "AdaDelta",
        "sparse_adam": "Sparse Adam",
        "lbfgs": "L-BFGS",
        "asgd": "Averaged SGD"
      },
      "schedulers": {
        "step_lr": "Step Learning Rate",
        "multi_step_lr": "Multi-Step Learning Rate",
        "exponential_lr": "Exponential Learning Rate",
        "cosine_annealing_lr": "Cosine Annealing",
        "cosine_annealing_warm_restarts": "Cosine Annealing with Warm Restarts",
        "reduce_lr_on_plateau": "Reduce LR on Plateau",
        "cyclic_lr": "Cyclic Learning Rate",
        "one_cycle_lr": "One Cycle Learning Rate",
        "polynomial_lr": "Polynomial Learning Rate",
        "linear_lr": "Linear Learning Rate",
        "lambda_lr": "Lambda Learning Rate",
        "multiplicative_lr": "Multiplicative Learning Rate"
      },
      "losses": {
        "cross_entropy": "Cross Entropy",
        "nll_loss": "Negative Log Likelihood Loss",
        "bce_loss": "Binary Cross Entropy Loss",
        "bce_with_logits": "BCE with Logits",
        "multi_margin": "Multi-Class Margin Loss",
        "multi_label_margin": "Multi-Label Margin Loss",
        "multi_label_soft_margin": "Multi-Label Soft Margin",
        "mse_loss": "Mean Squared Error Loss",
        "l1_loss": "L1 Loss (MAE)",
        "smooth_l1": "Smooth L1",
        "huber_loss": "Huber Loss",
        "kl_div": "KL Divergence",
        "margin_ranking": "Margin Ranking",
        "hinge_embedding": "Hinge Embedding",
        "triplet_margin": "Triplet Margin",
        "cosine_embedding": "Cosine Embedding",
        "ctc_loss": "CTC Loss",
        "poisson_nll": "Poisson NLL",
        "gaussian_nll": "Gaussian NLL"
      }
    }
  },
  "groups": {
    "model_settings": "Modelinställige",
    "task_configuration": "Aufgabekonfiguration",
    "training_parameters": "Trainingsparameter",
    "optimizer_settings": "Optimizerinställige",
    "scheduler_settings": "Schedulerinställige",
    "loss_configuration": "Verlustkonfiguration",
    "data_loading": "Dataladig",
    "normalization": "Normalisierung",
    "checkpointing": "Checkpointing",
    "weight_initialization": "Gewichtsinitialisierung"
  },
  "actions": {
    "save_config": "Konfiguration speichere",
    "export": "Exportiere",
    "save_training_config": "Training-Konfiguration speichere",
    "save_system_settings": "Globali Inställige speichere"
  },
  "footer": {
    "tagline": "Konfiguriert",
    "generated": "",
    "ready": "Bereit"
  },
  "field": {
    "training_model_type": "Modeltyp",
    "training_model_name": "Modelname",
    "training_pretrained": "Vortrainiert",
    "training_task": "Aufgab",
    "training_batch_size": "Batchgrössi",
    "training_epochs": "Epochen",
    "training_learning_rate": "Lernrate",
    "training_weight_decay": "Gewichtsverfall",
    "training_input_size": "Eingabagrössi",
    "training_val_ratio": "Validierungsratio",
    "training_optimizer_type": "Optimizertyp",
    "training_scheduler_type": "Schedulertyp",
    "training_loss_type": "Verlusttyp",
    "training_dataloader": "DataLoader",
    "training_dataloader_num_workers": "Num Arbeiter",
    "training_dataloader_pin_memory": "Speicher pinnig",
    "training_dataloader_persistent_workers": "Persistenti Arbeiter",
    "training_dataloader_prefetch_factor": "Prefetch-Faktor",
    "training_normalize": "Normalisiere",
    "training_normalize_mean": "Mittelwert",
    "training_normalize_std": "Standardabweichung",
    "training_checkpoint": "Checkpoint",
    "training_checkpoint_save_best_only": "Nur bests speichere",
    "training_checkpoint_save_frequency": "Speicherfrequenz",
    "training_checkpoint_max_checkpoints": "Max Checkpoints",
    "training_checkpoint_checkpoint_dir": "Checkpoint-Verzeichnis",
    "training_checkpoint_best_model_filename": "Bests Model Dateiname",
    "training_checkpoint_training_history_filename": "Training-Historie Dateiname",
    "training_weight_init": "Gewicht Init",
    "training_weight_init_type": "Init-Typ",
    "training_weight_init_params": "Init-Parameter",
    "training_optimizer_params_adamw_lr": "Lernrate",
    "training_optimizer_params_adamw_betas": "Betas",
    "training_optimizer_params_adamw_eps": "Eps",
    "training_optimizer_params_adamw_weight_decay": "Gewichtsverfall",
    "training_optimizer_params_adamw_amsgrad": "Amsgrad",
    "training_scheduler_params_step_lr_step_size": "Schrittgrössi",
    "training_scheduler_params_step_lr_gamma": "Gamma",
    "training_scheduler_params_step_lr_last_epoch": "Letschti Epoch",
    "training_loss_params_bce_with_logits_weight": "Gewicht",
    "training_loss_params_bce_with_logits_size_average": "Grössi Durchschnitt",
    "training_loss_params_bce_with_logits_reduce": "Reduziere",
    "training_loss_params_bce_with_logits_reduction": "Reduktion",
    "training_loss_params_bce_with_logits_pos_weight": "Positivgewicht"
  },
  "ui": {
    "generate_heatmap": "Heatmap generiere",
    "no_heatmap_generated": "Nonig Heatmap isch no generiert worde.",
    "no_data_available": "Kei Daten verfügbar.",
    "page_not_implemented": "Siet nit implementiert",
    "error": "Fehler",
    "schema_not_loaded": "Schema no nit glade. Bitte wart...",
    "config_not_loaded": "Config no nit glade. Bitte wart...",
    "augmentation_phase": "Augmentierung {phase}",
    "add": "Hinzufüge",
    "remove": "Entferne",
    "transform": "transformiere",
    "no_project_loaded": "Kei Projekt glade",
    "load_project_first": "Bitte lad zerscht es Projekt us dr Projekte-Tab.",
    "go_to_projects": "Gang zu Projekte",
    "dataset_overview": "Dataset-Übersicht",
    "balance_analysis": "Balance-Analyse",
    "label_distribution": "Labelverteilung (Top 20)",
    "recommendations": "Empfehlunge",
    "failed_to_load_dataset": "Fehler bim Lade vo dr Datasetinformatione.",
    "current_project": "AKTUELLS PROJEKT",
    "load": "Lade",
    "start_training": "Training starte",
    "stop_training": "Training stoppe",
    "stop_training_disabled": "Kei aktivs Training für das Projekt zum stoppe.",
    "training_in_progress": "Training am laufe",
    "memory": "Speicher",
    "loading": "Lade...",
    "training_status": "Trainingstatus",
    "idle": "Inaktiv",
    "prediction": "Vorhersag",
    "predictions": "Vorhersage",
    "no_predictions_above_threshold": "Kei Vorhersage über em Threshold",
    "image": "Bild",
    "checkpoint": "Checkpoint",
    "auto": "auto",
    "value": "Wert",
    "one_number_per_line": "Ei Zahl pro Zeil",
    "empty_object": "Leers Objekt",
    "language_warning": "Sprachwechsel refresht s System",
    "language_select_title": "Sprach uswähle",
    "not_available": "N/V",
    "unknown": "Unbekannt",
    "configuration_empty": "Kei Konfigurationsabschnitt verfügbar",
    "configuration_schema_missing": "Konfigurationsschema no nit glade."
  },
  "augmentation_ui": {
    "page_title": "Data Augmentierung",
    "page_description": "Konfiguriere Bildtransformatione für verbessereti Generalisierung und Robustheit vom Model.",
    "train_title": "Training-Augmente",
    "train_description": "Während em Training aagwendet für meh Vielfalt bim visuelle Aspekt während Labels intakt bliibe.",
    "val_title": "Validierungs-Augmente",
    "val_description": "Während dr Validierung aagwendet für deterministisch Evaluierunge.",
    "toggle_help": "Schalt ei Augmentierung für d Phase ein oder us.",
    "no_options": "Kei Augmentierungsoptione verfügbar.",
    "custom_warning": "D folgende Transformatione werde beibhalte aber chönne do nit bearbeitet werde:",
    "unknown_transform": "Unbekannti Transformation",
    "random_resized_crop": "Zufälligs redimensionierts Crop",
    "random_resized_crop_description": "Cropt und redimensioniert s Bild zufällig uf d Ziilgrössi während Skala- und Seitenverhältnis-Bereiche respektiert werde.",
    "random_horizontal_flip": "Zufälligs horizontal Flip",
    "random_horizontal_flip_description": "Flipt s Bild horizontal mit dr konfigurierten Wahrscheinlichkeit für links-rechts Variatione.",
    "random_vertical_flip": "Zufälligs vertikal Flip",
    "random_vertical_flip_description": "Flipt s Bild vertikal für Perspektivänderunge oben-unten.",
    "random_rotation": "Zufälligi Rotation",
    "random_rotation_description": "Wendet ei zufälligi Rotation innerhalb vom Gradbereich a für Orientierungs-Bias-Reduktion.",
    "color_jitter": "Farbvariation",
    "color_jitter_description": "Variiert zufällig Helligkeit, Kontrast, Sättigung und Farbton für verbessereti Farbrobustheit.",
    "random_grayscale": "Zufälligs Graustufe",
    "random_grayscale_description": "Konvertiert Bilder zu Graustufe mit dr konfigurierten Wahrscheinlichkeit für Luminanz-Erkennung.",
    "random_erasing": "Zufälligs Löschig",
    "random_erasing_description": "Maskiert rechteckigi Regionen zufällig für räumlich Robustheit und Objekt-Vollständigkeits-Raisonierung.",
    "random_perspective": "Zufälligi Perspektiv",
    "random_perspective_description": "Wendet ei zufälligi Perspektivtransformation mit Distorsionsskala und Wahrscheinlichkeit a.",
    "center_crop": "Zentrals Crop",
    "center_crop_description": "Cropt d zentral Region uf d Ziilgrössi für konsistenti Validierungseingabe.",
    "random_resized_crop.size_label": "Ausgabagrössi",
    "random_resized_crop.size_description": "Kantenlängi in Pixel nach em Crop redimensioniert worde isch.",
    "random_resized_crop.scale_min_label": "Minimal Skala",
    "random_resized_crop.scale_min_description": "Untergrenz für relativ Flächenskala zum ursprüngliche Bild (0-1).",
    "random_resized_crop.scale_max_label": "Maximal Skala",
    "random_resized_crop.scale_max_description": "Obergrenz für relativ Flächenskala zum ursprüngliche Bild.",
    "random_resized_crop.ratio_min_label": "Minimal Seitenverhältnis",
    "random_resized_crop.ratio_min_description": "Untergrenz für Seitenverhältnis vor em Redimensioniere.",
    "random_resized_crop.ratio_max_label": "Maximal Seitenverhältnis",
    "random_resized_crop.ratio_max_description": "Obergrenz für Seitenverhältnis vor em Redimensioniere.",
    "random_horizontal_flip.p_label": "Flip-Wahrscheinlichkeit",
    "random_horizontal_flip.p_description": "Wahrscheinlichkeit dass es Bild horizontal gespiegelt wird.",
    "random_vertical_flip.p_label": "Flip-Wahrscheinlichkeit",
    "random_vertical_flip.p_description": "Wahrscheinlichkeit dass es Bild vertikal gflipped wird.",
    "random_rotation.min_label": "Minimal Grad",
    "random_rotation.min_description": "Untergrenz vo dr Rotation in Grad (negativ Werte rotieren im Uhrzeigersinn).",
    "random_rotation.max_label": "Maximal Grad",
    "random_rotation.max_description": "Obergrenz vo dr Rotation in Grad (positiv Werte rotieren gegen Uhrzeigersinn).",
    "color_jitter.brightness_label": "Helligkeitsvariation",
    "color_jitter.brightness_description": "Maximal Helligkeitsänderung zu jedem Kanal hinzugefügt.",
    "color_jitter.contrast_label": "Kontrastvariation",
    "color_jitter.contrast_description": "Maximal Kontrastskalierung uf s Bild aagwendet.",
    "color_jitter.saturation_label": "Sättigungsvariation",
    "color_jitter.saturation_description": "Maximal Sättigungsänderung in HSV-Raum.",
    "color_jitter.hue_label": "Farbtonvariation",
    "color_jitter.hue_description": "Maximal Farbtonänderungsbereich (0-0.5).",
    "random_grayscale.p_label": "Graustufe-Wahrscheinlichkeit",
    "random_grayscale.p_description": "Wahrscheinlichkeit dass es Bild zu Graustufe konvertiert wird.",
    "random_erasing.p_label": "Lösch-Wahrscheinlichkeit",
    "random_erasing.p_description": "Wahrscheinlichkeit dass ei zufälligi Region pro Bild glöscht wird.",
    "random_erasing.scale_min_label": "Minimal Skala",
    "random_erasing.scale_min_description": "Untergrenz für relativ Flächenskala vom glöschten Bereich zum ganze Bild.",
    "random_erasing.scale_max_label": "Maximal Skala",
    "random_erasing.scale_max_description": "Obergrenz für relativ Flächenskala vom glöschten Bereich zum ganze Bild.",
    "random_erasing.ratio_min_label": "Minimal Seitenverhältnis",
    "random_erasing.ratio_min_description": "Untergrenz für Seitenverhältnis vom glöschten Patch.",
    "random_erasing.ratio_max_label": "Maximal Seitenverhältnis",
    "random_erasing.ratio_max_description": "Obergrenz für Seitenverhältnis vom glöschten Patch.",
    "random_erasing.value_label": "Füllwert",
    "random_erasing.value_description": "Pixelwert zum Fülle vo dr glöschten Region (0-1).",
    "random_erasing.inplace_label": "In Place",
    "random_erasing.inplace_description": "Löschig direkt uf em Eingabetensor aawende ohni ei Kopie z erstelle.",
    "random_perspective.distortion_scale_label": "Distorsionsskala",
    "random_perspective.distortion_scale_description": "Kontrolliert d Stärchi vo dr Perspektivdistorsion (0-1).",
    "random_perspective.p_label": "Perspektiv-Wahrscheinlichkeit",
    "random_perspective.p_description": "Wahrscheinlichkeit dass ei zufälligi Perspektivdeformation aagwendet wird.",
    "center_crop.size_label": "Crop-Grössi",
    "center_crop.size_description": "Ziil-Kantenlängi in Pixel für s zentral Crop.",
    "preview_section_title": "Vorschau",
    "preview_description": "Wendet d aktuell Pipeline uf es zufälligs Bild us em Dataset a.",
    "preview_button": "Vorschau zeige",
    "preview_idle": "Klick uf Vorschau zeige für s augmentiert Bild.",
    "preview_loading": "Vorschau generiere...",
    "preview_no_project": "Lad es Projekt für Augmentierungsvorschau.",
    "preview_empty_pipeline": "Konfiguriere zmindisch ei Transformation für Vorschau.",
    "preview_generic_error": "Fehler bim Generiere vo dr Vorschau.",
    "preview_original_label": "Original",
    "preview_augmented_label": "Augmentiert",
    "preview_image_path_label": "Bildpfad"
  },
  "about_ui": {
    "page_title": "Über Hootsight",
    "page_description": "Versteh d Zweck, zentral Architektur und Entwicklungsprinzipie wo Hootsight forme.",
    "card_title": "Offline-Bild-Augmentierungstool für Training",
    "intro": "Hootsight isch es offline-first Bildklassifizierungstool wo PyTorch-Training mit ere konfigurierten Web-UI kombiniert.",
    "content_markdown": "## Über Hootsight\n\nHoi, ich bi Tanathy! D einzelni Entwicklerin wo Hootsight am laufe hält. Ich han es baut weil ich es zuverlässigs, offline-first Bildklassifizierungstool wott wo ich uf mini eigen Hardware vertroue cha, und ich han denkt, anderi verdiene die Freiheit au.\n\n### Philosophie\n- Dini Daten verlöse nie mini Maschin usser du bewegsch si. Kei Hintergrund-Sync-Jobs oder überraschendi Cloud-Aufruf.\n- Ich weiger mich, Telemetrie oder Tracking-Hooks z schicke. Diagnostik bliibe lokal für dass du entscheide chasch was z teile.\n- Alli Konfiguration lebt in JSON. Versionier, differenzier, deploy in Git—alles was dini Workflow ehrlich hält.\n- Dr Installer konfiguriert es isolierte virtuelle Umgebung, wo dini global Python sauber hält.\n- Vortrainiert Gewicht lebe unter `cache/` für dass du si sichere, auditieren oder verbrenne chasch in Sekunde.\n- Roadmaps folge em echte Läbe. Versione chöme us wenn ich d Bandbreiti han, nit wenn es Sprint-Board sagt vorwärts.\n- Tools si neutral; wie du si verwendisch, isch wichtig. Ich hoff, alli, ich inklusive, verwende si mit Sorgfalt.\n\n>Disclaimer: Jedes Dataset wo du ingibsch, jedes Label wo du vorhersagisch und jedes Model wo du exportiersch isch dini Verantwortung. Halte di a Konsent, Legalität und d betroffene Persone.\n\n### Entwicklungsstatus\n- Hootsight isch fest in Alpha. Erwart Updates, Experiment und gelegentlich rauen Rand.\n- ResNet het voll end-to-end Validierung. ResNeXt, EfficientNet und d restliche Architekture si in langfristig Tests wenn d Ziit erlaubt.\n- Hesch es Bug gfunde? Bitte logge es in [GitHub Issues](https://github.com/Tanathy/HootSight/issues) ein. Klari Bericht helfe mir, schneller z fixe.\n\n### Technisch Grundlage\n- **Backend**: FastAPI-Services koordinieren Dataset-Entdeckung, Training-Orchestrierung und Status-Endpoints.\n- **ML-Kern**: PyTorch handhabt Trainingsschleife, Inferenz und Augmentierungspipelines.\n- **Frontend**: Ei leichte Web-UI HTML/JS/CSS potenziert mit ere grundlegende Hilfsbibliothek (`qte.js`) statt em schweren Framework.\n- **Konfiguration**: Alles isch konfiguriert—kei versteckti Defaults in Code.\n- **Offline-Betrieb**: D App lauft ohni Internetzugang. Optional Update-Checks rufe GitHub nur wenn du s wottsch.\n- **Speicherverwaltung**: Eigen Entwicklungsutilities passe Batchgrössen on-the-fly a und überwache GPU/CPU-Nutzung für OOM-Fehlervermeidung.\n- **Datenhandling**: Projekte, Datasets, Checkpoints und Logs bliibe unter dinere Dateisystem-Kontrolle. Kei automatische Sync, kei remote Mirrors.\n\n### Privatsphäre und Compliance\n- Entwickelt mit GDPR-Erwartunge im Sinn: Kei persönlich Daten wo standardmässig us dinere Umgebung usgöhen.\n- Du entscheidisch was importiert wird, und behaltsch voll Kontrolle über Editierung, Export oder Löschung.\n- Konfiguration, Logs und Checkpoints bliibe uf em Laufwerk usser du teilsch si explizit.\n- Update-Checks si opt-in und übertrage nur Request-Metadaten; Projektinhalt geht nit mit.\n- Wenn du sensitivi Kategorie handlischt (biometrisch, medizinisch, irgendwas reguliert), mappe die Obligatiöne gege dini eigen Richtlinie bevor du trainiersch.\n- Kei Analytics-SDKs, Crash-Reporter oder Third-Party-Tracker in dr App inkludiert.\n\n### Unterstützung\nIch bi froh, das Projekt freizteile für dass du s verwende chasch. Wenn du mini Arbeit unterstütze wottsch, chasch mir es Kaffee kaufe uf [ko-fi.com/tanathy](https://ko-fi.com/tanathy).\n\n### Lizenz und Credits\nHootsight wird mit dr Quelle [Roboto](https://fonts.google.com/specimen/Roboto/license) usgliefert, distribuiert unter dr Open Font License, Version 1.1."
  },
  "training_ui": {
    "page_title": "Training-Setup",
    "page_description": "Konfiguriere Modelarchitektur, Trainingsparameter und Optimierungseinstellige.",
    "optimizer_params_title": "Optimizer-Parameter",
    "scheduler_params_title": "Scheduler-Parameter",
    "loss_params_title": "Verlustparameter",
    "select_type_first": "Wähl zerscht en Typ für Parameter z sehe.",
    "no_extra_params": "Kei zusätzlich Parameter für die Auswahl."
  },
  "dataset_ui": {
    "page_title": "Dataset",
    "page_description": "Erforsche und analysiere d Struktur vo dinere Dataset, Labels und Datenverteilung.",
    "summary": {
      "project": "Projekt",
      "dataset_type": "Dataset-Typ",
      "total_images": "Total Bilder",
      "total_labels": "Total Labels",
      "balance_status": "Balance-Status",
      "balance_score": "Balance-Score",
      "images_per_label_ideal": "Bilder pro Label (Ideal)",
      "min_images": "Min Bilder",
      "max_images": "Max Bilder",
      "max_min_ratio": "Max/Min Ratio"
    },
    "table": {
      "label": "Label",
      "count": "Zähl",
      "percentage": "Prozent"
    }
  },
  "projects_ui": {
    "page_title": "Projekte",
    "page_description": "Verwalte und wechsle zwüsche verschidene Projekte und ML-Datasets.",
    "card": {
      "images": "Bilder",
      "labels": "Labels",
      "balance_score": "Balance-Score",
      "balance_status": "Balance",
      "dataset_type": "Dataset-Typ",
      "status": {
        "balanced": "Balanciert",
        "imbalanced": "Unbalanciert",
        "critical": "Kritisch",
        "warning": "Warnig",
        "good": "Guet",
        "poor": "Schlecht",
        "excellent": "Exzellent",
        "fair": "Fair",
        "ok": "OK",
        "unstable": "Instabil"
      }
    }
  },
  "status_ui": {
    "page_title": "Status",
    "page_description": "Überwach Trainingfortschritt, Systemstatus und Performance-Metriken in Echtzeit."
  },
  "heatmap_ui": {
    "page_title": "Heatmap",
    "page_description": "Generiere und visualisiere Attention-Maps vom Model für Fokusaree vo dr Vorhersag z verstoh."
  },
  "memory_ui": {
    "page_title": "Speicher",
    "page_description": "Überwach System-Speichernutzung und optimier Batchgrössen für effizient Training."
  },
  "environment": {
    "venv_creating": "Erstelle virtuelle Umgebung in {path}...",
    "venv_created": "Virtuelle Umgebung bereit.",
    "venv_create_failed": "Erstelle vo dr virtuellen Umgebung gscheitert: {error}",
    "venv_exists": "Virtuelle Umgebung bereits vorhande.",
    "pip_upgrading": "Pip in dr virtuellen Umgebung aktualisiere...",
    "pip_upgraded": "Pip-Aktualisierung fertig.",
    "pip_upgrade_failed": "Pip-Aktualisierung gscheitert: {error}",
    "cuda_debug_nvcc": "Ausgab vo nvcc --version:\n{output}",
    "cuda_debug_nvcc_error": "Fehler bim Abfrage vo nvcc: {error}",
    "cuda_debug_nvidia_smi": "Ausgab vo nvidia-smi:\n{output}",
    "cuda_debug_nvidia_smi_error": "Fehler bim Abfrage vo nvidia-smi: {error}",
    "cuda_debug_detected": "Erkannti CUDA-Version: {version}",
    "pytorch_install": "PyTorch für CUDA {cuda} uf {platform} installiere...",
    "pytorch_installed": "PyTorch-Installation fertig.",
    "pytorch_install_failed": "PyTorch-Installation gscheitert: {error}",
    "xformers_already_installed": "xFormers bereits installiert und aktualisiert.",
    "xformers_installing": "xFormers (CUDA {cuda_version}) installiere...",
    "xformers_installed": "xFormers-Installation fertig.",
    "xformers_install_failed": "xFormers-Installation gscheitert: {error}",
    "pytorch_skip": "PyTorch-Installation überspringe (erkannt CUDA={cuda}, Platform={platform}).",
    "config_loading": "Umgebungskonfiguration lade...",
    "config_loaded": "Umgebungskonfiguration glade.",
    "using_compatible_xformers": "Verwende CUDA-Index {cuda_version} für xFormers.",
    "env_packages_all_installed": "Umgebungspakete bereits installiert.",
    "env_packages_progress_desc": "Umgebungspakete installiere",
    "env_package_installing": "Umgebungspaket {package} installiere...",
    "env_package_installed": "Umgebungspaket installiert: {package}",
    "env_package_install_failed": "Fehler bim Installiere vom Umgebungspaket {package}: {error}",
    "env_vars_configured": " {count} Umgebungsvariable(n) für dr Trainingprozess vorbereitet.",
    "env_vars_config_failed": "Fehler bim Konfiguriere vo dr Umgebungsvariable: {error}",
    "entry_not_found": "Eingabe-Script nit gfunde in {path}.",
    "venv_python_not_found": "Virtuelle Umgebung Python-Executable fählt: {path}.",
    "venv_python_test_failed": "Virtuelle Umgebung Python gscheitert bim --version Test: {error}",
    "re_exec_starting": "Training via {venv_python} -> {entry_py} starte (Root {root}).",
  "re_exec_timeout": "Timeout bim erneute Uusfüehre.",
    "re_exec_failed": "Fehler bim Start vom Trainingprozess: {error}",
    "re_exec_unexpected_error": "Unerwartete Fehler bim Start vom Trainingprozess: {error}"
  },
  "updates_ui": {
    "page_title": "System-Updates",
    "page_description": "Halte dini Installation mit em Upstream-Repository synchronisiert ohni Projekt-spezifisch Konfigurationsüberschreibunge.",
    "card_title": "Update-Manager",
    "intro": "Vergleich lokal Dateie mit em Referenz-Repository und synchronisier fehlendi Fixes während config.json intakt bliibt.",
    "check_button": "Updates prüfe",
    "apply_button": "Updates aawende",
    "apply_disabled_hint": "Führ ei Prüfung us für Updates z aktiviere.",
    "status_idle": "Kei Updateprüfungen no usgführt.",
    "status_checking": "Updates prüfe...",
    "status_ready": "Update-Zusammenfassung bereit.",
    "status_up_to_date": "Alles isch aktualisiert.",
    "status_failed": "Updateprüfung gscheitert.",
    "status_applying": "Dateie aktualisiere...",
    "status_applied": "Updates erfolgrich aagwendet.",
    "status_apply_failed": "Einigi Updates si gscheitert.",
    "table_header_file": "Datei",
    "table_header_status": "Status",
    "table_header_local": "Lokal",
    "table_header_remote": "Remote",
    "table_row_missing": "Lokal fehlend",
    "table_row_outdated": "Checksum-Unstimmigkeit",
    "table_footnote": "Hashes für Lesbarkeit gekürzt.",
    "no_updates": "Alli verfolgte Dateie si aktualisiert.",
    "hash_missing": "—",
    "orphaned_title": "Lokal nit verfolgte Dateie",
    "orphaned_none": "Kei extra lokal Dateie entdeckt."
  },
  "schema": {
    "description": "JSON Schema für Hootsight config.json – definiert Typä, Wertebereiche und de Aufbau vo alli konfigurierbäre Einstellige",
    "general_description": "Allgemeini App-Einstellige",
    "general_language_description": "Sprachcode für d UI",
    "api_description": "API-Server-Konfiguration",
    "api_host_description": "Hostadresse vom API-Server",
    "api_port_description": "Portnummer vom API-Server",
    "ui_description": "Benutzeroberfläche",
    "ui_title_description": "Fenstertitel vo dr App",
    "ui_width_description": "Fensterbreiti in Pixel",
    "ui_height_description": "Fensterhöh in Pixel",
    "ui_resizable_description": "Ob s Fenster grössser/zchliiner gmacht cha werde",
    "system_description": "Systemnahi Einstellige",
    "system_max_threads_description": "Maximali Thread-Aazahl",
    "system_fallback_batch_size_description": "Fallback-Batchgröscht falls d Auto-Berechnig scheitert",
    "system_memory_cleanup_interval_description": "Intervall für Speicher-Bereinigig (Sekunde)",
    "system_thread_pool_timeout_description": "Thread-Pool-Timeout (Sekunde)",
    "system_startup_wait_seconds_description": "Wartezit bim Start (Sekunde)",
    "memory_description": "Speicherverwaltig",
    "memory_target_memory_usage_description": "Zielauslastig vom Speicher (0.0-1.0)",
    "memory_safety_margin_description": "Sicherheitsmarge für Speicher-Kalkulation (0.0-1.0)",
    "memory_augmentation_threads_description": "Thread-Aazahl für Datenaugmentierig",
    "training_description": "Trainingseinstellige",
    "training_model_type_description": "Modelltyp",
    "training_model_name_description": "Spezifischer Modellname",
    "training_pretrained_description": "Verwendet vortrainierti ImageNet-Gwicht falls verfügbar; deaktivieren für Training ab Null",
    "training_task_description": "Art vo dr ML-Aufgab",
    "training_batch_size_description": "Batchgröscht fürs Training",
    "training_epochs_description": "Aazahl Trainings-Epochen",
    "training_learning_rate_description": "Lernrate",
    "training_weight_decay_description": "Weight Decay (L2-Regularisierung)",
    "training_input_size_description": "Kantenläng in Pixel fürs quadratische Input-Tensor (muss zu dine Augmentierungen passe)",
    "training_normalize_description": "Bildnormalisierungs-Parameter",
    "training_normalize_mean_description": "Mittelwert pro RGB-Kanal",
    "training_normalize_std_description": "Standardabwüch pro RGB-Kanal",
    "training_val_ratio_description": "Validierungsanteil (0.0-1.0)",
    "training_dataloader_description": "DataLoader-Konfiguration",
    "training_dataloader_num_workers_description": "Aazahl Worker-Prozesse",
    "training_dataloader_pin_memory_description": "Memory pinsle für schnellere GPU-Transfers",
    "training_dataloader_persistent_workers_description": "Worker zwüsche de Epochen laufe lah",
    "training_dataloader_prefetch_factor_description": "Wieviel Batches pro Worker vorgelade werde",
    "training_augmentation_description": "Datenaugmentierungs-Konfiguration",
    "training_augmentation_train_description": "Augmentierungen im Training",
    "training_augmentation_val_description": "Augmentierungen im Validation",
    "training_optimizer_type_description": "Optimizer-Typ",
    "training_optimizer_params_description": "Optimizer-Parameter",
    "training_scheduler_type_description": "Scheduler-Typ",
    "training_scheduler_params_description": "Scheduler-Parameter",
    "training_loss_type_description": "Loss-Typ",
    "training_loss_params_description": "Loss-Parameter",
    "training_weight_init_description": "Gewichtsinitialisierung",
    "training_checkpoint_description": "Checkpoint-Einstellige",
    "training_early_stopping_description": "Early-Stopping-Einstellige",
    "training_gradient_description": "Gradient-Einstellige",
    "training_runtime_description": "Runtime-Optimierungs-Einstellige",
    "training_runtime_mixed_precision_description": "Automatisches Mixed Precision Training aktiviere",
    "training_runtime_channels_last_description": "Channels-last Speicherformat für bessere GPU-Auslastig",
    "training_runtime_allow_tf32_description": "TF32 für schnellere Matrixoperatione uf Ampere+ GPUs erlaube",
    "training_runtime_cudnn_benchmark_description": "cuDNN Benchmark aktiviere für optimiert Convolution-Algorithme",
    "dataset_description": "Dataset-Konfiguration",
    "dataset_image_extensions_description": "Unterstützti Bild-Dateiendige",
    "optimizers_description": "Optimizer-Defaults überschriibe",
    "optimizers_defaults_description": "Standard-Parameter für Optimizer",
    "schedulers_description": "Scheduler-Defaults überschriibe",
    "schedulers_defaults_description": "Standard-Parameter für Scheduler",
    "schedulers_defaults_lambda_lr_lr_lambda_description": "Lambda-Funktion als Text, z.B. 'lambda epoch: 0.95 ** epoch'",
    "schedulers_defaults_multiplicative_lr_lr_lambda_description": "Lambda-Funktion als Text, z.B. 'lambda epoch: 0.95'",
    "losses_description": "Loss-Defaults überschriibe",
    "losses_defaults_description": "Standard-Parameter für Losses",
    "models_description": "Modell-Konfiguratione",
    "models_resnet_description": "ResNet-Familie",
    "models_resnet_variants_description": "ResNet-Varianten",
    "models_resnext_description": "ResNeXt-Familie",
    "models_resnext_variants_description": "ResNeXt-Varianten",
    "models_mobilenet_description": "MobileNet-Familie",
    "models_mobilenet_variants_description": "MobileNet-Varianten",
    "models_shufflenet_description": "ShuffleNet-Familie",
    "models_shufflenet_variants_description": "ShuffleNet-Varianten",
    "models_squeezenet_description": "SqueezeNet-Familie",
    "models_squeezenet_variants_description": "SqueezeNet-Varianten",
    "models_efficientnet_description": "EfficientNet-Familie",
    "models_efficientnet_variants_description": "EfficientNet-Varianten",
    "models_supported_types_description": "Unterstützti Modell-Typ",
    "general_language_enum_descriptor": {
      "en": "Englischi Sprach - Steuert d ganz UI-Lokalisierig inklusiv Menu-Texte, Fehlermeldigä, Tooltips und Validierigstext. Beeinflusst alli Text-aagzeige im Web-Interface und i de API-Antworte. Legt fescht, weli Sprachpaket bim Start glade wird. Aktuell einzi unterstützti Sprach und drum Standard i jedere Installation."
    },
    "system_max_threads_enum_descriptor": {
      "auto": "Automatischi Thread-Aazahl - Rechnet dynamisch die optimali Pool-Grössi basierend uf verfügbari CPU-Cores (meist Cores - 1). Beeinflusst parallels Datenlade, Bildvorverarbeitig, Modell-Inferenz-Batching und Hintergrundjobs. Steuert Zuewiisig für PyTorch-DataLoader-Worker, Augmentierungs-Pipelines und gläichziitigi HTTP-Requests. Passt sich automatisch de Hardware und em verfügbare Speicher a."
    },
    "memory_augmentation_threads_enum_descriptor": {
      "auto": "Automatischi Augmentierungs-Threads - Berechnet optimale Thread-Aazahl für paralleli Bildaugmentierig basierend uf CPU-Kerne und verfügbarem RAM. Beeinflusst Durchsatz vo Transformatione wie Drehig, Skalierig, Farb-Jitter und Normalisierung. Steuert Speicherzuewiisig für Augmentierungs-Puffer und Zwischespicherig. Balanciert CPU-Uslastig und Speicherdruck damit s System au bi harter Vorverarbeitig stabil bliibt."
    },
    "training_model_type_enum_descriptor": {
      "resnet": "ResNet (Residual Network) - S tiefs CNN mit Skip-Verbindige für Netz bis 18-152 Layer. Beeinflusst Gradientenfluss, Trainings-Stabilität, Feature-Tüüf und Modellkapazität. Nutzt Residual-Blöck mit Batch-Norm und ReLU. Steuert Komplexität vo 11M Parameter (ResNet-18) bis 60M (ResNet-152). Wirkt sich uf Speicherbedarf, Trainingszit, Inferenz-Gschwindigkeit und finale Genauigkeit bi Bildklassifikationen us.",
      "resnext": "ResNeXt (Aggregated Residual Transformations) - ResNet-Weiterentwicklig mit Gruppä-Convolutions für meh Kapazität ohni viel meh Parameter. Erhöht Diversität bim Feature-Lerne, Expressivität und Effizienz. Steuert paralleli Transformationspfad i jede Residual-Block. Wirkt sich uf GPU-Speicher, Trainingsdauer und erreicht höcheri Genauigkeit als Standard-ResNet bi ähnleche Kosten.",
      "mobilenet": "MobileNet - Leichti CNN mit depthwise separable Convolutions zum Speicher und Rechenaufwand spare. Beeinflusst Latenz, Energieverbrauch, Speicherplatz und ob s uf Mobilegeräte lauffäig isch. Steuert Trade-off zwische Genauigkeit und Effizienz über Width-Multiplier und Auflösig. Wirkt uf Akku-Lebensdauer, Echtzit-Fähigkeit und Edge-Kompatibilität.",
      "shufflenet": "ShuffleNet - Extrem effizients CNN mit Channel-Shuffle und Gruppen-Convolutions. Beeinflusst Speicherbandbreite, Rechenkoschte pro Inferenz, Modellgrössi und Speed. Sorgt für Kanal-Kommunikation zwüsche Gruppä zum Infofluss erhalte. Optimiert für ARM und Low-Power-Gerät. Hilft where Echtzeit-Leistig und beschränkti Ressource im Vordergrund stöh.",
      "squeezenet": "SqueezeNet - Sehr chliises CNN mit Fire-Modul (squeeze + expand) für AlexNet-Genauigkeit mit massiv weniger Parameter. Reduziert Speicherbedarf, Download-Zit und Bandbreite. Steuert Parameter-Aazahl über aggressivi Dimensionalitäts-Reduktion mit nachfolgender Expansion. Minimiert Disk-Footprint und liefert trotzdem brauchbari Genauigkeit für einfache Klassifikations-Ufgabe.",
      "efficientnet": "EfficientNet - Compound-Scaling-CNN wo Tüüf, Breiti und Resoluzion gleichzeitig skaliert via neural Architecture Search. Beeinflusst Effizienz, Genauigkeits-Skalierig, Trainingsressourcen und Inferenz-Optimierig. Steuert Komplexität über en Koeffizient wo alli Dimensione gliichziitig ausgleicht. Gheit besseri Accuracy-Effizienz-Trade-offs als traditionelle Skalierungs-Strategie."
    },
    "training_task_enum_descriptor": {
      "classification": "Single-Label-Klassifikation - Weist pro Bild genau ei sich usschliessends Label zue. Steuert Softmax-Ausgabeschicht, Loss-Wahl und Interpretazion vo Confidence. Am beschte bi guet getrennte Klassen und balanced Datensatz.",
      "multi_label": "Multi-Label-Klassifikation - Ermöglicht mehfachi Labels pro Bild über unabhängigi Sigmoid-Kanäl. Nutzt binäri Kreuzentropie pro Label und bruucht gueti Threshold-Strategie für Imbalance.",
      "detection": "Objekterkenne - Lokalisiert und klassifiziert mehri Objekti mit Bounding Boxes. Verlangt komplexi Architekturä mit Region-Proposals, sauber annotierti Daten und Non-Max-Suppression im Nachgang.",
      "segmentation": "Semantischi Segmentierig - Klassifiziert jedes Pixel und bruucht drum Encoder-Decoder mit Skip-Verbindige. Hohe Speicherlast, handling vo Klassen-Ungleichgwicht und feini Upsampling-Strategie nödig."
    },
    "training_epochs_enum_descriptor": {
      "auto": "Automatischi Epochenwahl - Überwacht Validierungs-Loss und Accuracy und stoppt s Training sobald kei Fortschritt meh sichtbar isch. Spart Rechenressource und schützt vor Overfitting."
    },
    "training_optimizer_type_enum_descriptor": {
      "sgd": "Stochastic Gradient Descent - Klassischer Gradientabstieg mit optionalem Momentum oder Nesterov. Läuft stabil wenn du Scheduler plane chasch und Lernrate sauber abstimmst.",
      "adam": "Adam - Adaptiver Erstordnigs-Optimizer mit gleitende Mittelwerte vo Gradiente. Funktioniert guet bi noisige oder spärlichi Gradiente und bruucht wenig Tuning.",
      "adamw": "AdamW - Variants vo Adam mit abkoppelte Weight Decay, drum bessere Regularisierung. Ideaal fürs Finetuning vo ResNet oder Transformere.",
      "adamax": "AdaMax - Adam mit Unendlich-Norm. Stabilisiert d Schrittgröscht wenn Gradiente Sprüng mache, läuft drum sicherer bi GANs oder RL.",
      "nadam": "Nadam - Kombiniert Adam mit Nesterov-Momentum. Hilft bim Beschleunige vo glatte Zielfunktione, bruucht aber chli meh Rechenaufwand.",
      "radam": "RAdam - Adam-Version mit automatisch Wärmig. Verhindert instabile Startphase und eignet sich für chliini Datäsätze.",
      "rmsprop": "RMSprop - Hält exponentielle Mittelwerte vo quadrierte Gradiente zum Normalisiere. Gschickt bi oszillierende Signale, z.B. RNNs.",
      "rprop": "Rprop - Nutz nume s Vorzeiche vom Gradient und passt Schrittgrössen pro Parameter aa. Nützlich in deterministische Settings mit volle Batches.",
      "adagrad": "Adagrad - Akkumuliert quadrierte Gradiente und schrumpft Lernrate für oft aktualisiert Parameter. Stark für spärlichi Feature-Embeddings.",
      "adadelta": "Adadelta - Baut uf Adagrad uf aber hält Lernrate stabil dank gleitendem Fenster. Funktioniert guet ohni grosses Hyperparameter-Tuning.",
      "sparse_adam": "Sparse Adam - Adam nur für Indize mit Gradient. Spart Speicher bi riesige Embedding-Tabälle, lohnt sich nid für dichte CNNs.",
      "lbfgs": "L-BFGS - Quasi-Newton mit kleinem Speicherbedarf. Bruucht Closures und volle Batches, drum eher fürs Finetuning chliine Modelle.",
      "asgd": "ASGD - Mittelt d Parameter während em Training für ruigere Konvergenz. Praktisch wenn SGD am Schluss schwankt und du kei Adam wotsch."
    },
    "training_scheduler_type_enum_descriptor": {
      "step_lr": "Step-LR - Reduziert d Lernrate nach fix definierte Anzahl Epochen mit Faktor Gamma. Praktisch wenn d Meilenstei vo Vormässig bekannte sind.",
      "multi_step_lr": "Multi-Step-LR - Gleiche wie Step, aber mit meh als ein Meilenstein. Erlaubt fein abgestufte Reduktionen.",
      "exponential_lr": "Exponentiells Decay - Multipliziert jede Epoche mit Gamma und sorgt für gleitendi Abfall. Gut für langi Trainingsläufe.",
      "cosine_annealing_lr": "Cosine Annealing - Lernrate folgt ere Cosinuskurve bis eta_min und landet drum weich im Ziel. Top fürs Feintuning.",
      "cosine_annealing_warm_restarts": "Cosine mit Warm Restarts - Wiederholt Cosinus-Zyklus und setzt nach jedem Durchgang zrugg. Hilft us flache Minimum uszbräche.",
      "reduce_lr_on_plateau": "Reduce on Plateau - Beobachtet e Validierungsmetrik und reduziert Lernrate sobald kei Fortschritt meh chunnt.",
      "cyclic_lr": "Cyclic - Pendlet Lernrate zwischen base_lr und max_lr. Unterstützt schnälls Explorieren vo guete Werte.",
      "one_cycle_lr": "One-Cycle - Erstes Aufwärme bis max_lr, denn Absenkig unter Startwert und invertiert Momentum. Funktioniert top wenn Anzahl Schritt bekannt isch.",
      "polynomial_lr": "Polynomial - Lernrate fällt nach (1 - t/T)^power uf Null. Beliebt bi Segmentation wo kontrollierti Ausläufe bruucht werden.",
      "linear_lr": "Linear - Interpoliert linear zwi Start- und Endfaktor. Häufig fürs Warmup mit chliiner Lernrate.",
      "lambda_lr": "Lambda - Wendet dini eigeti Lambda-Funktion pro Epoche aa. Volli Freihiit aber bruucht sorgfälti Expression.",
      "multiplicative_lr": "Multiplikativ - Ähnlich Lambda, aber jede Schritt Rückgabewert fürs Multipliziere. Vorsichtig bliibe bei Werte > 1."
    },
    "training_loss_type_enum_descriptor": {
      "cross_entropy": "Cross-Entropy - Kombiniert Softmax und negative Log-Likelihood. Standard für Single-Label-Klassifikation.",
      "nll_loss": "Negative Log-Likelihood - Gleiche Mathematik wie Cross-Entropy, aber erwartet vorgängig log_softmax.",
      "bce_loss": "Binary Cross-Entropy - Arbeitet mit Wahrscheinligkeite in [0,1] und bruucht drum explizits Sigmoid.",
      "bce_with_logits": "BCE mit Logits - Numerisch stabili Variante mit internem Sigmoid, perfekt für Multi-Label.",
      "multi_margin": "Multi-Class Margin - Hinge-artigi Loss die en Margin zwüsche richtigem und falschem Klassenscore erzwingt.",
      "multi_label_margin": "Multi-Label Margin - Rangiert positivi Klassä vor negative, aber bruucht Index-Listen als Target.",
      "multi_label_soft_margin": "Multi-Label Soft Margin - Glätteti Sigmoid-Variante für überlappendi Labels und Imbalance.",
      "mse_loss": "Mean Squared Error - Klassischi L2-Strafe, reagiert stark uf grosse Fehler.",
      "l1_loss": "L1 Loss - Absolutwert-Strafe, robust ggü. Ausreisser aber langsamer um Null. Guet wenn MAE relevant isch.",
      "smooth_l1": "Smooth L1 - Huber-ähnlich, verbindet L2 ume Null mit L1 usserthalb. Beliebt bi Bounding Boxes.",
      "huber_loss": "Huber Loss - Wie SmoothL1 aber mit Delta statt Beta für direkte Kontrolle.",
      "kl_div": "KL-Divergenz - Misst Differenz zwüsche zwei Verteilige. Erfordert Log-Probabilitäten und korrekti Reduktion.",
      "margin_ranking": "Margin Ranking - Arbeitet mit Score-Paar und zwingt Ordnung gemäss Label y ∈ {−1, 1}.",
      "hinge_embedding": "Hinge Embedding - Für Ähnlichkeits-Learning mit binäre gleich/ungleiche Labels und definierte Margin.",
      "triplet_margin": "Triplet Margin - Arbeitet mit Anchor/Positiv/Negativ und fordert Mindestabstand. Gutsch Triplet-Mining nötig.",
      "cosine_embedding": "Cosine Embedding - Optimiert Cosinus-Ähnligkeit direkt, sinnvoll mit normalisierte Vektore.",
      "ctc_loss": "CTC - Richtet Sequenze ohni Frame-Alignment us. Targets ohni Blanks, Log-Wahrscheinligkeite als Input.",
      "poisson_nll": "Poisson NLL - Für Zähldate mit nicht-negative Targets, unterstützt log_input oder rohe Raten.",
      "gaussian_nll": "Gaussian NLL - Modelliert Mittelwert und Varianz für kontinuierligi Targets, bruucht positive Varianz."
    },
    "training_loss_reduction_enum_descriptor": {
      "mean": "Mittelwert - Teilt Gesamtloss durch Batchgröscht und sorgt für stabile Gradiente unabhängig vo Batch-Gröscht.",
      "sum": "Summe - Addiert alli Loss-Werte ohni Normalisierung. Gradiente wachse mit Batch und verlange angepassti Lernrate.",
      "none": "Kei Reduktion - Gitt pro Sample e Loss zrugg. Ideal für eigeti Gewichtigs-Schemas oder Analysen."
    },
    "training_early_stopping_monitor_enum_descriptor": {
      "val_loss": "Validierungs-Loss - Stoppt Training sobald dr Verlust kei Fortschritt meh zeigt. Spart Rechenzeit und schützt vor Overfitting.",
      "val_accuracy": "Validierungs-Genauigkeit - Beobachtet Accuracy und stoppt bi Plateau. Fokus uf Klassifikationsqualität statt nur Loss."
    },
    "optimizers_defaults_lbfgs_line_search_fn_oneOf[1]_enum_descriptor": {
      "strong_wolfe": "Strong-Wolfe-Suche - Sicheret, dass L-BFGS-Schrittgrössen sowohl Armijo- wie au Krümmigsbedingungen erfülle und drum stabil konvergiert."
    },
    "schedulers_defaults_reduce_lr_on_plateau_mode_enum_descriptor": {
      "min": "Minimum - Nutzt Scheduler für Metrike wo chliner besser isch (z.B. Loss). Reduziert Lernrate wenn Wert nüm fällt.",
      "max": "Maximum - Geeignet wenn grössere Werte besser sind (Accuracy). Reduziert Lernrate sobald Steigerig stoppt."
    },
    "schedulers_defaults_reduce_lr_on_plateau_threshold_mode_enum_descriptor": {
      "rel": "Relativ - Threshold basiert uf Prozänt vo aktuellem Bestwert, wird strenger je besser d Metrik isch.",
      "abs": "Absolut - Fester Mindestfortschritt unabhängig vom momentane Wert. Liefert konstante Anforderungen."
    },
    "schedulers_defaults_cyclic_lr_mode_enum_descriptor": {
      "triangular": "Triangular - Klassische Dreiecksform mit konstanter Amplitude während em ganze Training.",
      "triangular2": "Triangular2 - Gleiche Form, aber d Amplitude halbiert sich nach jedem Zyklus.",
      "exp_range": "Exp Range - Passt Amplitude exponentiell mit Gamma aa, liefert dynamischi Bereiche."
    },
    "schedulers_defaults_cyclic_lr_scale_mode_enum_descriptor": {
      "cycle": "Cycle - Skaliert pro abgeschlossne Zyklus. Änderungen passiere an de Zyklusgrenze.",
  "iterations": "Iteratione - Skaliert kontinuierlich pro Schritt schafft drum glatte Übergäng."
    },
    "schedulers_defaults_one_cycle_lr_anneal_strategy_enum_descriptor": {
      "cos": "Cosine - Nutzt Cosinuskurve für sanfti Übergäng bi de Lernrate.",
      "linear": "Linear - Verändert Lernrate mit konstantem Tempo über dr Zyklus."
    },
    "losses_defaults_multi_margin_p_enum_descriptor": {
      "1": "L1-Norm - Abständ mit Absolut-Differenze, robust ggü. Ausreisser.",
      "2": "L2-Norm - Nutzt quadrierte Differenze und straft grosse Fehler stärker."
    },
    "losses_defaults_kl_div_reduction_enum_descriptor": {
      "none": "Kei Reduktion - Behält KL-Wärt pro Sample bei für eigeti Verarbeitung.",
      "mean": "Mittelwert - Mittlet über alli Elemente, berücksichtigt drum Batch und Spatial.",
      "sum": "Summe - Addiert alles uf, sorgt für grössere Gradiente bi grosse Batches.",
      "batchmean": "Batchmean - Mittlet nur über Batches, behaltet räumlichi Strukture."
    },
    "models_resnet_default_optimizer_type_enum_descriptor": {
      "adamw": "AdamW - Standardempfehlig für ResNet, trennt Weight Decay vo den adaptiven Updates und bleibt stabil.",
      "adam": "Adam - Sichere Allzweck-Wahl mit adaptiver Lernrate. Läuft guet bi verschiedenste ResNet-Varianten.",
      "sgd": "SGD mit Momentum - Klassischer Ansatz, bruucht sauber geplante Lernraten-Schedule liefert aber top Resultat."
    },
    "models_resnet_default_scheduler_type_enum_descriptor": {
      "step_lr": "Step-LR - Meilenstein-basierte Reduktion wie im klassische ResNet-Training dokumentiert.",
      "cosine_annealing_lr": "Cosine Annealing - Sanfte Verlaufe die d Schlussgenauigkeit häufig verbessere.",
      "reduce_lr_on_plateau": "Reduce on Plateau - Automatisch adaptiv falls Training stagniert und kei fixe Meilenstein bekannt sind."
    },
    "paths_description": "Pfad-Einstellige",
    "paths_projects_dir_description": "Verzeichnis wo d Projektordner liege",
    "paths_ui_dir_description": "Verzeichnis mit de UI-Assets",
    "paths_config_dir_description": "Ordner für Konfigurationsdateie",
    "paths_localizations_dir_description": "Ordner für d Lokalisierungsdateie",
    "paths_packages_file_description": "Pfad zur packages.jsonc",
    "paths_mappings_file_description": "Pfad zur Mapping-Datei",
    "paths_cache_dir_description": "Ordner für Cache-Dateie"
  },
  "status_graph": {
    "epoch_accuracy": "Epoche-Genauigkeit",
    "epoch_loss": "Epoche-Loss",
    "step_loss": "Schritt-Loss",
    "learning_rate": "Lernrate",
    "loss": "Loss",
    "no_data": "Warte uf Update",
    "no_training": "Kei aktivs Training.",
    "active_count": "Aktivi Trainings: {count}",
    "label_training_id": "Training-ID",
    "label_status": "Status",
    "label_phase": "Phase",
    "label_epoch": "Epoche",
    "label_step": "Schritt",
    "badge_training": "Training: {project}",
    "footer_training": "Training {project} — Epoche {epoch} • Schritt {step}"
  },
  "updates": {
    "log": {
      "check_started": "Prüef Upstream-Checksums...",
      "check_complete": "Update-Check fertig. Offeni Dateie: {count}",
      "check_failed": "Update-Check isch fehlgschlage: {error}",
      "remote_config_failed": "Remote config.json het sich nid lade lah: {error}",
      "remote_checksum_failed": "Remote-Checksum-Manifest konnt nid gholt werde: {error}",
      "remote_payload_invalid": "Remote Payload vo {url} isch kei Mapping gsi.",
      "local_checksum_missing": "Lokali checksum.json fehlt, nimm leers Manifest a.",
      "local_checksum_invalid": "Lokali checksum.json cha nid gläse werde: {error}",
      "path_escape": "Unsichere Pfad blockiert: {path}",
      "apply_started": "Wend Updates aa...",
      "apply_failed": "Updates chönd nid aawendet werde: {error}",
      "apply_nothing": "Kei Updates nötig.",
      "apply_file_success": "Aktualisiert: {path}",
      "apply_file_failed": "Aktualisierig fehlgschlage für {path}: {error}",
      "apply_partial": "{updated} Updates aawendt, {failed} sind gschittert.",
      "apply_complete": "{count} Updates erfolgrich aawendt."
    },
    "api": {
      "check_success": "Update-Check abgschlosse. {count} Dateie müend aktualisiert werde.",
      "check_no_updates": "Alles isch aktuell.",
      "check_failed": "Update-Check isch fehlgschlage: {error}",
      "apply_success": "Updates erfolgrich aawendet. {updated} Dateie aktualisiert.",
      "apply_partial": "Updates teilwiis umgesetzt: {updated} Erfolgi, {failed} Feeler.",
      "apply_failed": "Updates chönd nid aawendet werde: {error}",
      "apply_nothing": "Kei Updates nötig gsi."
    },
    "status": {
      "missing": "Fehlt lokal",
      "outdated": "Checksum passt nid"
    }
  },
  "status": {
    "project_load_failed": "Projektladung gscheitert",
    "project_loading": "Projekt {projectName} lade...",
    "project_loaded_custom": "Projekt {projectName} mit benutzerdefiniertem Config glade",
    "project_loaded_defaults": "Projekt {projectName} mit globale Defaults glade",
    "project_load_error": "Fehler bim Lade vom Projekt {projectName}: {error}",
    "no_project_loaded": "Kei Projekt glade",
    "validation_errors": "Beheb Validierungsfehler bevor speichere",
    "saving_training_config": "Training-Config speichere...",
    "training_config_saved": "Training-Config gspeichert",
    "save_failed": "Speicherung gscheitert",
    "loading_schema": "Schema & Config lade...",
    "init_failed": "Init gscheitert",
    "memory_load_failed": "Speicherladung gscheitert",
    "checking_updates": "Updates prüfe...",
    "updates_ready": "Updates verfügbar",
    "updates_none": "Kei Updates verfügbar",
    "updates_check_failed": "Updateprüfung gscheitert",
    "updates_applying": "Updates aawende...",
    "updates_applied": "Updates erfolgrich aagwendet",
    "updates_apply_failed": "Updateanwendung gscheitert",
    "generating_heatmap": "Heatmap generiere...",
    "heatmap_generated": "Heatmap generiert",
    "heatmap_generation_failed": "Heatmap-Generierung gscheitert",
    "saving_system_settings": "Systemeinstellige speichere...",
    "system_settings_saved": "Systemeinstellige gspeichert",
    "starting_training": "Training starte...",
    "training_started": "Training gstaltet",
    "training_stopping": "Training stoppe...",
    "training_stop_requested": "Trainingstopp aagforderet",
    "training_stop_failed": "Trainingstopp gscheitert",
    "training_start_failed": "Trainingstart gscheitert",
    "switching_language": "Sprach wechsle...",
    "language_switched": "Sprach erfolgrich gwechslet",
    "language_switch_failed": "Sprachwechsel gscheitert",
    "augmentation_preview_ready": "Augmentierungsvorschau generiert"
  }
}
