{
  "language_name": "Magyar",
  "activations": {
  "not_supported": "Nem támogatott aktiváció: {activation}. Elérhető opciók: {available}",
  "created": "Aktivációs függvényt létrehoztuk: {activation}, paraméterek: {params}",
  "creation_failed": "Nem sikerült létrehozni az aktivációt: {error}",
  "invalid_params": "Érvénytelen paraméterek az aktivációhoz: {error}",
  "config_missing_type": "Hiányzik a 'type' az aktiváció konfigurációjából",
  "recommendations_removed": "Az aktivációs ajánlásokat eltávolítottuk a rendszerből"
  },
  "augmentation": {
  "not_supported": "Nem támogatott augmentáció: {aug}. Elérhető opciók: {available}",
  "created": "Augmentációt létrehoztuk: {aug}, paraméterek: {params}",
  "creation_failed": "Nem sikerült létrehozni az augmentációt: {error}",
  "invalid_params": "Érvénytelen paraméterek az augmentációhoz: {error}",
  "config_missing_type": "Hiányzik a 'type' az augmentáció konfigurációjából",
  "preview_invalid_phase": "Érvénytelen augmentációs fázis: {phase}",
  "preview_no_images": "Nincsenek képek a {project} projekthez az előnézethez.",
  "preview_failed": "Nem sikerült előállítani az előnézetet: {error}",
  "preview_generated": "Előnézet elkészült a {phase} fázishoz"
  },
  "coordinator_settings": {
  "user_settings_saved": "A beállításaidat elmentettük ide: {path}",
  "user_settings_save_failed": "Nem sikerült elmenteni a beállításokat: {error}"
  },
  "recommendations": {
  "critical_shortage": "Kritikus adathiány: {labels}",
  "reduce_oversampled": "Csökkentsd a túlmintázott címkéket: {labels}",
  "augment_undersampled": "Augmentáld az alulreprezentált címkéket: {labels}",
  "weighted_loss": "Használj súlyozott loss-t",
  "stratified_sampling": "Fontold meg a rétegzett mintavételezést",
  "hierarchical_imbalance": "Hierarchikus egyensúlyhiány: {categories}",
  "small_dataset": "Kis adathalmaz — érdemes augmentálni",
  "tiny_dataset": "Nagyon kis adathalmaz — magas az overfitting kockázata"
  },
  "losses": {
  "not_supported": "Nem támogatott loss: {loss}. Elérhető opciók: {available}",
  "created": "Loss-t létrehoztuk: {loss}, paraméterek: {params}",
  "creation_failed": "Nem sikerült létrehozni a loss-t: {error}",
  "invalid_params": "Érvénytelen paraméterek a loss-hoz: {error}",
  "config_missing_type": "Hiányzik a 'type' a loss konfigurációjából",
  "recommendations_removed": "A loss-ajánlásokat eltávolítottuk"
  },
  "normalization": {
  "not_supported": "Nem támogatott normalizáció: {norm}. Elérhető opciók: {available}",
  "missing_num_features": "Hiányzik a 'num_features' paraméter: {norm}",
  "missing_num_channels": "Hiányzik a 'num_channels' paraméter: {norm}",
  "missing_normalized_shape": "Hiányzik a 'normalized_shape' paraméter: {norm}",
  "created": "Normalizációs réteget létrehoztuk: {norm}, paraméterek: {params}",
  "creation_failed": "Nem sikerült létrehozni a normalizációs réteget: {error}",
  "invalid_params": "Érvénytelen paraméterek a normalizációhoz: {error}",
  "config_missing_type": "Hiányzik a 'type' a normalizáció konfigurációjából",
  "recommendations_removed": "A normalizációs ajánlásokat eltávolítottuk"
  },
  "optimizers": {
  "not_supported": "Nem támogatott optimizer: {optimizer}. Elérhető opciók: {available}",
  "created": "Optimiert létrehozva: {optimizer}, paraméterek: {params}",
  "creation_failed": "Nem sikerült létrehozni az optimalizálót: {error}",
  "invalid_params": "Érvénytelen paraméterek az optimalizálóhoz: {error}",
  "config_missing_type": "Hiányzik a 'type' az optimizer konfigurációjából",
  "recommendations_removed": "Az optimizer-ajánlásokat eltávolítottuk"
  },
  "pooling": {
  "not_supported": "Nem támogatott pooling: {pool}. Elérhető opciók: {available}",
  "created": "Pooling réteget létrehoztuk: {pool}, paraméterek: {params}",
  "creation_failed": "Nem sikerült létrehozni a pooling réteget: {error}",
  "invalid_params": "Érvénytelen paraméterek a poolinghoz: {error}",
  "config_missing_type": "Hiányzik a 'type' a pooling konfigurációjából",
  "recommendations_removed": "A pooling-ajánlásokat eltávolítottuk"
  },
  "regularization": {
  "not_supported": "Nem támogatott regularizáció: {reg}. Elérhető opciók: {available}",
  "created": "Regularizációs réteget létrehoztuk: {reg}, paraméterek: {params}",
  "creation_failed": "Nem sikerült létrehozni a regularizációt: {error}",
  "invalid_params": "Érvénytelen paraméterek a regularizációhoz: {error}",
  "config_missing_type": "Hiányzik a 'type' a regularizáció konfigurációjából",
  "recommendations_removed": "A regularizációs ajánlásokat eltávolítottuk"
  },
  "schedulers": {
  "not_supported": "Nem támogatott scheduler: {scheduler}. Elérhető opciók: {available}",
  "created": "Schedulert létrehoztuk: {scheduler}, paraméterek: {params}",
  "creation_failed": "Nem sikerült létrehozni a schedulert: {error}",
  "invalid_params": "Érvénytelen paraméterek a schedulerhez: {error}",
  "config_missing_type": "Hiányzik a 'type' a scheduler konfigurációjából",
  "recommendations_removed": "A scheduler-ajánlásokat eltávolítottuk"
  },
  "weight_init": {
  "not_supported": "Nem támogatott súly-inicializáció: {init}. Elérhető opciók: {available}",
  "applied": "Súly-inicializáció alkalmazva: {init} a(z) {module}-on, paraméterek: {params}",
  "application_failed": "Nem sikerült alkalmazni az inicializációt: {error}",
  "invalid_params": "Érvénytelen paraméterek az inicializációhoz: {error}",
  "recommendations_removed": "A súly-inicializációs ajánlásokat eltávolítottuk"
  },
  "heatmap": {
  "no_images": "Nincsenek képek a(z) {project} projekthez",
  "checkpoint_missing": "Modell-ellenőrzőpont nem található a könyvtárban: {dir}",
  "project_or_dataset_missing": "A(z) {project} projekt vagy az adathalmaza nem található",
  "generated": "Hőtérképet készítettünk a(z) {project} projekthez: {image} (osztály {clazz})"
  },
  "app": {
  "brand": "Hootsight"
  },
  "nav": {
    "training_group": "Tanítás",
    "projects": "Projektek",
    "dataset": "Adathalmaz",
    "training_setup": "Tanítási Beállítás",
    "augmentation": "Augmentáció",
    "status_group": "Állapot",
    "status": "Állapot",
    "heatmap": "Hőtérkép",
    "memory": "Memória",
    "system_group": "Rendszer",
    "updates": "Frissítések"
  },
  "page": {
    "projects": "Projektek",
    "dataset": "Adathalmaz",
    "training": "Tanítási Beállítás",
    "augmentation": "Augmentáció",
    "status": "Állapot",
    "heatmap": "Hőtérkép",
    "memory": "Memória",
    "updates": "Frissítések"
  },
  "config": {
    "sections": {
      "training": "Tanítás",
      "optimizers": "Optimalizálók",
      "schedulers": "Schedulerek",
      "losses": "Veszteségfüggvények",
      "models": "Modellek"
    },
    "entities": {
      "optimizers": {
        "sgd": "SGD (Sztochasztikus Gradiens Descent)",
        "adam": "Adam Optimalizáló",
        "adamw": "AdamW Optimalizáló",
        "adamax": "AdaMax Optimalizáló",
        "nadam": "Nesterov Adam",
        "radam": "Rektifikált Adam",
        "rmsprop": "RMSprop Optimalizáló",
        "rprop": "Rugalmas Visszafelé Propagáció",
        "adagrad": "AdaGrad Optimalizáló",
        "adadelta": "AdaDelta Optimalizáló",
        "sparse_adam": "Ritka Adam",
        "lbfgs": "L-BFGS Optimalizáló",
        "asgd": "Átlagolt SGD"
      },
      "schedulers": {
        "step_lr": "Lépéses Tanulási Ráta",
        "multi_step_lr": "Többlépéses Tanulási Ráta",
        "exponential_lr": "Exponenciális Tanulási Ráta",
        "cosine_annealing_lr": "Koszinusz Annealing",
        "cosine_annealing_warm_restarts": "Koszinusz Annealing Meleg Újraindításokkal",
        "reduce_lr_on_plateau": "Csökkentés LR Fennsíkon",
        "cyclic_lr": "Ciklikus Tanulási Ráta",
        "one_cycle_lr": "Egy Ciklus Tanulási Ráta",
        "polynomial_lr": "Polinomiális Tanulási Ráta",
        "linear_lr": "Lineáris Tanulási Ráta",
        "lambda_lr": "Lambda Tanulási Ráta",
        "multiplicative_lr": "Multiplikatív Tanulási Ráta"
      },
      "losses": {
        "cross_entropy": "Kereszt-Entrópia Veszteség",
        "nll_loss": "Negatív Log-Likelihood",
        "bce_loss": "Bináris Kereszt-Entrópia",
        "bce_with_logits": "BCE Logitekkel",
        "multi_margin": "Többosztályos Margó Veszteség",
        "multi_label_margin": "Többcímkés Margó Veszteség",
        "multi_label_soft_margin": "Többcímkés Puha Margó",
        "mse_loss": "Átlagos Négyzetes Hiba",
        "l1_loss": "L1 Veszteség (MAE)",
        "smooth_l1": "Sima L1 Veszteség",
        "huber_loss": "Huber Veszteség",
        "kl_div": "KL Divergencia",
        "margin_ranking": "Margó Rangsorolás Veszteség",
        "hinge_embedding": "Hinge Beágyazás Veszteség",
        "triplet_margin": "Triplet Margó Veszteség",
        "cosine_embedding": "Koszinusz Beágyazás Veszteség",
        "ctc_loss": "CTC Veszteség",
        "poisson_nll": "Poisson NLL Veszteség",
        "gaussian_nll": "Gauss NLL Veszteség"
      }
    }
  },
  "groups": {
    "model_settings": "Modell Beállítások",
    "task_configuration": "Feladat Konfiguráció",
    "training_parameters": "Tanítási Paraméterek",
    "optimizer_settings": "Optimalizáló Beállítások",
    "scheduler_settings": "Scheduler Beállítások",
    "loss_configuration": "Veszteség Konfiguráció",
    "data_loading": "Adat Betöltés",
    "normalization": "Normalizáció",
    "checkpointing": "Ellenőrzőpont Készítés",
    "weight_initialization": "Súly Inicializáció"
  },
  "actions": {
    "save_config": "Konfiguráció Mentése",
    "export": "Exportálás",
    "save_training_config": "Tanítási Konfiguráció Mentése",
    "save_system_settings": "Globális Beállítások Mentése"
  },
  "footer": {
    "tagline": "Konfiguráció-alapú",
    "generated": "",
    "ready": "Kész"
  },
  "field": {
    "training_model_type": "Modell Típus",
    "training_model_name": "Modell Név",
    "training_pretrained": "Előtanított",
    "training_task": "Feladat",
    "training_batch_size": "Köteg Méret",
    "training_epochs": "Epochok",
    "training_learning_rate": "Tanulási Ráta",
    "training_weight_decay": "Súly Csökkenés",
    "training_input_size": "Bemeneti Méret",
    "training_val_ratio": "Validációs Arány",
    "training_optimizer_type": "Optimalizáló Típus",
    "training_scheduler_type": "Scheduler Típus",
    "training_loss_type": "Veszteség Típus",
    "training_dataloader": "Adatbetöltő",
    "training_dataloader_num_workers": "Munkások Száma",
    "training_dataloader_pin_memory": "Memória Kitűzése",
    "training_dataloader_persistent_workers": "Állandó Munkások",
    "training_dataloader_prefetch_factor": "Előhívási Tényező",
    "training_normalize": "Normalizálás",
    "training_normalize_mean": "Átlag",
    "training_normalize_std": "Szórás",
    "training_checkpoint": "Ellenőrzőpont",
    "training_checkpoint_save_best_only": "Csak Legjobb Mentése",
    "training_checkpoint_save_frequency": "Mentési Gyakoriság",
    "training_checkpoint_max_checkpoints": "Max Ellenőrzőpontok",
    "training_checkpoint_checkpoint_dir": "Ellenőrzőpont Könyvtár",
    "training_checkpoint_best_model_filename": "Legjobb Modell Fájlnév",
    "training_checkpoint_training_history_filename": "Tanítási Előzmények Fájlnév",
    "training_weight_init": "Súly Inicializálás",
    "training_weight_init_type": "Inicializálás Típus",
    "training_weight_init_params": "Inicializálás Paraméterek",
    "training_optimizer_params_adamw_lr": "Tanulási Ráta",
    "training_optimizer_params_adamw_betas": "Béták",
    "training_optimizer_params_adamw_eps": "Epszilon",
    "training_optimizer_params_adamw_weight_decay": "Súly Csökkenés",
    "training_optimizer_params_adamw_amsgrad": "Amsgrad",
    "training_scheduler_params_step_lr_step_size": "Lépés Méret",
    "training_scheduler_params_step_lr_gamma": "Gamma",
    "training_scheduler_params_step_lr_last_epoch": "Utolsó Epoch",
    "training_loss_params_bce_with_logits_weight": "Súly",
    "training_loss_params_bce_with_logits_size_average": "Méret Átlag",
    "training_loss_params_bce_with_logits_reduce": "Csökkentés",
    "training_loss_params_bce_with_logits_reduction": "Redukció",
    "training_loss_params_bce_with_logits_pos_weight": "Pozitív Súly"
  },
  "ui": {
    "generate_heatmap": "Hőtérkép Előállítása",
    "no_heatmap_generated": "Még nincs hőtérkép előállítva.",
    "no_data_available": "Nincs elérhető adat.",
    "page_not_implemented": "Az oldal nincs megvalósítva",
    "error": "Hiba",
    "schema_not_loaded": "A séma még nincs betöltve. Kérlek várj...",
    "config_not_loaded": "A konfiguráció még nincs betöltve. Kérlek várj...",
    "augmentation_phase": "Augmentáció {phase}",
    "add": "Hozzáadás",
    "remove": "Eltávolítás",
    "transform": "transzformáció",
    "no_project_loaded": "Nincs Projekt Betöltve",
    "load_project_first": "Először tölts be egy projektet a Projektek fülről.",
    "go_to_projects": "Menj a Projektekhez",
    "dataset_overview": "Adathalmaz Áttekintés",
    "balance_analysis": "Egyensúly Elemzés",
    "label_distribution": "Címke Eloszlás (Top 20)",
    "recommendations": "Javaslatok",
    "failed_to_load_dataset": "Nem sikerült betölteni az adathalmaz információt.",
    "current_project": "AKTUÁLIS PROJEKT",
    "load": "Betöltés",
    "start_training": "Tanítás Indítása",
    "stop_training": "Tanítás Leállítása",
    "stop_training_disabled": "Nincs aktív tanítás ehhez a projekthez.",
    "training_in_progress": "Tanítás folyamatban",
    "memory": "Memória",
    "loading": "Betöltés...",
    "training_status": "Tanítási Állapot",
    "idle": "Tétlen",
    "prediction": "Előrejelzés",
    "predictions": "Előrejelzések",
    "no_predictions_above_threshold": "Nincs előrejelzés a küszöb felett",
    "image": "Kép",
    "checkpoint": "Ellenőrzőpont",
    "auto": "auto",
    "value": "érték",
    "one_number_per_line": "Egy szám soronként",
    "empty_object": "Üres objektum",
    "language_warning": "A nyelv váltás újratölti a rendszert",
    "language_select_title": "Válassz nyelvet",
    "not_available": "N/A",
    "unknown": "Ismeretlen",
    "configuration_empty": "Nincsenek elérhető konfigurációs szekciók",
    "configuration_schema_missing": "A konfigurációs séma nincs betöltve még."
  },
  "augmentation_ui": {
    "page_title": "Adat Augmentáció",
    "page_description": "Konfiguráld a kép transzformációkat a modell általánosításának és robusztusságának javítására.",
    "train_title": "Tanítási Augmentációk",
    "train_description": "Alkalmazva a tanítás során a vizuális sokféleség növelésére, miközben a címkék érintetlenek maradnak.",
    "val_title": "Validációs Augmentációk",
    "val_description": "Alkalmazva a validáció során a determinisztikus kiértékelés fenntartására.",
    "toggle_help": "Kapcsold be vagy ki az augmentációt ehhez a fázishoz.",
    "no_options": "Nincsenek elérhető augmentációs opciók.",
    "custom_warning": "A következő transzformációk meg vannak őrizve, de itt nem szerkeszthetők:",
    "unknown_transform": "Ismeretlen transzformáció",
    "random_resized_crop": "Véletlen Átméretezett Kivágás",
    "random_resized_crop_description": "Véletlenül kivág és átméretez a célméretre, figyelembe véve a skála és arány tartományokat.",
    "random_horizontal_flip": "Véletlen Vízszintes Tükrözés",
    "random_horizontal_flip_description": "Tükrözi a képet vízszintesen a konfigurált valószínűséggel a bal és jobb változatok rögzítésére.",
    "random_vertical_flip": "Véletlen Függőleges Tükrözés",
    "random_vertical_flip_description": "Tükrözi a képet függőlegesen a perspektíva változások felfelé és lefelé kitetésére.",
    "random_rotation": "Véletlen Forgatás",
    "random_rotation_description": "Alkalmaz véletlen forgatást a meghatározott fok tartományban az irányfüggőség csökkentésére.",
    "color_jitter": "Szín Remegés",
    "color_jitter_description": "Véletlenül változtatja a fényességet, kontrasztot, telítettséget és színtone-t a szín robusztusság javítására.",
    "random_grayscale": "Véletlen Szürkeárnyalat",
    "random_grayscale_description": "Konvertálja a képeket szürkeárnyalatra a konfigurált valószínűséggel a luminancia tudatosság javítására.",
    "random_erasing": "Véletlen Törlés",
    "random_erasing_description": "Véletlenül maszkol téglalap alakú régiókat a térbeli robusztusság és objektum teljesség érvelés ösztönzésére.",
    "random_perspective": "Véletlen Perspektíva",
    "random_perspective_description": "Alkalmaz véletlen perspektíva transzformációt a konfigurált torzítási skálával és valószínűséggel.",
    "center_crop": "Középső Kivágás",
    "center_crop_description": "Kivágja a középső régiót a célméretre a konzisztens validációs bemenetekhez.",
    "random_resized_crop.size_label": "Kimeneti méret",
    "random_resized_crop.size_description": "Végső élhossz pixelben a kivágás átméretezése után.",
    "random_resized_crop.scale_min_label": "Skála minimum",
    "random_resized_crop.scale_min_description": "Alsó határ a véletlen terület skálának relatív az eredeti képhez (0-1).",
    "random_resized_crop.scale_max_label": "Skála maximum",
    "random_resized_crop.scale_max_description": "Felső határ a véletlen terület skálának relatív az eredeti képhez.",
    "random_resized_crop.ratio_min_label": "Arány minimum",
    "random_resized_crop.ratio_min_description": "Alsó határ a mintázott arányhoz az átméretezés előtt.",
    "random_resized_crop.ratio_max_label": "Arány maximum",
    "random_resized_crop.ratio_max_description": "Felső határ a mintázott arányhoz az átméretezés előtt.",
    "random_horizontal_flip.p_label": "Tükrözési valószínűség",
    "random_horizontal_flip.p_description": "Esély, hogy egy kép vízszintesen tükröződik.",
    "random_vertical_flip.p_label": "Tükrözési valószínűség",
    "random_vertical_flip.p_description": "Esély, hogy egy kép függőlegesen tükröződik.",
    "random_rotation.min_label": "Minimum fok",
    "random_rotation.min_description": "Alsó forgatási határ fokban (negatív értékek óramutató járásával ellentétesen forgatnak).",
    "random_rotation.max_label": "Maximum fok",
    "random_rotation.max_description": "Felső forgatási határ fokban (pozitív értékek óramutató járásával forgatnak).",
    "color_jitter.brightness_label": "Fényesség remegés",
    "color_jitter.brightness_description": "Maximális fényesség eltérés hozzáadva minden csatornához.",
    "color_jitter.contrast_label": "Kontraszt remegés",
    "color_jitter.contrast_description": "Maximális kontraszt skálázás alkalmazva a képre.",
    "color_jitter.saturation_label": "Telítettség remegés",
    "color_jitter.saturation_description": "Maximális telítettség változás alkalmazva HSV térben.",
    "color_jitter.hue_label": "Színtónus remegés",
    "color_jitter.hue_description": "Maximális színtónus eltolás tartomány (0-0.5).",
    "random_grayscale.p_label": "Szürkeárnyalat valószínűség",
    "random_grayscale.p_description": "Esély, hogy egy kép szürkeárnyalatra konvertálódik.",
    "random_erasing.p_label": "Törlési valószínűség",
    "random_erasing.p_description": "Esély, hogy egy véletlen régió törlődik képenként.",
    "random_erasing.scale_min_label": "Skála minimum",
    "random_erasing.scale_min_description": "Alsó határ a törölt terület skálának relatív a teljes képhez.",
    "random_erasing.scale_max_label": "Skála maximum",
    "random_erasing.scale_max_description": "Felső határ a törölt terület skálának relatív a teljes képhez.",
    "random_erasing.ratio_min_label": "Arány minimum",
    "random_erasing.ratio_min_description": "Alsó határ a törölt folt arányának.",
    "random_erasing.ratio_max_label": "Arány maximum",
    "random_erasing.ratio_max_description": "Felső határ a törölt folt arányának.",
    "random_erasing.value_label": "Kitöltési érték",
    "random_erasing.value_description": "Pixel érték a törölt régió kitöltésére (0-1).",
    "random_erasing.inplace_label": "Helyben",
    "random_erasing.inplace_description": "Alkalmazd a törlést közvetlenül a bemeneti tenzoron másolat készítése nélkül.",
    "random_perspective.distortion_scale_label": "Torzítási skála",
    "random_perspective.distortion_scale_description": "Szabályozza a perspektíva torzítás erejét (0-1).",
    "random_perspective.p_label": "Perspektíva valószínűség",
    "random_perspective.p_description": "Esély, hogy egy véletlen perspektíva torzítás alkalmazódik.",
    "center_crop.size_label": "Kivágási méret",
    "center_crop.size_description": "Cél élhossz pixelben a középső kivágáshoz.",
    "preview_section_title": "Előnézet",
    "preview_description": "Alkalmazd az aktuális folyamatot egy véletlen adathalmaz képre.",
    "preview_button": "Előnézet Ellenőrzése",
    "preview_idle": "Kattints az Előnézet Ellenőrzésére a augmentált kép megtekintéséhez.",
    "preview_loading": "Előnézet előállítása...",
    "preview_no_project": "Tölts be egy projektet az augmentációk előnézetéhez.",
    "preview_empty_pipeline": "Konfigurálj legalább egy transzformációt az előnézethez.",
    "preview_generic_error": "Nem sikerült előállítani az előnézetet.",
    "preview_original_label": "Eredeti",
    "preview_augmented_label": "Augmentált",
    "preview_image_path_label": "Kép útvonal"
  },
  "training_ui": {
    "page_title": "Tanítási Beállítás",
    "page_description": "Konfiguráld a modell architektúrát, tanítási paramétereket és optimalizálási beállításokat.",
    "optimizer_params_title": "Optimalizáló Paraméterek",
    "scheduler_params_title": "Scheduler Paraméterek",
    "loss_params_title": "Veszteség Paraméterek",
    "select_type_first": "Először válassz egy típust a paraméterek megtekintéséhez.",
    "no_extra_params": "Nincsenek extra paraméterek ehhez a kiválasztáshoz."
  },
  "dataset_ui": {
    "page_title": "Adathalmaz",
    "page_description": "Fedezd fel és elemezd az adathalmaz struktúráját, címkéit és adat eloszlását.",
    "summary": {
      "project": "Projekt",
      "dataset_type": "Adathalmaz Típus",
      "total_images": "Összes Kép",
      "total_labels": "Összes Címke",
      "balance_status": "Egyensúly Állapot",
      "balance_score": "Egyensúly Pontszám",
      "images_per_label_ideal": "Képek Címkénként (Ideális)",
      "min_images": "Min Képek",
      "max_images": "Max Képek",
      "max_min_ratio": "Max/Min Arány"
    },
    "table": {
      "label": "Címke",
      "count": "Darab",
      "percentage": "Százalék"
    }
  },
  "projects_ui": {
    "page_title": "Projektek",
    "page_description": "Kezeld és válts különböző gépi tanulási projektek és adathalmazok között.",
    "card": {
      "images": "Képek",
      "labels": "Címkék",
      "balance_score": "Egyensúly Pontszám",
      "balance_status": "Egyensúly",
      "dataset_type": "Adathalmaz Típus",
      "status": {
        "balanced": "Egyensúlyozott",
        "imbalanced": "Egyensúlytalan",
        "critical": "Kritikus",
        "warning": "Figyelmeztetés",
        "good": "Jó",
        "poor": "Gyenge",
        "excellent": "Kiváló",
        "fair": "Elfogadható",
        "ok": "OK",
        "unstable": "Instabil"
      }
    }
  },
  "status_ui": {
    "page_title": "Állapot",
    "page_description": "Figyeld a tanítási folyamatot, rendszer állapotot és valós idejű teljesítmény mutatókat."
  },
  "heatmap_ui": {
    "page_title": "Hőtérkép",
    "page_description": "Állítsd elő és vizualizáld a modell figyelem térképeit az előrejelzési fókusz területek megértéséhez."
  },
  "memory_ui": {
    "page_title": "Memória",
    "page_description": "Figyeld a rendszer memória használatát és optimalizáld a köteg méreteket hatékony tanításhoz."
  },
  "environment": {
    "venv_creating": "Python virtuális környezet létrehozása itt: {path}...",
    "venv_created": "Virtuális környezet kész.",
    "venv_create_failed": "Virtuális környezet létrehozása sikertelen: {error}",
    "venv_exists": "Virtuális környezet már jelen van.",
    "pip_upgrading": "Pip frissítése a virtuális környezetben...",
    "pip_upgraded": "Pip frissítés befejezve.",
    "pip_upgrade_failed": "Pip frissítés sikertelen: {error}",
    "cuda_debug_nvcc": "nvcc --version kimenet:\n{output}",
    "cuda_debug_nvcc_error": "Nem sikerült lekérdezni az nvcc-t: {error}",
    "cuda_debug_nvidia_smi": "nvidia-smi kimenet:\n{output}",
    "cuda_debug_nvidia_smi_error": "Nem sikerült lekérdezni az nvidia-smi-t: {error}",
    "cuda_debug_detected": "Észlelt CUDA verzió: {version}",
    "pytorch_install": "PyTorch telepítése CUDA {cuda} számára {platform} rendszeren...",
    "pytorch_installed": "PyTorch telepítés befejezve.",
    "pytorch_install_failed": "PyTorch telepítés sikertelen: {error}",
    "xformers_already_installed": "xFormers már telepítve és naprakész.",
    "xformers_installing": "xFormers telepítése (CUDA {cuda_version})...",
    "xformers_installed": "xFormers telepítés befejezve.",
    "xformers_install_failed": "xFormers telepítés sikertelen: {error}",
    "pytorch_skip": "PyTorch telepítés kihagyása (észlelt CUDA={cuda}, platform={platform}).",
    "config_loading": "Környezeti konfiguráció betöltése...",
    "config_loaded": "Környezeti konfiguráció betöltve.",
    "using_compatible_xformers": "CUDA index {cuda_version} használata xFormers számára.",
    "env_packages_all_installed": "Környezeti csomagok már telepítve.",
    "env_packages_progress_desc": "Környezeti csomagok telepítése",
    "env_package_installing": "Környezeti csomag telepítése {package}...",
    "env_package_installed": "Környezeti csomag telepítve: {package}",
    "env_package_install_failed": "Nem sikerült telepíteni a környezeti csomagot {package}: {error}",
    "env_vars_configured": "{count} környezeti változó előkészítve a tanítási folyamathoz.",
    "env_vars_config_failed": "Nem sikerült konfigurálni a környezeti változókat: {error}",
    "entry_not_found": "Belépési szkript nem található itt: {path}.",
    "venv_python_not_found": "Virtuális környezet Python végrehajtható hiányzik: {path}.",
    "venv_python_test_failed": "Virtuális környezet Python --version tesztje sikertelen: {error}",
    "re_exec_starting": "Tanítási belépés indítása {venv_python} -> {entry_py} (root {root}).",
    "re_exec_timeout": "Újra-végrehajtás időtúllépés.",
    "re_exec_failed": "Nem sikerült elindítani a tanítási folyamatot: {error}",
    "re_exec_unexpected_error": "Váratlan hiba a tanítási folyamat indítása közben: {error}"
  },
  "updates_ui": {
    "page_title": "Rendszer Frissítések",
    "page_description": "Tartsd szinkronban a telepítésedet a referencia repository-val anélkül, hogy felülírnád a projekt-specifikus konfigurációs felülírásokat.",
    "card_title": "Frissítő Manager",
    "intro": "Hasonlítsd össze a helyi fájlokat a referencia repository-val és szinkronizáld a hiányzó javításokat miközben a config.json érintetlen marad.",
    "check_button": "Frissítések Ellenőrzése",
    "apply_button": "Frissítések Alkalmazása",
    "apply_disabled_hint": "Futtass egy ellenőrzést az alkalmazás engedélyezéséhez.",
    "status_idle": "Még nem futottak frissítési ellenőrzések.",
    "status_checking": "Frissítések ellenőrzése...",
    "status_ready": "Frissítési összefoglaló előkészítve.",
    "status_up_to_date": "Minden már naprakész.",
    "status_failed": "Frissítési ellenőrzés sikertelen.",
    "status_applying": "Fájlok frissítése...",
    "status_applied": "Frissítések sikeresen alkalmazva.",
    "status_apply_failed": "Egyes frissítések sikertelenek.",
    "table_header_file": "Fájl",
    "table_header_status": "Állapot",
    "table_header_local": "Helyi",
    "table_header_remote": "Távoli",
    "table_row_missing": "Helyileg hiányzik",
    "table_row_outdated": "Ellenőrző összeg eltérés",
    "table_footnote": "Az összegek olvashatóság érdekében rövidítettek.",
    "no_updates": "Az összes követett fájl naprakész.",
    "hash_missing": "—",
    "orphaned_title": "Nem követett helyi fájlok",
    "orphaned_none": "Nem észleltek extra helyi fájlok."
  },
  "schema": {
    "description": "JSON Séma a Hootsight config.json számára - meghatározza a típusokat, tartományokat és hierarchikus struktúrát minden konfigurálható beállításhoz",
    "general_description": "Általános alkalmazás beállítások",
    "general_language_description": "UI nyelv kód",
    "api_description": "API szerver konfiguráció",
    "api_host_description": "API szerver host",
    "api_port_description": "API szerver port",
    "ui_description": "Felhasználói felület beállítások",
    "ui_title_description": "Alkalmazás ablak címsor",
    "ui_width_description": "Ablak szélesség pixelben",
    "ui_height_description": "Ablak magasság pixelben",
    "ui_resizable_description": "Hogy az ablak átméretezhető-e",
    "system_description": "Rendszer-szintű beállítások",
    "system_max_threads_description": "Maximális szálak száma",
    "system_fallback_batch_size_description": "Tartalék köteg méret amikor az auto-számítás sikertelen",
    "system_memory_cleanup_interval_description": "Memória tisztítás intervallum másodpercben",
    "system_thread_pool_timeout_description": "Szál pool időtúllépés másodpercben",
    "system_startup_wait_seconds_description": "Indítási várakozási idő másodpercben",
    "memory_description": "Memória kezelési beállítások",
    "memory_target_memory_usage_description": "Cél memória használat arány (0.0-1.0)",
    "memory_safety_margin_description": "Biztonsági margó memória számításokhoz (0.0-1.0)",
    "memory_augmentation_threads_description": "Szálak száma adat augmentációhoz",
    "training_description": "Tanítási konfiguráció",
    "training_model_type_description": "Használandó modell típusa",
    "training_model_name_description": "Specifikus modell név",
    "training_pretrained_description": "Inicializálja a hálózatot ImageNet előtanított súlyokkal amikor elérhető; tiltsd le a nulláról való tanításhoz",
    "training_task_description": "Gépi tanulási feladat típusa",
    "training_batch_size_description": "Köteg méret tanításhoz",
    "training_epochs_description": "Tanítási epochok száma",
    "training_learning_rate_description": "Tanulási ráta",
    "training_weight_decay_description": "Súly csökkenés (L2 regularizáció)",
    "training_input_size_description": "Négyzetes bemeneti tenzor élhossza pixelben (konzisztensnek kell maradnia az augmentációs átméretezéssel)",
    "training_normalize_description": "Kép normalizációs paraméterek",
    "training_normalize_mean_description": "Átlag értékek RGB csatornákhoz",
    "training_normalize_std_description": "Szórás értékek RGB csatornákhoz",
    "training_val_ratio_description": "Validációs split arány (0.0-1.0)",
    "training_dataloader_description": "DataLoader konfiguráció",
    "training_dataloader_num_workers_description": "Munkás folyamatok száma",
    "training_dataloader_pin_memory_description": "Hogy memória kitűzése gyorsabb GPU átvitelhez",
    "training_dataloader_persistent_workers_description": "Hogy a munkások életben maradjanak-e epochok között",
    "training_dataloader_prefetch_factor_description": "Előre lehívott kötegek száma munkásonként",
    "training_augmentation_description": "Adat augmentációs konfiguráció",
    "training_augmentation_train_description": "Tanítási augmentációk",
    "training_augmentation_val_description": "Validációs augmentációk",
    "training_optimizer_type_description": "Optimalizáló típusa",
    "training_optimizer_lr_description": "Optimalizáló tanulási ráta",
    "training_optimizer_weight_decay_description": "Optimalizáló súly csökkenés",
    "training_scheduler_type_description": "Tanulási ráta scheduler típusa",
    "training_scheduler_step_size_description": "Lépés méret step_lr schedulerhez",
    "training_scheduler_gamma_description": "Gamma step_lr schedulerhez",
    "training_loss_type_description": "Veszteségfüggvény típusa",
    "training_loss_reduction_description": "Veszteség redukciós módszer",
    "training_weight_init_description": "Súly inicializációs konfiguráció",
    "training_checkpoint_description": "Ellenőrzőpont konfiguráció",
    "training_early_stopping_description": "Korai leállítás konfiguráció",
    "training_gradient_description": "Gradiens konfiguráció",
    "training_runtime_description": "Futásidejű teljesítmény optimalizálási beállítások",
    "training_runtime_mixed_precision_description": "Automatikus vegyes pontosságú tanítás engedélyezése",
    "training_runtime_channels_last_description": "Csatornák-utolsó memória formátum használata jobb GPU kihasználáshoz",
    "training_runtime_allow_tf32_description": "TF32 engedélyezése gyorsabb mátrix műveletekhez Ampere+ GPU-kon",
    "training_runtime_cudnn_benchmark_description": "cuDNN benchmark engedélyezése optimalizált konvolúciós algoritmusokhoz",
    "dataset_description": "Adathalmaz konfiguráció",
    "dataset_image_extensions_description": "Támogatott képfájl kiterjesztések",
    "optimizers_description": "Optimalizáló alapértelmezett felülírások",
    "optimizers_defaults_description": "Alapértelmezett paraméterek optimalizálókhoz",
    "schedulers_description": "Scheduler alapértelmezett felülírások",
    "schedulers_defaults_description": "Alapértelmezett paraméterek schedulerekhez",
    "schedulers_defaults_lambda_lr_lr_lambda_description": "Lambda függvény stringként, pl. 'lambda epoch: 0.95 ** epoch'",
    "schedulers_defaults_multiplicative_lr_lr_lambda_description": "Lambda függvény stringként, pl. 'lambda epoch: 0.95'",
    "losses_description": "Veszteség alapértelmezett felülírások",
    "losses_defaults_description": "Alapértelmezett paraméterek veszteségfüggvényekhez",
    "models_description": "Modell konfigurációk",
    "models_resnet_description": "ResNet modell család beállításai",
    "models_resnet_variants_description": "ResNet változatok konfigurációja",
    "models_resnext_description": "ResNeXt modell család beállításai",
    "models_resnext_variants_description": "ResNeXt változatok konfigurációja",
    "models_mobilenet_description": "MobileNet modell család beállításai",
    "models_mobilenet_variants_description": "MobileNet változatok konfigurációja",
    "models_shufflenet_description": "ShuffleNet modell család beállításai",
    "models_shufflenet_variants_description": "ShuffleNet változatok konfigurációja",
    "models_squeezenet_description": "SqueezeNet modell család beállításai",
    "models_squeezenet_variants_description": "SqueezeNet változatok konfigurációja",
    "models_efficientnet_description": "EfficientNet modell család beállításai",
    "models_efficientnet_variants_description": "EfficientNet változatok konfigurációja",
    "models_supported_types_description": "Támogatott modell típusok",
    "general_language_enum_descriptor": {
      "en": "Angol nyelv - Szabályozza az egész felhasználói felület lokalizációját beleértve a menü címkéket, hibaüzeneteket, tooltip-eket és validációs szöveget. Befolyásolja az összes szöveg renderelést a web felületen és API válaszokban. Meghatározza a nyelv csomag betöltését alkalmazás indításkor. Jelenleg ez az egyetlen támogatott nyelv opció, így ez az alapértelmezett minden telepítéshez."
    },
    "system_max_threads_enum_descriptor": {
      "auto": "Automatikus szál szám - Dinamikusan számítja ki az optimális szál pool méretet az elérhető CPU magok alapján (általában magok - 1). Befolyásolja a párhuzamos adat betöltést, kép előfeldolgozást, modell következtetési köteg kezelést és egyidejű HTTP kérés kezelést. Szabályozza a szál kiosztást PyTorch DataLoader munkásokhoz, kép augmentációs pipeline-okhoz és konkurens HTTP kérés kezeléshez. Automatikusan skálázódik a hardver képességeivel és igazodik az elérhető rendszer memória alapján."
    },
    "memory_augmentation_threads_enum_descriptor": {
      "auto": "Automatikus augmentációs szál szám - Számítja ki az optimális szál számot párhuzamos kép augmentációhoz CPU magok és elérhető RAM alapján. Befolyásolja a kép transzformációs pipeline teljesítményét beleértve a forgatást, skálázást, szín remegést és normalizálást. Szabályozza a memória kiosztást augmentációs pufferekhez és köztes kép tároláshoz. Kiegyenlíti a CPU kihasználtságot a memória nyomás ellen a intenzív előfeldolgozási fázisokban."
    },
    "training_model_type_enum_descriptor": {
      "resnet": "ResNet (Reziduális Hálózat) - Mély konvolúciós neurális hálózat skip kapcsolatokkal a mély hálózatok tanításának engedélyezésére (18-152 réteg). Befolyásolja a gradiens áramlást, tanítási stabilitást, jellemző reprezentációs mélységet és modell kapacitást. Használ reziduális blokkokat batch normalizációval és ReLU aktivációval. Szabályozza az architekturális komplexitást 11M paramétertől (ResNet-18) 60M paraméterig (ResNet-152). Befolyásolja a memória használatot, tanítási időt, következtetési sebességet és végső modell pontosságot kép osztályozási feladatokban.",
      "resnext": "ResNeXt (Aggregált Reziduális Transzformációk) - ResNet evolúció kardinalitással (csoportosított konvolúciók) a modell kapacitás növelésére anélkül, hogy jelentősen növelné a paraméter számot. Befolyásolja a jellemző tanulási sokféleséget, modell expresszivitást és számítási hatékonyságot. Szabályozza a párhuzamos transzformációs utakat minden reziduális blokkban. Befolyásolja a GPU memória használatot, tanítási időtartamot és magasabb pontosságot ér el mint a standard ResNet hasonló számítási költséggel.",
      "mobilenet": "MobileNet - Könnyű CNN depthwise elkülönített konvolúciókkal a modell méret és számítási követelmények csökkentésére. Befolyásolja a következtetési késleltetést, energia fogyasztást, modell tárolási méretet és telepítési megvalósíthatóságot mobil eszközökön. Szabályozza a pontosság és hatékonyság közötti kompromisszumot szélesség szorzóval és felbontás paraméterekkel. Befolyásolja az akkumulátor élettartamot mobil alkalmazásokban, valós idejű feldolgozási képességet és edge eszköz kompatibilitást.",
      "shufflenet": "ShuffleNet - Rendkívül hatékony CNN csatorna keverési műveletekkel és pointwise csoport konvolúciókkal. Befolyásolja a memória sávszélesség kihasználtságot, következtetésenkénti számítási költséget, modell méretet és feldolgozási sebességet. Szabályozza a csatorna kommunikációt csoport konvolúciók között az információ áramlás fenntartásához. Optimalizált ARM processzorokhoz és alacsony energia fogyasztású eszközökhöz. Befolyásolja a valós idejű teljesítmény követelményeket és erőforrás-korlátozott telepítési forgatókönyveket.",
      "squeezenet": "SqueezeNet - Ultra-kompakt CNN Fire modulokkal (squeeze + expand rétegek) AlexNet-szintű pontosság elérésére 50x kevesebb paraméterrel. Befolyásolja a modell tárolási követelményeket, letöltési időt, gyorsítótár hatékonyságot és telepítési sávszélességet. Szabályozza a paraméter számot agresszív dimenzió csökkentéssel követett expanzióval. Minimalizálja a lemez lábnyomot miközben elfogadható pontosságot tart fenn alapvető osztályozási feladatokhoz.",
      "efficientnet": "EfficientNet - Összetett skálázás CNN neurális architektúra kereséssel egységesen skálázva hálózat mélység, szélesség és felbontás lambda együtthatóval. Befolyásolja a számítási hatékonyságot, pontosság skálázást, tanítási erőforrás követelményeket és következtetés optimalizálást. Szabályozza a modell komplexitást összetett együtthatóval amely egyszerre kiegyenlíti mindhárom dimenziót. Kiváló pontosság-hatékonyság kompromisszumokat biztosít a hagyományos skálázási módszerekhez képest."
    },
    "training_task_enum_descriptor": {
      "classification": "Egycímkés Osztályozás - Pontosan egy kölcsönösen kizáró osztály címkét rendel minden bemeneti képhez. Befolyásolja a végső réteg architektúrát (softmax aktiváció), veszteségfüggvény kiválasztást (kategorikus kereszt-entrópia), kimeneti dimenzionalitást (osztályok száma) és előrejelzési bizalom interpretációját. Szabályozza a modell döntési határait, osztály valószínűség eloszlást és tanítási konvergencia mintákat. Optimális teljesítményhez kiegyensúlyozott adathalmaz eloszlás és tiszta osztály elkülöníthetőség szükséges.",
      "multi_label": "Többcímkés Osztályozás - Egyidejűleg nulla, egy vagy több nem kizáró osztály címkét rendel minden bemeneti képhez. Befolyásolja a kimeneti réteg aktivációját (sigmát osztályonként), veszteségfüggvény kompozíciót (bináris kereszt-entrópia osztályonként), pozitív előrejelzések küszöb kiválasztását és kiértékelési metrikákat (F1-score, mAP). Szabályozza a független osztály előrejelzési utakat, címke korreláció kezelést és kiegyensúlyozatlan osztály súly stratégiákat. Kezeli a komplex valós világ forgatókönyveket ahol képek több szemantikus koncepciót tartalmaznak.",
      "detection": "Objektum Detektálás - Egyidejűleg lokalizál és osztályoz több objektum példányt képeken bounding box előrejelzésekkel. Befolyásolja a modell architektúra komplexitását (feature piramis hálózatok, anchor generálás), veszteségfüggvény kompozíciót (osztályozás + bounding box regresszió), tanítási adat követelményeket (annotált bounding box-ok), utófeldolgozási pipeline-t (nem-maximum elnyomás) és számítási terhelést. Szabályozza a térbeli jellemző extrakció mélységét, multi-skála objektum felismerést, régió javaslat mechanizmusokat és intersection-over-union számításokat.",
      "segmentation": "Szemantikus Szekmentálás - Sűrű pixel-szintű osztályozást hajt végre minden pixelhez szemantikus osztály címkék hozzárendelésével a bemeneti képben. Befolyásolja a memória követelményeket (teljes felbontású jellemző térképek), modell architektúrát (encoder-decoder skip kapcsolatokkal), veszteségfüggvény dizájnt (pixel-szintű kereszt-entrópia, focal loss osztály egyensúlytalanságra), tanítási komplexitást (osztály egyensúlytalanság kezelése pixel szinten) és kimeneti felbontás korlátozásokat. Szabályozza az upsampling stratégiákat, határ finomítás minőségét, térbeli pontosságot és kontextuális érvelési képességeket."
    },
    "training_epochs_enum_descriptor": {
      "auto": "Automatikus epoch meghatározás - Figyeli a validációs veszteség és pontosság trendeket optimális tanítási időtartam meghatározására korai leállítás kritériumokkal. Befolyásolja a teljes tanítási időt, modell konvergencia minőségét, számítási erőforrás használatát és túltanulás megelőzést. Követi a validációs metrika javulásokat türelem periódusokon keresztül és automatikusan leállítja a tanítást amikor nincs jelentős előrehaladás észlelhető. Kiegyenlíti a tanítási alaposágot a számítási hatékonysággal."
    },
    "training_optimizer_type_enum_descriptor": {
      "sgd": "Sztochasztikus Gradiens Descent - Determinisztikus gradiens lépés opcionális lendülettel és Nesterov lookahead-del. Kiteti learning_rate, momentum, dampening és weight_decay mint kritikus gombokat. Legjobban akkor működik amikor előre megtervezhetsz egy schedulert és szoros kontrollt akarsz a generalizáció felett. Erős eredményeket várj nagy vision adathalmazokon amikor párosítod koszinusz vagy lépéses csökkenéssel, de készülj fel a momentum hangolására (0.9 tipikus kiindulási pont) és tartsd a tanulási rátákat 0.01-0.1 között a köteg méret függvényében.",
      "adam": "Adam Optimalizáló - Adaptív elsőrendű módszer mozgó átlagokkal a gradienseknek (beta1) és négyzetes gradienseknek (beta2). Alapértelmezett beta-k 0.9/0.999 és eps 1e-8 illik legtöbb munkaterheléshez. Kezeli a zajos vagy ritka gradienseket manuális tanulási ráta skálázás nélkül, ami megbízható alapot tesz transfer tanuláshoz és osztályozáshoz. Figyelj a lassú konvergenciára ha weight decay kapcsolódik Adam adaptív frissítéseihez; fontold meg AdamW-t amikor regularizáció számít.",
      "adamw": "AdamW Optimalizáló - Elválasztja a weight decay-t Adam adaptív frissítéseitől hogy L2 regularizáció megfelelően viselkedjen. Tartja ugyanazokat a beta paramétereket és epsilon alapértelmezéseket mint Adam miközben weight_decay-t igazi regularizátorként teszi ki. Előnyben részesített transformer-ek finomhangolásához, ResNet finomhangoláshoz vagy bármely modellhez ahol törődsz a stabil tanítással és megjósolható generalizációval. Kezdd weight_decay körülbelül 0.01-gyel és hangold tanulási_rátát 3e-5 és 3e-4 között transfer tanuláshoz.",
      "adamax": "AdaMax Optimalizáló - Adam variáns végtelen norma használatával második momentum követéshez. Hasonló hiperparaméterek Adam-hez, de rugalmasabb amikor gradiensek szórványosan ugranak. Hasznos amikor Adam instabillá válik extrém gradiens nagyságok miatt, különösen GAN vagy reinforcement munkaterhelésekben. Tartsd beta2 közel 0.999-hez és kezeld tanulási_rátát standard Adam-ként; várj kissé lassabb konvergenciát de kevesebb katasztrofális ugrást.",
      "nadam": "Nesterov-gyorsított Adam - Hozzáad Nesterov lendületet Adam adaptív skálázására. Megosztja ugyanazokat a beta-kat és epsilon-t de előretekintő gradiens kiértékelést hajt végre, ami szűkítheti a sima objektívumok konvergenciáját. Tervezz kissé magasabb számítási terhelést lépésenként. Ajánlott amikor Adam konvergál de korán leáll; hangold tanulási_rátát kissé alacsonyabbra mint sima Adam (pl. 1e-4 helyett 3e-4) hogy elkerüld a túllépést.",
      "radam": "Rektifikált Adam - Adam automatikus warmup mechanizmussal származtatva variancia rektifikációból. Eltávolítja a manuális warmup ütemezés szükségességét variancia futó átlag stabilizálásáig. Hiperparaméterek megegyeznek Adam alapértelmezéseivel. Használd amikor adaptív viselkedésre van szükséged de tanításod érzékeny az első néhány száz lépésre. Jól működik kis adathalmazokon ahol manuális warmup túltanítana.",
      "rmsprop": "RMSprop Optimalizáló - Exponenciális átlagot tart fenn a négyzetes gradienseknek (alpha) normalizáláshoz frissítésekhez. Alapértelmezett alpha=0.99 és eps=1e-8. Történelmileg népszerű rekurrens hálózatokhoz és reinforcement tanuláshoz, még mindig jól teljesít amikor gradiensek erősen oszcillálnak és Adam túl agresszívnek tűnik. Párosítsd csökkenő tanulási_ráta ütemezéssel; tipikus kiindulási értékek körül 1e-3 momentum nélkül vagy alacsonyra állítva (≤0.1).",
      "rprop": "Rugalmas Visszafelé Propagáció - Jel-alapú optimalizáló paraméterenkénti lépés méretek adaptálásával gradiens jel fordulatokat használva. Nem veszi figyelembe köteg méretet mivel teljes köteg frissítéseket feltételez, így ritkán megfelelő mini-köteg CNN tanításhoz. Csak használatos determinisztikus beállításokban (pl. kis adathalmazok teljes köteg pass-okkal) ahol tiszta másodikrendű-szerű konvergenciát akarsz anélkül hogy Hessian-t tárolj. Hiperparaméterek eta_plus (1.2) és eta_minus (0.5) szabályozzák lépés adaptációt.",
      "adagrad": "AdaGrad Optimalizáló - Halmozott négyzetes gradienseket hogy csökkentse tanulási rátát gyakran frissített súlyokhoz. Majdnem karbantarthatatlan ritka jellemzőkön, de kumulatív összeg kényszeríti a hatékony tanulási rátát nulla felé hosszú futásokon. Használatos jellemző embeddings-hez vagy klasszikus ritka NLP problémákhoz, nem mély CNN-ekhez ami száz epoch-ot tanítanak. Tipikus kezdeti tanulási_ráta körül 1e-2 epsilon körül 1e-10 hogy elkerüld nullával való osztást.",
      "adadelta": "AdaDelta Optimalizáló - Javítja Adagrad-ot mozgó ablakkal a négyzetes gradienseknek hogy megakadályozza tanulási ráta eltűnését. Szükségtelenül kevés tuning rho (0.9) és eps (1e-6) mellett. Működik zajos objektívumokon ahol Adam túl agresszív, bár végső pontossága gyakran elmarad AdamW-tól. Inkább használd amikor nem kerülheted el manuális tanulási ráta ütemezéseket és még mindig adaptív viselkedésre van szükséged.",
      "sparse_adam": "Ritka Adam - Adam frissítésekkel csak azokra az indexekre ahol gradiensek érkeznek, csökkentve memória és számítást embedding táblákhoz. Használja ugyanazokat a hiperparamétereket mint Adam de feltételezi gradiensek majdnem mindenhol nullák. Lényeges nagy szókincsű NLP modellekhez. Hagyd ki sűrű konvolúciós modellekhez; ritka frissítés könyvelés csak pazarolja az időt.",
      "lbfgs": "L-BFGS Optimalizáló - Korlátozott memória kvázi-Newton módszer hogy közelítse az inverz Hessian-t múltbeli gradiensek használatával. Szükséges teljes köteg gradiensek és vonal keresés minden lépéshez, így minden lépés drága és memória növekszik történelem mérettel (max_iter és history_size szabályozza). Kiváló kis modellek finomhangolásához vagy konvex problémák megoldásához magas pontossággal. Nem életképes nagy mini-köteg tanításhoz mert minden lépés drága.",
      "asgd": "Átlagolt SGD - Futtó átlagot tart paramétereknek hogy csillapítsa az oszcillációkat zajos gradiensek okozta. Még mindig hangolod az alap SGD tanulási_rátát, de átlagolás bekapcsol a averaging_start epoch után hogy simítsa konvergenciát. Fontold meg amikor sima SGD himbálózik végén de nem akarsz Adam-ra váltani. Legjobban működik állandó vagy lassan csökkenő tanulási rátákkal és momentum kikapcsolva."
    },
    "training_scheduler_type_enum_descriptor": {
      "step_lr": "Lépéses Tanulási Ráta Scheduler - Szorozza tanulási rátát gamma-val minden step_size epoch után. Tökéletes amikor már tudod az epoch-okat ahol teljesítmény csökken (pl. 30/60/90 ImageNet-en). Válassz gamma-t 0.1 és 0.3 között és igazítsd step_size-t teljes epoch költségvetésedhez. Manuális tudás nélkül kissé hirtelennek érezhető, így figyeld validációs metrikákat hogy megerősítsd csökkenések segítenek.",
      "multi_step_lr": "Többlépéses Tanulási Ráta Scheduler - Generalizált lépés ütemezés elfogadva mérföldkő epoch-ok listáját. Lehetővé teszi több ráta csökkenés szakaszolását tetszőleges pontokon, ami ideális papírokból portolt ütemezésekhez vagy korábbi kísérletekből. Tartsd gamma-t azonos mérföldkő között hacsak nincs okod változtatni, és biztosítsd mérföldkövek szigorúan növekvő egész számok.",
      "exponential_lr": "Exponenciális Tanulási Ráta Scheduler - Alkalmaz lr_t = lr_0 * gamma^t, sima csökkenést adva cserébe gondos gamma tuningért. Működik nagyon hosszú futásokhoz ahol sima siklást akarsz nulla felé helyett diszkrét ugrásoknak. Tipikus gamma értékek ülnek 0.97 és 0.995 között per-epoch frissítésekhez. Kombináld warmup-pal ha kezdeti lejtő túl meredek modellhez.",
      "cosine_annealing_lr": "Koszinusz Annealing Tanulási Ráta Scheduler - Seper tanulási rátát le koszinusz görbe mentén T_max epoch felett opcionálisan újraindít eta_min-nél. Puha leszállásokat biztosít jobb végső pontosságért vision modellekben. Állítsd T_max-ot ciklus epoch-ok számára és eta_min-t kis alapnak mint lr_0 / 100. Használd amikor sima finomhangolást akarsz végén anélkül hogy manuális mérföldköveket.",
      "cosine_annealing_warm_restarts": "Koszinusz Annealing Meleg Újraindításokkal - Ismétel koszinusz csökkenés ciklusokat, visszaállít kezdeti tanulási rátára minden ciklus után. Nagyszerű sekély minimumokból való kilépéshez hosszú tanítási munkamenetekben. T_0 definiálja első ciklus hosszát, és T_mult skálázza következő ciklus hosszakat. Tartsd eta_min-t kicsi de nem nulla hogy elkerüld optimalizáló befagyását.",
      "reduce_lr_on_plateau": "Csökkentés LR Fennsíkon - Figyeli metrikát (általában validációs veszteség) és dob tanulási rátát factor-rel amikor javulás stagnál patience epoch-okig. Lényeges amikor nem jósolhatod stagnálás időzítését. Konfiguráld cooldown-t hogy elkerüld egymást követő triggereket és használd threshold-ot zajos metrikák szűréséhez. Gamma 0.1 és 0.5 között tipikusan üti meg a megfelelő egyensúlyt.",
      "cyclic_lr": "Ciklikus Tanulási Ráta Scheduler - Ciklikusan tanulási rátát base_lr és max_lr között rövid ablakokon, opcionálisan zsugorít amplitúdót mode használatával. Hasznos gyors konvergenciához kemény objektívumokon vagy LR tartomány tesztekhez. Állítsd step_size_up/down-ot iterációk számára fél ciklusonként; tartsd max_lr-t körülbelül 3-10× base_lr. Párosítsd momentum ciklikussal ha engedélyezed cycle_momentum.",
      "one_cycle_lr": "Egy Ciklus Tanulási Ráta Irányelv - Egyetlen söpör tanulási ráta fel max_lr-re majd le a base érték frakciójára miközben inverz lendületet. Gyors konvergenciát szállít amikor teljes tanítási lépések ismertek. Biztosíts total_steps-ot vagy (epochs × steps_per_epoch); állítsd pct_start-ot warmup arány definiálására (0.3 gyakori). Legjobban működik SGD-vel vagy AdamW-vel és vár teljes további schedulerek nélkül.",
      "polynomial_lr": "Polinomiális Tanulási Ráta Scheduler - Csökkenti tanulási rátát nulla felé következő (1 - t/T)^power. Válassz total_iters-t optimizer lépések számára ütemezésben és power-t görbület szabályozására (1 lineáris, 2 kvadratikus). Hasznos szegmentáláshoz és detektáláshoz ahol determinisztikus siklást akarsz nulla felé végső iterációig.",
      "linear_lr": "Lineáris Tanulási Ráta Scheduler - Egyszerű lineáris interpoláció start_factor és end_factor között total_iters lépésen keresztül. Ideális warmup (start_factor < 1) vagy cool-down fázisokhoz. Tartsd total_iters-t igazítva iterációk számára amiket ramp-nek akarsz fedni; kombináld másik scheduler-rel maradék tanításhoz.",
      "lambda_lr": "Lambda Tanulási Ráta Scheduler - Direkt horog hogy szorozza alap tanulási rátát egyedi lambda(epoch) függvényeddel. Teljes kontrollt ad kutatási ütemezésekhez vagy tanítási tanfolyamokhoz. Biztosíts Python kifejezést ami float-ot értékel; emlékezz string-ként értékelődik tanítási folyamatban. Validáld függvényt gondosan—syntax hibák vagy negatív kimenetek megölik futásod.",
      "multiplicative_lr": "Multiplikatív Tanulási Ráta Scheduler - Hasonló lambda_lr-hez de callable-t vár ami szorzót ad vissza lépésenként, gyakran epoch-alapú skálázáshoz. Biztosíts lambda-t ami optimizer lépés számtól függ helyett epoch-tól ha per-iteráció kontrollt akarsz. Tartsd szorzókat pozitív és korlátozott; értékek >1 növelik tanulási rátát és destabilizálhatják tanítást gyorsan."
    },
    "training_loss_type_enum_descriptor": {
      "cross_entropy": "Kereszt-Entrópia Veszteség - Softmax + negatív log-likelihood egy hívásban. Menj ehhez egycímkés osztályozáshoz. Elfogad nyers logit-okat, kezeli osztály egyensúlytalanságot súly vagy label_smoothing-gal, és kalibrált valószínűségeket ad. Tartsd reduction='mean'-t stabil gradiensekért és figyeld label_smoothing-ot hogy ne töröld kisebbségi osztályokat.",
      "nll_loss": "Negatív Log-Likelihood Veszteség - Ugyanaz a matek mint kereszt-entrópia de log_softmax-ot hívod magadnak. Hasznos amikor modell már log-valószínűségeket ad ki (pl. egyedi hőmérséklet skálázás vagy manuális vegyes pontosság). Biztosítsd bemenetek log valószínűségek; nyers logit-ok csendes szemétté teszik.",
      "bce_loss": "Bináris Kereszt-Entrópia Veszteség - Működik valószínűségeken [0,1], párosítsd explicit sigmoid-del. Megfelelő bináris osztályozáshoz amikor kontrollálni akarod aktivációt külön. Vigyázz numerikus underflow-ra extrém logit-okon—klippeld bemeneteket vagy válts BCEWithLogitsLoss-ra ha NaN-okat látsz.",
      "bce_with_logits": "Bináris Kereszt-Entrópia Logit-ekkel - Numerikusan stabil BCE sigmoid-ot alkalmazva belülről. Alapértelmezett többcímkés osztályozáshoz és bináris feladatokhoz. Támogat pos_weight-ot osztály egyensúlytalanság nélkül manuális súlyozás trükkök. Kimenet korlátlan veszteség ha elfelejted célokat {0,1}-re klippelni.",
      "multi_margin": "Többosztályos Margó Veszteség - Margó-alapú osztályozási objektívum (hinge-stílusú) hogy helyes pontszámot toljon többi fölé margóval. Opcionális L1 vagy L2 normák p paraméterrel. Használd amikor nagy-margó viselkedést akarsz helyett valószínűségi kereszt-entrópia, de vedd figyelembe lassabb konvergenciát nélkül gondos tanulási ráta kontroll.",
      "multi_label_margin": "Többcímkés Margó Veszteség - Kiterjeszti margó veszteséget többcímkés problémákra pozitív osztályokat tolva negatívok fölé. Szükséges célokat index listákként kódolni és ezért trükkös sűrű címke tenzorokkal integrálni. Fenntartsd kutatási forgatókönyvekhez ahol explicit margó rangsorolást hívsz többcímkés térben.",
      "multi_label_soft_margin": "Többcímkés Puha Margó Veszteség - Alkalmaz puha-margó formulációt sigmoid aktivációkon keresztül, simább gradienseket adva mint kemény margó veszteségek. Jobb átfedő címkék kezelésére és egyensúlytalanságra. Célok még mindig {0,1}; fontold küszöb tuning-ot következtetéskor hogy kihasználd simább tanítási tájat.",
      "mse_loss": "Átlagos Négyzetes Hiba Veszteség - Klasszikus L2 büntetés. Bünteti nagy hibákat kvadratikusan, ami kiemeli outlier-eket hatását. Nagyszerű autoencoder-ekhez és alacsony-zaj regresszióhoz, de fontold klippelést extrém célokhoz vagy Huber-ra váltást ha gradiens robbanásokat látsz.",
      "l1_loss": "L1 Veszteség (Átlagos Abszolút Hiba) - Lineáris büntetés abszolút hibára, robusztusságot adva outlier-ekhez csökkentett konvergencia sebességgel. Használd amikor medián-szerű viselkedést akarsz vagy amikor kiértékelési metrikád MAE. Gradiensek állandó magnitúdójúak, így párosítsd sima scheduler-ekkel hogy elkerüld remegést.",
      "smooth_l1": "Sima L1 Veszteség - Huber-stílusú veszteség beta régióval hogy L2-szerű legyen nulla közel és L1 kívül. Alapértelmezett bounding-box regresszióhoz (beta ≈ 1). Hangold beta-t ha skálád jelentősen különbözik; kisebb beta szűkíti kvadratikus ablakot és élesebb büntetéseket ad középső hibákhoz.",
      "huber_loss": "Huber Veszteség - Hasonló SmoothL1-hez de delta-val parametriza helyett beta. Explicit kontrollt ad switch pont felett kvadratikus és lineáris büntetések között. Kiváló regressziós feladatokhoz alkalmi outlier-ekkel; állítsd delta-t várt zaj standard deviációjához közel.",
      "kl_div": "Kullback-Leibler Divergencia Veszteség - Méri divergenciát prediktált és cél eloszlás között. Szükséges log-valószínűségek bemenetként és nyers valószínűségek célként alapértelmezésben (vagy fordítva log_target-rel). Lényeges tudás desztillációhoz és variációs modellekhez. Kettős check reduction mód; 'batchmean' megőrzi KL elméletet (osztás osztályokon keresztül és átlagolás kötegen).",
      "margin_ranking": "Margó Rangsorolás Veszteség - Működik pontszám párokon (x1, x2) földrajzi rendezéssel y ∈ {−1, 1}. Tanítja modellt hogy rangsorolja x1-et x2 fölé margóval amikor y=1. Kombináld gondos mintavételezéssel pozitív/negatív párok vagy triplet-ek—véletlen párok ritkán adnak hasznos jelet.",
      "hinge_embedding": "Hinge Beágyazás Veszteség - Hasonlóság tanuláshoz ahol címkék jelzik hogy párok közel vagy távol legyenek (+1) vagy (−1). Bünteti távolságokat ami megsérti meghatározott margót. Használd amikor csak bináris azonos/különböző felügyeletet kapsz és beágyazásokat akarsz klaszterezni aszerint.",
      "triplet_margin": "Triplet Margó Veszteség - Fogyaszt anchor, pozitív és negatív beágyazásokat és kikényszerít margót pozitív és negatív távolságok között. Szükséges kemény vagy félig-kemény triplet bányászat hogy ragyogjon; naiv véletlen triplet-ek általában pazarolják számítást. Margó alapértelmezik 1.0-ra de hangold beágyazás skálád alapján (kisebb normalizált vektorokhoz).",
      "cosine_embedding": "Koszinusz Beágyazás Veszteség - Közvetlenül optimalizálja koszinusz hasonlóságot, hangsúlyozva szög távolságot helyett magnitúdót. Ideális amikor vektorok normalizáltak vagy amikor irány hordozza szemantikát (pl. arc felismerés). Biztosítsd beágyazások normalizálását hogy elkerüld magnitúd effektusok visszaáramlását.",
      "ctc_loss": "Connectionist Temporal Classification Veszteség - Igazít változó hosszúságú bemeneteket cél címke szekvenciákhoz frame-szintű annotáció nélkül. Szükséges log-valószínűségek (T, N, C) méretben és cél szekvenciák üres nélkül beszúrva (veszteség kezeli üreseket). Konfiguráld üres indexet és biztosítsd célokat rendezve minta szerint; méreteltelen cél hosszúságok futásidejű hibákat dobnak.",
      "poisson_nll": "Poisson Negatív Log-Likelihood Veszteség - Szám adat modellezéséhez ahol célok nem-negatív egész számok. Elfogad log_input hogy pozitív predikciókat kényszerítsen vagy teljes logit-okat clamp-pel nulla fölé. Állítsd full=True ha modell nyers rátákat prediktál. Ne etesd negatív célokkal; eloszlás feltételezése azonnal megszakad.",
      "gaussian_nll": "Gauss Negatív Log-Likelihood Veszteség - Tanít modellt hogy prediktáljon átlagot és varianciát folyamatos célokhoz. Várja modellt hogy visszaadjon (átlag, variancia) tenzorokat. Támogat teljes kovarianciát cholesky_factor-rel; különben variancia pozitív kell maradjon. Nagyszerű uncertainty-aware regresszióhoz; adj kis epsilon-t varianciához hogy elkerüld log(0) problémákat."
    },
    "training_loss_reduction_enum_descriptor": {
      "mean": "Átlag Redukció - Számítja átlag veszteséget összes köteg elem felett veszteség osztásával köteg mérettel. Befolyásolja gradiens magnitúdó normalizálást, köteg méret függetlenséget, tanítási stabilitást és tanulási ráta érzékenységet. Szabályozza veszteség skálázást hogy konzisztens gradienseket biztosítson függetlenül köteg méret variációktól. Standard választás legtöbb tanítási forgatókönyvhöz mivel gradienseket arányosítja egyéni minta hibákhoz helyett köteg méret.",
      "sum": "Összeg Redukció - Számítja teljes veszteséget összes egyéni minta veszteség összegzésével normalizálás nélkül. Befolyásolja gradiens magnitúdó skálázást, köteg méret függőséget, tanulási ráta követelményeket és tanítási dinamikát. Szabályozza veszteség akkumulációt ami nagyobb gradienseket eredményez nagyobb kötegekhez, tanulási ráta igazítás szükséges köteg méret arányosan. Hasznos amikor gradiens magnitúdót akarod skálázni feldolgozott minták számával.",
      "none": "Nincs Redukció - Visszaad egyéni veszteség értékeket minden minta számára kötegben aggregáció nélkül. Befolyásolja egyedi veszteség súlyozás képességeit, minta-specifikus elemzést, manuális veszteség kombinációt és fejlett tanítási stratégiákat. Szabályozza egyéni minta veszteség hozzáférést hogy lehetővé tegye egyedi súlyozás, szűrés vagy részletes veszteség vizsgálat. Lényeges fejlett alkalmazásokhoz ahol per-minta veszteség manipuláció szükséges."
    },
    "training_early_stopping_monitor_enum_descriptor": {
      "val_loss": "Validációs Veszteség Figyelés - Korai leállítás mechanizmus hogy követi validációs veszteség értékeket optimális tanítási termináció meghatározására veszteség fennsík miatt. Befolyásolja túltanulás megelőzést, tanítási időtartam optimalizálást, modell generalizációs minőségét és számítási erőforrás használatát. Szabályozza tanítási terminációt veszteség stagnálás alapján, ami tipikusan azt jelzi hogy modell megtanulta generalizálható mintákat és további tanítás túltanuláshoz vezethet. Különösen hatékony regressziós feladatokhoz és helyzetekhez ahol veszteség minimalizálás közvetlenül korrelál modell minőségével.",
      "val_accuracy": "Validációs Pontosság Figyelés - Korai leállítás mechanizmus hogy követi validációs pontosság metrikákat optimális tanítási terminációs pont meghatározására. Befolyásolja modell teljesítmény optimalizálást, túltanulás detektálást, tanítási hatékonyságot és végső modell minőségét. Szabályozza tanítási megállást pontosság fennsík alapján, fókuszálva osztályozási teljesítményre helyett veszteség minimalizálásra. Legmegfelelőbb kiegyensúlyozott osztályozási feladatokhoz ahol pontosság elsődleges siker metrika és jól korrelál modell generalizációs képességével."
    },
    "optimizers_defaults_lbfgs_line_search_fn_oneOf[1]_enum_descriptor": {
      "strong_wolfe": "Erős Wolfe Vonal Keresés - Fejlett vonal keresési algoritmus L-BFGS optimalizáláshoz hogy biztosítsa megfelelő csökkenést (Armijo feltétel) és görbület feltételeket (erős Wolfe feltételek). Befolyásolja optimalizálási konvergencia minőségét matematikai optimalitási kritériumok biztosításával megfelelő lépés méretekhez. Szabályozza lépés hossz kiválasztást rigorózus matematikai feltételek által hogy biztosítsa konvergencia tulajdonságokat miközben fenntartja számítási hatékonyságot. Lényeges L-BFGS elméleti garanciákhoz és robusztos lépés méret kiválasztás kvázi-Newton optimalizálási módszerekhez."
    },
    "schedulers_defaults_reduce_lr_on_plateau_mode_enum_descriptor": {
      "min": "Minimum Mód - Figyeli metrikákat ahol alacsonyabb értékek jelzik jobb teljesítményt (mint validációs veszteség). Befolyásolja tanulási ráta csökkentés trigger-t hogy követi mikor monitorozott metrika nem csökken tovább küszöb alatt meghatározott türelem epoch-okig. Szabályozza scheduler viselkedést hogy csökkentse tanulási rátát veszteség fennsík esetén, megelőzve tanítási stagnálást. Optimális veszteség-alapú monitorozáshoz ahol csökkenő értékek képviselik tanítási előrehaladást.",
      "max": "Maximum Mód - Figyeli metrikákat ahol magasabb értékek jelzik jobb teljesítményt (mint validációs pontosság). Befolyásolja tanulási ráta csökkentés trigger-t hogy követi mikor monitorozott metrika nem növekszik tovább küszöb fölött meghatározott türelem epoch-okig. Szabályozza scheduler viselkedést hogy csökkentse tanulási rátát pontosság fennsík esetén, lehetővé téve további finomhangolást. Optimális pontosság-alapú monitorozáshoz ahol növekvő értékek képviselik tanítási előrehaladást."
    },
    "schedulers_defaults_reduce_lr_on_plateau_threshold_mode_enum_descriptor": {
      "rel": "Relatív Küszöb Mód - Meghatározza javulás küszöböt százalékban aktuális legjobb metrika értékéből. Befolyásolja javulás érzékenységét hogy követel arányos változásokat relatív aktuális teljesítmény szinthez. Szabályozza adaptív küszöb skálázást ami szigorúbbá válik ahogy modell teljesítmény javul. Hasznos amikor javulás magnitúdó skáláznia kell aktuális metrika értékekkel, megelőzve korai tanulási ráta csökkentést magas teljesítményű modellekben.",
      "abs": "Abszolút Küszöb Mód - Meghatározza javulás küszöböt fix abszolút értékként ami túllépendő függetlenül aktuális metrika szinttől. Befolyásolja javulás detektálás érzékenységét állandó követelményekkel függetlenül aktuális teljesítménytől. Szabályozza egységes javulás standardokat egész tanítás során függetlenül metrika magnitúdótól. Hasznos amikor konzisztens javulás szintek szükségesek függetlenül aktuális modell teljesítmény állapotától."
    },
    "schedulers_defaults_cyclic_lr_mode_enum_descriptor": {
      "triangular": "Háromszög Ciklus Mód - Konstans amplitúdóval hoz létre alap háromszög tanulási ráta ciklusokat egész tanítás során. Befolyásolja tanulási ráta oszcillációs mintát lineáris növekedésekkel és csökkenésekkel base_lr és max_lr határok között. Szabályozza konzisztens felfedezés-kihasználás egyensúlyt fix tanulási ráta tartománnyal. Egyszerű ciklikus tanulási ráta minták megfelelő tanulási ráta tartományok megtalálásához anélkül hogy csökkenés.",
      "triangular2": "Háromszög2 Ciklus Mód - Háromszög tanulási ráta ciklusokat hoz létre amplitúdó felezéssel minden teljes ciklus után. Befolyásolja tanulási ráta tartomány csökkenést idővel miközben fenntartja háromszög oszcillációs mintát. Szabályozza fokozatos tanulási ráta csökkenést ciklikus keretben, kombinálva ciklikusság előnyeit progresszív finomítással. Lehetővé teszi agresszív kezdeti felfedezést egyre konzervatívabb tanulási ráta igazításokkal.",
      "exp_range": "Exponenciális Tartomány Mód - Gamma faktor használatával exponenciálisan skálázza tanulási ráta ciklus amplitúdót dinamikus tartomány igazításhoz. Befolyásolja tanulási ráta határ módosítást exponenciális skálázással max_lr relatív ciklus számhoz. Szabályozza kifinomult amplitúdó evolúciót ami növelheti vagy csökkentheti ciklus magnitúdót gamma érték alapján. Fejlett ciklikus tanulási ráta minták exponenciális amplitúdó modulációval."
    },
    "schedulers_defaults_cyclic_lr_scale_mode_enum_descriptor": {
      "cycle": "Ciklus-alapú Skálázás Mód - Skálázási függvényt alkalmaz ciklus számon alapulva helyett egyéni iterációs lépések. Befolyásolja skálázási függvény kiértékelés gyakoriságát és tanulási ráta amplitúdó módosítás ritmusát. Szabályozza skálázás alkalmazást ciklus határokon, lehetővé téve különböző amplitúdó igazításokat minden teljes tanulási ráta ciklusra. Hasznos amikor skálázási viselkedés diszkréten változzon ciklusok között helyett folyamatosan tanítás során.",
      "iterations": "Iteráció-alapú Skálázás Mód - Skálázási függvényt alkalmaz teljes iterációs számon alapulva tanítás kezdetétől, folyamatos skálázási evolúciót biztosítva. Befolyásolja skálázási függvény kiértékelést minden lépésben, lehetővé téve sima amplitúdó átmeneteket tanítási folyamat során. Szabályozza finom skálázás alkalmazást helyett ciklus határ diszkrét igazításokat. Hasznos amikor fokozatos, folyamatos skálázási változások előnyben részesítettek."
    },
    "schedulers_defaults_one_cycle_lr_anneal_strategy_enum_descriptor": {
      "cos": "Koszinusz Annealing Stratégia - Sima tanulási ráta átmenetekhez koszinusz függvény használatával fokozatos változásokkal extrémeken és meredekebb változásokkal középen. Befolyásolja tanulási ráta pálya simaságát hogy biztosítsa természetes gyorsítás és lassítás fázisokat. Szabályozza szinuszoidális tanulási ráta evolúciót ami emlékeztet természetes optimalizálási dinamikákra. Különösen hatékony sima konvergencia eléréséhez csökkentett oszcillációkkal tanulási ráta határok közelében.",
      "linear": "Lineáris Annealing Stratégia - Konstans ráta tanulási ráta változásokhoz lineáris interpolációval gyorsítás vagy lassítás fázisok nélkül. Befolyásolja tanulási ráta átmeneteket egyenletes progresszióval változás sebesség nélkül. Szabályozza megjósolható, állandó tanulási ráta evolúciót konzisztens változás sebességgel. Egyszerűbb alternatíva amikor sima koszinusz átmenetek nem szükségesek és egyenletes tanulási ráta progresszió előnyben részesített."
    },
    "losses_defaults_multi_margin_p_enum_descriptor": {
      "1": "L1 Norma (Manhattan Távolság) - Abszolút különbségeket használ margó kalkulációhoz multi-margin veszteség függvényben. Befolyásolja veszteség kalkulációt lineáris büntetéssel ami egyenletesen kezeli minden hibát függetlenül magnitúdótól. Szabályozza távolság mérés összeg abszolút különbségekkel prediktált és cél értékek között. Robusztosabb margó kalkulációt biztosít kevésbé érzékeny outlier-ekre mint L2 norma, megfelelő amikor tanítási adat jelentős zajt vagy extrém értékeket tartalmaz.",
      "2": "L2 Norma (Euklideszi Távolság) - Négyzetes különbségeket használ margó kalkulációhoz multi-margin veszteség függvényben. Befolyásolja veszteség kalkulációt kvadratikus büntetéssel ami erősen bünteti nagyobb hibákat miközben engedékeny kisebbekkel szemben. Szabályozza távolság mérés összeg négyzetes különbségekkel prediktált és cél értékek között. Sima gradiens karakterisztikákat biztosít és erős büntetést nagy margó megsértésekre, megfelelő tiszta adatokhoz ahol nagy hibák erősen büntetendők."
    },
    "losses_defaults_kl_div_reduction_enum_descriptor": {
      "none": "Nincs Redukció - Egyéni KL divergencia értékeket ad vissza minden minta számára aggregáció nélkül. Befolyásolja veszteség kimenet dimenzionalitását hogy megőrizze per-minta veszteség értékeket egyedi feldolgozáshoz vagy elemzéshez. Szabályozza egyéni minta veszteség hozzáférést lehetővé téve minta-specifikus súlyozás, szűrés vagy részletes veszteség vizsgálat. Lényeges fejlett tanítási stratégiákhoz ahol per-minta veszteség manipuláció szükséges.",
      "mean": "Átlag Redukció - Átlag KL divergenciát számít térbeli dimenziók beleértve batch dimenziót. Befolyásolja gradiens skálázást hogy normalizálja veszteség magnitúdót összes elem számával batch méret helyett. Szabályozza veszteség skálázást ami figyelembe veszi batch méretet és térbeli dimenziókat sűrű predikciós feladatokban. Biztosít konzisztens gradienseket függetlenül bemenet felbontástól vagy batch kompozíciótól.",
      "sum": "Összeg Redukció - Teljes KL divergenciát számít összes egyéni elem divergencia összegzésével normalizálás nélkül. Befolyásolja gradiens magnitúdó skálázást arányosan összes elem számával batch-ban és térbeli dimenziókban. Szabályozza veszteség akkumulációt ami nagyobb gradienseket eredményez nagyobb kötegekhez vagy magasabb felbontású bemenetekhez. Szükséges gondos tanulási ráta igazítás amikor batch méretek vagy bemenet dimenziók jelentősen változnak.",
      "batchmean": "Batch Átlag Redukció - Átlag KL divergenciát számít batch dimenzión csak, megőrizve térbeli dimenzió hozzájárulásokat. Befolyásolja veszteség kalkulációt átlagolással minták felett miközben fenntart teljes térbeli veszteség hozzájárulást. Szabályozza standard KL divergencia redukciót ami fókuszál minta-szintű átlagolásra helyett elem-szintű normalizálásra. Ajánlott redukciós módszer KL divergencia veszteséghez mivel megőrzi elméleti tulajdonságokat stabil tanítással."
    },
    "models_resnet_default_optimizer_type_enum_descriptor": {
      "adamw": "AdamW ResNet-hez - Adam dekoupled weight decay-vel specifikusan hangolva ResNet architektúrákhoz. Befolyásolja regularizációs hatékonyságot és tanítási stabilitást megfelelő szétválasztással gradiens-alapú adaptáció és L2 büntetés között. Szabályozza weight decay-t függetlenül gradiens frissítésektől, megelőzve regularizációs interferenciát adaptív tanulási rátákkal. Ajánlott alapértelmezett választás ResNet modellekhez kiváló generalizációs teljesítmény és stabil tanítás miatt különböző ResNet mélységeken és adathalmazokon keresztül.",
      "adam": "Adam Optimalizáló ResNet-hez - Klasszikus adaptív momentum becslés biztosít automatikus tanulási ráta skálázást ResNet tanításhoz. Befolyásolja konvergencia sebességet és hiperparaméter érzékenységet per-paraméter tanulási ráta adaptáció által. Szabályozza momentum és négyzetes gradiens becsléseket kiegyensúlyozva felfedezést és kihasználást ResNet optimalizálás során. Jó általános célú választás megbízható teljesítményért különböző ResNet variánsokon minimális hiperparaméter tuning-gal.",
      "sgd": "SGD Momentum-mal ResNet-hez - Hagyományos sztochasztikus gradiens descent momentum-mal specifikusan konfigurálva ResNet tanításhoz. Befolyásolja tanítási dinamikát momentum akkumuláció által és igényel gondos tanulási ráta ütemezést optimális teljesítményért. Szabályozza paraméter frissítéseket momentum-alapú gyorsítással miközben fenntart determinisztikus optimalizálási viselkedést. Hagyományos választás kiváló eredményekért megfelelő tuning-gal de több gondos hiperparaméter kiválasztást igényel mint adaptív optimalizálók."
    },
    "models_resnet_default_scheduler_type_enum_descriptor": {
      "step_lr": "Lépéses Tanulási Ráta ResNet-hez - Előre meghatározott mérföldkő epoch-okkal tanulási ráta csökkenés ResNet tanítási fázisokhoz igazítva. Befolyásolja tanulási ráta csökkentést specifikus tanítási stádiumokban megfelelő ResNet konvergencia mintáknak. Szabályozza determinisztikus tanulási ráta ütemezést ami igazodik tipikus ResNet tanítási progresszióhoz és veszteség táj jellemzőihez. Megfelelő amikor optimális csökkenés időzítés ismert korábbi ResNet kísérletekből vagy kutatási papírokból hasonló adathalmazokkal és architektúrákkal.",
      "cosine_annealing_lr": "Koszinusz Annealing ResNet-hez - Sima koszinusz-alapú tanulási ráta ütemezés ami gyakran javít ResNet végső pontosság fokozatos tanulási ráta csökkenéssel. Befolyásolja tanítási dinamikát hogy biztosítson sima átmeneteket segítve ResNet modelleket jobb végső konvergencia elérésében. Szabályozza szinuszoidális tanulási ráta progressziót ami csökkenti tanítási oszcillációkat és lehetővé teszi finom paraméter igazítást későbbi tanítási fázisokban. Gyakran kiváló végső pontosságot ér el hagyományos lépés-alapú ütemezésekhez képest ResNet architektúrákhoz.",
      "reduce_lr_on_plateau": "Adaptív Ütemezés ResNet-hez - Fennsík-alapú tanulási ráta csökkentés ami automatikusan reagál ResNet tanítási stagnálási periódusokra. Befolyásolja tanulási ráta adaptációt validációs metrika monitorozás által, csökkentve tanulási rátát amikor ResNet tanítási progresszió stagnál. Szabályozza automatikus ütemezés igazítást ami reagál aktuális tanítási dinamikákra helyett előre meghatározott mérföldkövekre. Optimális ResNet tanításhoz amikor optimális csökkenés időzítés ismeretlen vagy tanítási jellemzők változnak különböző adathalmazokon vagy kísérleti feltételek között."
    }
  },
  "status_graph": {
    "epoch_accuracy": "Epoch Pontosság",
    "epoch_loss": "Epoch Veszteség",
    "step_loss": "Lépés Veszteség",
    "learning_rate": "Tanulási Ráta",
    "loss": "Veszteség",
    "no_data": "Frissítések Várása",
    "no_training": "Nincs Aktív Tanítás.",
    "active_count": "Aktív tanítások: {count}",
    "label_training_id": "Tanítási ID",
    "label_status": "Állapot",
    "label_phase": "Fázis",
    "label_epoch": "Epoch",
    "label_step": "Lépés",
    "badge_training": "Tanítás: {project}",
    "footer_training": "Tanítás {project} — Epoch {epoch} • Lépés {step}"
  },
  "updates": {
    "log": {
      "check_started": "Felső stream checksum-ok ellenőrzése...",
      "check_complete": "Frissítési ellenőrzés kész. Függőben fájlok: {count}",
      "check_failed": "Frissítési ellenőrzés sikertelen: {error}",
      "remote_config_failed": "Nem sikerült letölteni távoli config.json-t: {error}",
      "remote_checksum_failed": "Nem sikerült letölteni távoli checksum manifest-et: {error}",
      "remote_payload_invalid": "Távoli payload {url}-ről nem volt mapping.",
      "local_checksum_missing": "Helyi checksum.json hiányzik; üres manifest feltételezve.",
      "local_checksum_invalid": "Nem sikerült parse-olni helyi checksum.json-t: {error}",
      "path_escape": "Blokkolt unsafe path {path}",
      "apply_started": "Frissítések alkalmazása...",
      "apply_failed": "Nem sikerült alkalmazni frissítéseket: {error}",
      "apply_nothing": "Nincs szükség frissítésekre.",
      "apply_file_success": "Frissítve {path}",
      "apply_file_failed": "Nem sikerült frissíteni {path}: {error}",
      "apply_partial": "Alkalmazva {updated} frissítést {failed} hibával.",
      "apply_complete": "Alkalmazva {count} frissítést."
    },
    "api": {
      "check_success": "Frissítési ellenőrzés befejezve. {count} fájl függőben.",
      "check_no_updates": "Minden már naprakész.",
      "check_failed": "Frissítési ellenőrzés sikertelen: {error}",
      "apply_success": "Frissítések sikeresen alkalmazva. {updated} fájl frissítve.",
      "apply_partial": "Frissítések alkalmazva {updated} sikerrel és {failed} hibával.",
      "apply_failed": "Nem sikerült alkalmazni frissítéseket: {error}",
      "apply_nothing": "Nem volt szükség frissítésekre."
    },
    "status": {
      "missing": "Helyileg hiányzik",
      "outdated": "Checksum eltérés"
    }
  },
  "status": {
    "project_load_failed": "Projekt betöltés sikertelen",
    "project_loading": "Projekt betöltése {projectName}...",
    "project_loaded_custom": "Betöltve projekt {projectName} egyedi konfiggal",
    "project_loaded_defaults": "Betöltve projekt {projectName} globális alapértelmezettekkel",
    "project_load_error": "Nem sikerült betölteni projektet {projectName}: {error}",
    "no_project_loaded": "Nincs projekt betöltve",
    "validation_errors": "Javítsd validációs hibákat mentés előtt",
    "saving_training_config": "Tanítási konfiguráció mentése...",
    "training_config_saved": "Tanítási konfiguráció mentve",
    "save_failed": "Mentés sikertelen",
    "loading_schema": "Séma & konfiguráció betöltése...",
    "init_failed": "Init sikertelen",
    "memory_load_failed": "Memória betöltés sikertelen",
    "checking_updates": "Frissítések ellenőrzése...",
    "updates_ready": "Frissítések elérhetőek",
    "updates_none": "Nincsenek frissítések",
    "updates_check_failed": "Frissítési ellenőrzés sikertelen",
    "updates_applying": "Frissítések alkalmazása...",
    "updates_applied": "Frissítések sikeresen alkalmazva",
    "updates_apply_failed": "Frissítési alkalmazás sikertelen",
    "generating_heatmap": "Hőtérkép előállítása...",
    "heatmap_generated": "Hőtérkép előállítva",
    "heatmap_generation_failed": "Hőtérkép előállítás sikertelen",
    "saving_system_settings": "Rendszer beállítások mentése...",
    "system_settings_saved": "Rendszer beállítások mentve",
    "starting_training": "Tanítás indítása...",
    "training_started": "Tanítás elindult",
    "training_stopping": "Tanítás leállítása...",
    "training_stop_requested": "Tanítás leállítás kérve",
    "training_stop_failed": "Tanítás leállítás sikertelen",
    "training_start_failed": "Tanítás indítás sikertelen",
    "switching_language": "Nyelv váltás...",
    "language_switched": "Nyelv sikeresen váltva",
    "language_switch_failed": "Nyelv váltás sikertelen",
    "augmentation_preview_ready": "Augmentációs előnézet előállítva"
  }
}
