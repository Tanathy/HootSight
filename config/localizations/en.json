{
  "language_name": "English",
  "app": {
    "brand": "Hootsight",
    "page_not_found": {
      "title": "Page Not Found",
      "description": "The requested page does not exist."
    }
  },
  "common": {
    "project_label": "Project:"
  },
  "training_controller": {
    "stop": "Stop",
    "clear": "Clear",
    "completed": "Training Completed",
    "stopped": "Training Stopped",
    "error": "Training Error",
    "already_running": "A training is already in progress"
  },
  "context_menu": {
    "view_image": "View Image",
    "select": "Select",
    "deselect": "Deselect",
    "select_all": "Select All",
    "clear_selection": "Clear Selection",
    "copy_filename": "Copy Filename",
    "copy_path": "Copy Path",
    "delete": "Delete",
    "delete_selected": "Delete Selected ({count})",
    "open_folder": "Open Folder",
    "new_subfolder": "New Subfolder",
    "rename": "Rename",
    "move_to": "Move To..."
  },
  "nav": {
    "training_group": "Training",
    "projects": "Projects",
    "dataset": "Dataset",
    "dataset_editor": "Dataset Editor",
    "training_setup": "Training",
    "augmentation": "Augmentation",
    "performance": "Performance",
    "status_group": "Status",
    "status": "Status",
    "heatmap": "Heatmap",
    "system_group": "System",
    "updates": "Updates",
    "docs": "Docs",
    "about": "About",
    "inference": "Inference",
    "settings": "Settings"
  },
  "training_page": {
    "tabs": {
      "model": "Model",
      "hyperparameters": "Hyperparameters",
      "dataloader": "Data Loader",
      "augmentation": "Augmentation",
      "optimizer": "Optimizer",
      "scheduler": "Scheduler",
      "loss": "Loss",
      "checkpoint": "Checkpoint",
      "early_stopping": "Early Stopping",
      "gradient": "Gradient",
      "runtime": "Runtime",
      "presets": "Presets"
    },
    "presets": {
      "title": "Training Presets",
      "description": "Apply predefined training configurations optimized for specific tasks",
      "no_presets": "No presets available",
      "loading": "Loading presets...",
      "apply_button": "Apply",
      "applied": "Preset applied successfully",
      "apply_error": "Failed to apply preset",
      "incompatible_dataset": "Dataset type not compatible with this preset",
      "dataset_size": "Dataset Size:",
      "recommended": "Recommended:",
      "search_placeholder": "Search presets by name, description, task...",
      "search_results": "{count} of {total} presets",
      "only_compatible": "Only Compatible"
    },
    "augmentation": {
      "train_title": "Training Augmentations",
      "train_description": "Select and configure augmentations applied during training. These help the model generalize better by introducing variations.",
      "val_title": "Validation Augmentations",
      "val_description": "Select augmentations for validation. Typically minimal - usually just center crop and normalization.",
      "no_params": "No configurable parameters",
      "preview_placeholder": "Click 'Random' to load an image",
      "btn_random": "Random",
      "btn_train": "Training",
      "btn_val": "Validation"
    },
    "no_settings": "No settings available for this section",
    "project_label": "Project:",
    "save_button": "Save",
    "saving": "Saving...",
    "saved": "Saved!",
    "save_error": "Save failed",
    "load_defaults_button": "Load Defaults",
    "load_project_button": "Project Defaults",
    "defaults_loaded": "Defaults loaded",
    "project_loaded": "Project loaded",
    "load_error": "Load failed",
    "no_project": {
      "title": "No Project Selected",
      "description": "Please select a project from the Projects page to configure training settings.",
      "button": "Go to Projects"
    }
  },
  "dataset_page": {
    "project_label": "Project:",
    "type_label": "Type:",
    "input_size_label": "Input Size:",
    "search_filename": "Filename",
    "search_annotation": "Annotation",
    "search_placeholder": "Search images...",
    "show_duplicates": "Show/Hide Duplicates",
    "sync_button": "Sync",
    "build_button": "Build Dataset",
    "progress_discovery": "Discovery",
    "progress_starting": "Starting...",
    "progress_complete": "Complete",
    "folders": "Folders",
    "root_folder": "All Images",
    "new_folder": "New folder",
    "enter_folder_name": "Enter folder name:",
    "enter_new_name": "Enter new name:",
    "rename_folder": "Rename",
    "delete_folder": "Delete",
    "delete_folder_confirm": "Are you sure you want to delete this folder?",
    "delete_folder_confirm_with_images": "This folder contains {count} images. Are you sure you want to delete it?",
    "folder_create_error": "Failed to create folder",
    "folder_rename_error": "Failed to rename folder",
    "folder_delete_error": "Failed to delete folder",
    "uploading": "Uploading...",
    "upload_error": "Failed to upload",
    "type_auto": "Auto",
    "types": {
      "unknown": "Not Set",
      "multi_label": "Multi Label",
      "folder_classification": "Folder Classification",
      "annotation": "Annotation",
      "mixed": "Mixed"
    },
    "drop_images": "Drop images here to upload",
    "delete_image": "Delete image",
    "annotation_placeholder": "Enter annotation...",
    "tag_placeholder": "+ add tag",
    "confirm_delete": "Are you sure you want to delete this image?",
    "syncing": "Syncing...",
    "building": "Building...",
    "build_complete": "Dataset build complete!",
    "build_error": "Build failed",
    "status_count": "{count} images",
    "per_page": "Per page:",
    "selected_count": "{count} selected",
    "clear_selection": "Clear",
    "select_all": "Select All",
    "bulk_add_tags_placeholder": "Tags to add...",
    "bulk_remove_tags_placeholder": "Tags to remove...",
    "bulk_add": "Add",
    "bulk_remove": "Remove",
    "bulk_delete": "Delete",
    "bulk_delete_confirm": "Are you sure you want to delete {count} images?",
    "bulk_error": "Bulk operation failed",
    "duplicate_count": "{count} duplicates found",
    "duplicates_button": "Find Duplicates",
    "duplicates_scanning": "Scanning...",
    "duplicates_none": "No duplicate images found.",
    "duplicates_error": "Failed to scan for duplicates",
    "duplicates_title": "Duplicate Images",
    "duplicates_stats": "Found {groups} duplicate groups with {total} total images (scanned {scanned} images in {duration}s)",
    "duplicates_group": "Group {num}",
    "duplicates_images": "images",
    "duplicates_keep": "Keep",
    "duplicates_select_all": "Select All Duplicates",
    "duplicates_delete": "Delete Selected ({count})",
    "duplicates_delete_confirm": "Are you sure you want to delete {count} duplicate images?",
    "duplicates_delete_error": "Failed to delete duplicate images",
    "duplicates_close": "Close",
    "no_project": {
      "title": "No Project Selected",
      "description": "Please select a project from the Projects page to manage the dataset.",
      "button": "Go to Projects"
    },
    "empty_dataset": {
      "title": "No Images Found",
      "description": "This dataset is empty. Sync to discover images from data_source folder."
    }
  },
  "heatmap_page": {
    "random_button": "Random",
    "refresh_button": "Refresh",
    "live_model_switch": "Use Live Model",
    "alpha_label": "Heatmap Opacity:",
    "checkpoint_label": "Checkpoint:",
    "no_project": {
      "title": "No Project Selected",
      "description": "Please select a project from the Projects page to use heatmap visualization.",
      "button": "Go to Projects"
    },
    "drop_zone": {
      "text": "Drop image here or click to upload",
      "hint": "Supports JPG, PNG, WEBP"
    },
    "results": {
      "title": "Detection Results",
      "placeholder": "Load an image to see predictions",
      "no_predictions": "No predictions above confidence threshold"
    }
  },
  "performance_page": {
    "tabs": {
      "training": "Training Performance",
      "system": "System Usage"
    },
    "system": {
      "title": "System Resource Monitor",
      "cpu_usage": "CPU Usage",
      "system_memory": "System Memory",
      "gpu_usage": "GPU {index} Usage",
      "gpu_memory": "GPU {index} Memory",
      "no_gpu": "No GPU detected",
      "monitoring_active": "Monitoring active",
      "monitoring_paused": "Monitoring paused",
      "speed": "Speed",
      "temperature": "Temperature",
      "max_memory": "Total Memory",
      "available": "Available",
      "dedicated_memory": "Dedicated Memory",
      "used_memory": "Used Memory",
      "cores_threads": "Cores / Threads",
      "power": "Power",
      "gpu_clock": "GPU Clock",
      "mem_clock": "Mem Clock",
      "fan": "Fan"
    },
    "training": {
      "title": "Training Metrics",
      "no_data": "No training data available",
      "description": "Training metrics will appear here during active training sessions.",
      "no_active": "No active training",
      "running": "Training in progress",
      "completed": "Training completed",
      "stopped": "Training stopped",
      "step_loss": "Step Loss",
      "train_step_loss": "Train Step Loss",
      "val_step_loss": "Validation Step Loss",
  "step_accuracy": "Step Accuracy",
  "train_step_accuracy": "Train Step Accuracy",
  "val_step_accuracy": "Validation Step Accuracy",
      "learning_rate": "Learning Rate",
      "epoch_loss": "Epoch Loss",
      "epoch_accuracy": "Epoch Accuracy",
      "train": "Train",
      "validation": "Validation",
      "current": "Current",
      "current_loss": "Current Loss",
      "phase": "Phase",
      "step": "Step",
      "current_lr": "Current LR",
      "train_loss": "Train Loss",
      "val_loss": "Val Loss",
      "train_accuracy": "Train Acc",
      "val_accuracy": "Val Acc"
    }
  },
  "page": {
    "projects": "Projects",
    "dataset": "Dataset",
    "dataset_editor": "Dataset Editor",
    "training": "Training Setup",
    "augmentation": "Augmentation",
    "status": "Status",
    "heatmap": "Heatmap",
    "updates": "Updates",
    "docs": "Docs",
    "about": "About"
  },
  "projects_page": {
    "title": "Projects",
    "description": "Manage your image recognition projects",
    "dataset_types": {
      "multi_label": "Multi Label",
      "mixed": "Mixed",
      "clean": "Clean",
      "folder_classification": "Folder Classification",
      "annotation": "Annotation",
      "unknown": "Unknown"
    },
    "card": {
      "unknown_type": "Unknown type",
      "no_stats": "No statistics available - click Refresh",
      "loading": "Loading...",
      "error": "Error"
    },
    "stats": {
      "total_images": "Total Images",
      "labels": "Labels",
      "min_images": "Min Images",
      "max_images": "Max Images",
      "balance_score": "Balance Score",
      "balance_status": "Balance Status"
    },
    "buttons": {
      "refresh": "Refresh",
      "load": "Load",
      "loaded": "Loaded",
      "new_project": "New Project",
      "rename_project": "Rename Project",
      "delete_project": "Delete Project",
      "start_training": "Start Training",
      "stop_training": "Stop Training"
    },
    "training": {
      "no_project": "Please load a project first before starting training.",
      "start_error": "Failed to start training",
      "stop_error": "Failed to stop training"
    },
    "new_project": {
      "title": "New Project",
      "prompt": "Enter project name:",
      "error": "Failed to create project"
    },
    "rename_project": {
      "title": "Rename Project",
      "prompt": "Enter new project name:",
      "no_selection": "No project is currently loaded. Load a project first to rename it.",
      "error": "Failed to rename project"
    },
    "delete_project": {
      "title": "Delete Project",
      "confirm": "Are you sure you want to delete project '{name}'? This action cannot be undone.",
      "no_selection": "No project is currently loaded. Load a project first to delete it.",
      "error": "Failed to delete project"
    },
    "empty": {
      "title": "No Projects Found",
      "description": "Create a project folder in the projects directory"
    },
    "error": {
      "title": "Error Loading Projects"
    }
  },
  "dataset_editor": {
    "api": {
      "project_not_found": "Project {project} is not registered for dataset editing.",
      "image_not_found": "Requested image could not be found in project {project}.",
      "invalid_page_size": "Page size is not allowed. Choose from: {allowed}.",
      "invalid_size": "Crop size is not allowed. Choose from: {allowed}.",
      "invalid_image_path": "Image path is invalid or outside the project directory.",
      "image_missing": "Image is missing or unreadable."
    }
  },
  "dataset_editor_ui": {
    "page_title": "Dataset Editor",
    "page_description": "Crop, tag, and build datasets without leaving the app.",
    "project_label": "Project",
    "crop_size": "Crop size",
    "build_button": "Build Dataset",
    "discovery_idle": "Idle",
    "build_idle": "Idle",
    "folders": "Folders",
    "folder_hint": "Hold CTRL to crop thumbs on the fly.",
    "refresh": "Refresh",
    "reset": "Reset",
    "stats_images": "Images",
    "stats_categories": "Categories",
    "stats_balance_score": "Balance Score",
    "stats_balance_status": "Balance Status",
    "stats_sparse": "Sparse Tags",
    "stats_dominant": "Dominant Tags",
    "search_placeholder": "Search annotations or filenames",
    "search_clear": "Clear",
    "page_size": "Page size",
    "prev": "Prev",
  "next": "Next",
  "pager_label": "Page {current} / {total} • {items} items",
  "stats_recommendations_title": "Recommendations",
  "stats_recommendations_note": "Suggested actions to improve dataset balance and quality",
  "filters_title": "Filters",
  "filters_note": "Filter images by folder, tags, or filename",
    "bulk_title": "Bulk tag edit",
    "bulk_note": "Applies to the current filter.",
    "bulk_add": "Add tags",
    "bulk_add_placeholder": "Comma-separated tags",
    "bulk_remove": "Remove tags",
    "bulk_remove_placeholder": "Comma-separated tags",
    "bulk_apply": "Apply to filtered",
    "unavailable": "Dataset editor unavailable",
    "bullet_separator": " \u2022 ",
    "list_separator": ", ",
    "size_no_presets": "No presets",
    "stats_placeholder": "—",
    "stats_balanced": "Dataset is well balanced. No immediate action required.",
    "stats_min_images": "Min per label",
    "stats_max_images": "Max per label",
    "stats_ratio": "Imbalance ratio",
    "stats_distribution": "Top labels",
    "rec_dataset_empty_title": "No Images Found",
    "rec_dataset_empty_desc": "Your dataset is currently empty. Upload images or run discovery to scan your data source folder.",
    "rec_dataset_empty_action": "Start by adding images to the data_source folder, then click Refresh to discover them.",
    "rec_dataset_very_small_title": "Critical Dataset Size",
    "rec_dataset_very_small_desc": "You have only {current_total} images. This is far below the recommended minimum for reliable training.",
    "rec_dataset_very_small_action": "Collect at least {recommended_min} images per category ({recommended_ideal} is ideal). Current total: {current_total}.",
    "rec_dataset_small_title": "Small Dataset Warning",
    "rec_dataset_small_desc": "Your dataset contains {current_total} images, which may limit model generalization.",
    "rec_dataset_small_action": "Aim for {recommended_min}+ images. Enable aggressive augmentation to increase effective dataset size during training.",
    "rec_severe_imbalance_title": "Severe Class Imbalance Detected",
    "rec_severe_imbalance_desc": "Your classes are heavily skewed with a {ratio}:1 imbalance ratio. This will bias your model toward majority classes.",
    "rec_severe_imbalance_what": "What's wrong: Largest class has {max_count} samples while smallest has only {min_count} (average: {avg_count}).",
    "rec_severe_imbalance_underrep": "Underrepresented classes that need MORE samples:",
    "rec_severe_imbalance_overrep": "Overrepresented classes that should be REDUCED or balanced:",
    "rec_severe_imbalance_action": "• Collect more images for minority classes\n• Enable weighted loss functions\n• Use class-balanced sampling\n• Consider removing duplicates from majority classes",
    "rec_moderate_imbalance_title": "Moderate Class Imbalance",
    "rec_moderate_imbalance_desc": "Classes are moderately imbalanced ({ratio}:1 ratio). Training may favor majority classes.",
    "rec_moderate_imbalance_what": "Largest: {max_count}, smallest: {min_count}, average: {avg_count} samples per class.",
    "rec_moderate_imbalance_action": "• Enable weighted loss functions or apply targeted augmentation to minority classes\n• Consider stratified sampling during training",
    "rec_severe_tag_imbalance_title": "Severe Tag Imbalance (Multi-Label)",
    "rec_severe_tag_imbalance_desc": "Your multi-label tags are extremely imbalanced ({ratio}:1 ratio).",
    "rec_severe_tag_imbalance_rare": "Rarest tags that need attention:",
    "rec_severe_tag_imbalance_action": "• Use per-tag weighting in BCEWithLogitsLoss\n• Collect more examples with rare tags\n• Consider merging very rare tags into broader categories",
    "rec_label_item": "{label}: {count} images",
    "rec_balance_status_excellent": "Excellent",
    "rec_balance_status_good": "Good",
    "rec_balance_status_fair": "Fair",
    "rec_balance_status_poor": "Poor",
    "rec_balance_status_critical": "Critical",
    "folders_loading": "Loading...",
    "footer_discovery": "Scanning {project} — {percent}% {processed}/{total}",
    "footer_build": "Building {project} — {percent}% {processed}/{total}",
    "scope_selected_one": "1 selected item",
    "scope_selected_many": "{count} selected items",
    "scope_total_one": "1 item",
    "scope_total_many": "{count} items",
    "scope_folder": "folder {folder}",
    "scope_search": "search \"{term}\"",
    "scope_separator": " \u2022 ",
    "delete_success_one": "Deleted 1 item",
    "delete_success_many": "Deleted {count} items",
    "delete_none": "No items deleted",
    "build_queue": "Dataset build queued @ {size}px",
    "refresh_queueing": "Queueing…",
    "refresh_scanning": "Scanning…",
    "refreshing_label": "Refreshing…",
    "refresh_label": "Refresh",
    "folders_refreshed": "Folders refreshed",
    "discovery_queued": "Discovery queued",
    "request_failed": "Request failed ({status})",
    "unexpected_error": "Unexpected error",
    "bulk_need_tags": "Add or remove at least one tag",
    "bulk_applying": "Applying…",
    "bulk_result": "Bulk edit applied ({updated} updated, {skipped} skipped)",
    "build_summary_updated": "{count} updated",
    "build_summary_removed": "{count} removed",
    "build_success": "Dataset built ({summary})",
    "build_failed_with_reason": "Build failed: {reason}",
    "build_failed": "Build failed",
    "build_button_preparing": "Preparing…",
    "build_button_running": "Building {completed}/{total}",
    "build_status_idle": "Idle",
    "build_status_pending": "Queued",
    "build_status_running": "Building",
    "build_status_success": "Done",
    "build_status_error": "Failed",
    "build_eta_idle": "ETA —",
    "build_eta_pending": "Preparing…",
    "build_eta_running_known": "ETA {duration}",
    "build_eta_running_unknown": "Estimating…",
    "build_eta_success": "Finished in {duration}",
    "build_eta_error": "Failed",
    "build_stats_none": "No builds yet.",
    "build_stats_updated": "{count} updated",
    "build_stats_removed": "{count} removed",
    "build_stats_failed": "{count} failed",
    "build_stats_ratio": "{completed}/{total}",
    "build_stats_size": "{size}px crops",
    "build_stats_last_run": "Last run {time}",
    "build_stats_waiting": "Waiting for first build.",
    "discovery_summary_added": "{count} new",
    "discovery_summary_updated": "{count} changed",
    "discovery_summary_removed": "{count} removed",
    "discovery_summary": "Discovery updated ({summary})",
    "discovery_refreshed": "Discovery refreshed",
    "discovery_failed_with_reason": "Discovery failed: {reason}",
    "discovery_failed": "Discovery failed",
    "discovery_status_idle": "Idle",
    "discovery_status_pending": "Scanning",
    "discovery_status_running": "Scanning",
    "discovery_status_success": "Done",
    "discovery_status_error": "Failed",
    "discovery_eta_idle": "ETA —",
    "discovery_eta_pending": "Preparing…",
    "discovery_eta_running_known": "ETA {duration}",
    "discovery_eta_running_unknown": "Estimating…",
    "discovery_eta_success": "Finished in {duration}",
    "discovery_eta_error": "Failed",
    "discovery_stats_none": "No scans yet.",
    "discovery_stats_processed": "{count} processed",
    "discovery_stats_added": "{count} new",
    "discovery_stats_updated": "{count} changed",
    "discovery_stats_removed": "{count} removed",
    "discovery_stats_skipped": "{count} skipped",
    "discovery_stats_last_run": "Last run {time}",
    "discovery_stats_waiting": "Scanning…"
  },
  "config": {
    "sections": {
      "training": "Training",
      "optimizers": "Optimizers",
      "schedulers": "Schedulers",
      "losses": "Losses",
      "models": "Models"
    },
    "entities": {
      "optimizers": {
        "sgd": "SGD (Stochastic Gradient Descent)",
        "adam": "Adam Optimizer",
        "adamw": "AdamW Optimizer",
        "adamax": "AdaMax Optimizer",
        "nadam": "Nesterov Adam",
        "radam": "Rectified Adam",
        "rmsprop": "RMSprop Optimizer",
        "rprop": "Resilient Backpropagation",
        "adagrad": "AdaGrad Optimizer",
        "adadelta": "AdaDelta Optimizer",
        "sparse_adam": "Sparse Adam",
        "lbfgs": "L-BFGS Optimizer",
        "asgd": "Averaged SGD"
      },
      "schedulers": {
        "step_lr": "Step Learning Rate",
        "multi_step_lr": "Multi-Step Learning Rate",
        "exponential_lr": "Exponential Learning Rate",
        "cosine_annealing_lr": "Cosine Annealing",
        "cosine_annealing_warm_restarts": "Cosine Annealing with Warm Restarts",
        "reduce_lr_on_plateau": "Reduce LR on Plateau",
        "cyclic_lr": "Cyclic Learning Rate",
        "one_cycle_lr": "One Cycle Learning Rate",
        "polynomial_lr": "Polynomial Learning Rate",
        "linear_lr": "Linear Learning Rate",
        "lambda_lr": "Lambda Learning Rate",
        "multiplicative_lr": "Multiplicative Learning Rate"
      },
      "losses": {
        "cross_entropy": "Cross-Entropy Loss",
        "nll_loss": "Negative Log-Likelihood",
        "bce_loss": "Binary Cross-Entropy",
        "bce_with_logits": "BCE with Logits",
        "multi_margin": "Multi-Class Margin Loss",
        "multi_label_margin": "Multi-Label Margin Loss",
        "multi_label_soft_margin": "Multi-Label Soft Margin",
        "mse_loss": "Mean Squared Error",
        "l1_loss": "L1 Loss (MAE)",
        "smooth_l1": "Smooth L1 Loss",
        "huber_loss": "Huber Loss",
        "kl_div": "KL Divergence",
        "margin_ranking": "Margin Ranking Loss",
        "hinge_embedding": "Hinge Embedding Loss",
        "triplet_margin": "Triplet Margin Loss",
        "cosine_embedding": "Cosine Embedding Loss",
        "ctc_loss": "CTC Loss",
        "poisson_nll": "Poisson NLL Loss",
        "gaussian_nll": "Gaussian NLL Loss"
      }
    }
  },
  "groups": {
    "model_settings": "Model Settings",
    "task_configuration": "Task Configuration",
    "training_parameters": "Training Parameters",
    "optimizer_settings": "Optimizer Settings",
    "scheduler_settings": "Scheduler Settings",
    "loss_configuration": "Loss Configuration",
    "data_loading": "Data Loading",
    "normalization": "Normalization",
    "checkpointing": "Checkpointing",
    "weight_initialization": "Weight Initialization"
  },
  "actions": {
    "save_config": "Save Config",
    "export": "Export",
    "save_training_config": "Save Training Config",
    "save_system_settings": "Save Global Settings"
  },
  "footer": {
    "tagline": "Config-driven",
    "generated": "",
    "ready": "Ready"
  },
  "field": {
    "training_model_type": "Model Type",
    "training_model_name": "Model Name",
    "training_pretrained": "Pretrained",
    "training_task": "Task",
    "training_batch_size": "Batch Size",
    "training_epochs": "Epochs",
    "training_learning_rate": "Learning Rate",
    "training_weight_decay": "Weight Decay",
    "training_input_size": "Input Size",
    "training_val_ratio": "Validation Ratio",
    "training_optimizer_type": "Optimizer Type",
    "training_scheduler_type": "Scheduler Type",
    "training_loss_type": "Loss Type",
    "training_dataloader": "DataLoader",
    "training_dataloader_num_workers": "Num Workers",
    "training_dataloader_pin_memory": "Pin Memory",
    "training_dataloader_persistent_workers": "Persistent Workers",
    "training_dataloader_prefetch_factor": "Prefetch Factor",
    "training_normalize": "Normalize",
    "training_normalize_mean": "Mean",
    "training_normalize_std": "Std",
    "training_checkpoint": "Checkpoint",
    "training_checkpoint_save_best_only": "Save Best Only",
    "training_checkpoint_save_frequency": "Save Frequency",
    "training_checkpoint_max_checkpoints": "Max Checkpoints",
    "training_checkpoint_checkpoint_dir": "Checkpoint Dir",
    "training_checkpoint_best_model_filename": "Best Model Filename",
    "training_checkpoint_training_history_filename": "Training History Filename",
    "training_weight_init": "Weight Init",
    "training_weight_init_type": "Init Type",
    "training_weight_init_params": "Init Params",
    "training_optimizer_params_adamw_lr": "Learning Rate",
    "training_optimizer_params_adamw_betas": "Betas",
    "training_optimizer_params_adamw_eps": "Eps",
    "training_optimizer_params_adamw_weight_decay": "Weight Decay",
    "training_optimizer_params_adamw_amsgrad": "Amsgrad",
    "training_scheduler_params_step_lr_step_size": "Step Size",
    "training_scheduler_params_step_lr_gamma": "Gamma",
    "training_scheduler_params_step_lr_last_epoch": "Last Epoch",
    "training_loss_params_bce_with_logits_weight": "Weight",
    "training_loss_params_bce_with_logits_size_average": "Size Average",
    "training_loss_params_bce_with_logits_reduce": "Reduce",
    "training_loss_params_bce_with_logits_reduction": "Reduction",
    "training_loss_params_bce_with_logits_pos_weight": "Pos Weight"
  },
  "ui": {
    "generate_heatmap": "Generate Heatmap",
    "no_heatmap_generated": "No heatmap generated yet.",
    "no_data_available": "No data available.",
    "page_not_implemented": "Page not implemented",
    "error": "Error",
    "schema_not_loaded": "Schema not loaded yet. Please wait...",
    "config_not_loaded": "Config not loaded yet. Please wait...",
    "augmentation_phase": "Augmentation {phase}",
    "add": "Add",
    "remove": "Remove",
    "transform": "transform",
    "no_project_loaded": "No Project Loaded",
    "load_project_first": "Please load a project first from the Projects tab.",
    "go_to_projects": "Go to Projects",
    "dataset_overview": "Dataset Overview",
    "balance_analysis": "Balance Analysis",
    "label_distribution": "Label Distribution (Top 20)",
    "recommendations": "Recommendations",
    "failed_to_load_dataset": "Failed to load dataset information.",
    "current_project": "CURRENT PROJECT",
    "load": "Load",
    "start_training": "Start Training",
    "stop_training": "Stop Training",
    "stop_training_disabled": "No active training for this project.",
    "training_in_progress": "Training in progress",
    "loading": "Loading...",
    "training_status": "Training Status",
    "idle": "Idle",
    "prediction": "Prediction",
    "predictions": "Predictions",
    "no_predictions_above_threshold": "No predictions above threshold",
    "image": "Image",
    "checkpoint": "Checkpoint",
    "auto": "auto",
    "value": "value",
    "one_number_per_line": "One number per line",
    "empty_object": "Empty object",
    "language_warning": "Language change refreshes the system",
    "language_select_title": "Select language",
    "not_available": "N/A",
    "unknown": "Unknown",
    "configuration_empty": "No configuration sections available",
    "configuration_schema_missing": "Configuration schema is not loaded yet."
  },
  "augmentation_ui": {
    "page_title": "Data Augmentation",
    "page_description": "Configure image transformations to improve model generalization and robustness.",
    "train_title": "Training Augmentations",
    "train_description": "Applied during training to increase visual diversity while keeping labels intact.",
    "val_title": "Validation Augmentations",
    "val_description": "Applied during validation to maintain deterministic evaluation.",
    "toggle_help": "Toggle an augmentation to enable or disable it for this phase.",
    "no_options": "No augmentation options are available.",
    "custom_warning": "The following transforms are preserved but cannot be edited here:",
    "unknown_transform": "Unknown transform",
    "random_resized_crop": "Random Resized Crop",
    "random_resized_crop_description": "Randomly crops and resizes the image to the target size while respecting scale and aspect ratio ranges.",
    "random_horizontal_flip": "Random Horizontal Flip",
    "random_horizontal_flip_description": "Flips the image horizontally with the configured probability to capture left and right variations.",
    "random_vertical_flip": "Random Vertical Flip",
    "random_vertical_flip_description": "Flips the image vertically to expose the model to top and bottom perspective changes.",
    "random_rotation": "Random Rotation",
    "random_rotation_description": "Applies a random rotation within the defined degree range to reduce orientation bias.",
    "color_jitter": "Color Jitter",
    "color_jitter_description": "Randomly varies brightness, contrast, saturation, and hue to improve color robustness.",
    "random_grayscale": "Random Grayscale",
    "random_grayscale_description": "Converts images to grayscale with the configured probability to improve luminance awareness.",
    "random_erasing": "Random Erasing",
    "random_erasing_description": "Randomly masks rectangular regions to encourage spatial robustness and object completeness reasoning.",
    "random_perspective": "Random Perspective",
    "random_perspective_description": "Applies a random perspective transformation using the configured distortion scale and probability.",
    "center_crop": "Center Crop",
    "center_crop_description": "Crops the centered region to the target size for consistent validation inputs.",
    "random_resized_crop.size_label": "Output size",
    "random_resized_crop.size_description": "Final edge length in pixels after the crop is resized.",
    "random_resized_crop.scale_min_label": "Scale minimum",
    "random_resized_crop.scale_min_description": "Lower bound for the random area scale relative to the original image (0-1).",
    "random_resized_crop.scale_max_label": "Scale maximum",
    "random_resized_crop.scale_max_description": "Upper bound for the random area scale relative to the original image.",
    "random_resized_crop.ratio_min_label": "Aspect ratio minimum",
    "random_resized_crop.ratio_min_description": "Lower bound for the sampled aspect ratio before resizing.",
    "random_resized_crop.ratio_max_label": "Aspect ratio maximum",
    "random_resized_crop.ratio_max_description": "Upper bound for the sampled aspect ratio before resizing.",
    "random_horizontal_flip.p_label": "Flip probability",
    "random_horizontal_flip.p_description": "Chance that an image is mirrored horizontally.",
    "random_vertical_flip.p_label": "Flip probability",
    "random_vertical_flip.p_description": "Chance that an image is flipped vertically.",
    "random_rotation.min_label": "Minimum degrees",
    "random_rotation.min_description": "Lower rotation bound in degrees (negative values rotate clockwise).",
    "random_rotation.max_label": "Maximum degrees",
    "random_rotation.max_description": "Upper rotation bound in degrees (positive values rotate counter-clockwise).",
    "color_jitter.brightness_label": "Brightness jitter",
    "color_jitter.brightness_description": "Maximum brightness deviation added to each channel.",
    "color_jitter.contrast_label": "Contrast jitter",
    "color_jitter.contrast_description": "Maximum contrast scaling applied to the image.",
    "color_jitter.saturation_label": "Saturation jitter",
    "color_jitter.saturation_description": "Maximum saturation change applied in HSV space.",
    "color_jitter.hue_label": "Hue jitter",
    "color_jitter.hue_description": "Maximum hue shift range (0-0.5).",
    "random_grayscale.p_label": "Grayscale probability",
    "random_grayscale.p_description": "Chance that an image is converted to grayscale.",
    "random_erasing.p_label": "Erasing probability",
    "random_erasing.p_description": "Chance that a random region is erased per image.",
    "random_erasing.scale_min_label": "Scale minimum",
    "random_erasing.scale_min_description": "Lower bound for the erased area scale relative to the whole image.",
    "random_erasing.scale_max_label": "Scale maximum",
    "random_erasing.scale_max_description": "Upper bound for the erased area scale relative to the whole image.",
    "random_erasing.ratio_min_label": "Aspect ratio minimum",
    "random_erasing.ratio_min_description": "Lower bound for the erased patch aspect ratio.",
    "random_erasing.ratio_max_label": "Aspect ratio maximum",
    "random_erasing.ratio_max_description": "Upper bound for the erased patch aspect ratio.",
    "random_erasing.value_label": "Fill value",
    "random_erasing.value_description": "Pixel value used to fill the erased region (0-1).",
    "random_erasing.inplace_label": "In-place",
    "random_erasing.inplace_description": "Apply erasing directly on the input tensor without allocating a copy.",
    "random_perspective.distortion_scale_label": "Distortion scale",
    "random_perspective.distortion_scale_description": "Controls the strength of the perspective distortion (0-1).",
    "random_perspective.p_label": "Perspective probability",
    "random_perspective.p_description": "Chance that a random perspective warp is applied.",
    "center_crop.size_label": "Crop size",
    "center_crop.size_description": "Target edge length in pixels for the centered crop.",
    "preview_section_title": "Preview",
    "preview_description": "Apply the current pipeline to a random dataset image.",
    "preview_button": "Check Preview",
    "preview_idle": "Click Check Preview to see the augmented image.",
    "preview_loading": "Generating preview...",
    "preview_no_project": "Load a project to preview augmentations.",
    "preview_empty_pipeline": "Configure at least one transform to preview.",
    "preview_generic_error": "Failed to generate preview.",
    "preview_original_label": "Original",
    "preview_augmented_label": "Augmented",
    "preview_image_path_label": "Image path"
  },
  "about_ui": {
    "page_title": "About Hootsight",
    "page_description": "Understand the purpose, core architecture, and development principles that shape Hootsight.",
    "card_title": "Image augmentation toolkit for offline-first training",
    "intro": "Hootsight is an offline-first image classification toolkit that pairs PyTorch training with a FastAPI backend and a configuration-driven UI.",
    "content_markdown": "## About Hootsight\n\nHi, I'm Tanathy! The solo developer keeping Hootsight up and running. I built it because I wanted a reliable, offline-first image classification toolkit that I could trust on my own hardware, and I figured other people deserved that freedom too.\n\n### Philosophy\n- Your data never leaves your machine unless you move it. There are no background sync jobs or surprise cloud calls.\n- I refuse to ship telemetry or tracking hooks. Diagnostics stay local so you can choose what gets shared.\n- Every setting lives in JSON. Version it, diff it, throw it in Git—whatever keeps your workflow honest.\n- The installer sets up an isolated virtual environment, keeping your global Python clean.\n- Pretrained weights live under `cache/` so you can back them up, audit them, or torch them in seconds.\n- Roadmaps follow real life. Releases happen when I have the bandwidth, not because a sprint board says go.\n- Tools are neutral; how you use them matters. I expect everyone, myself included, to wield them with care.\n\n>Disclaimer: Every dataset you ingest, every label you predict, and every model you export is your responsibility. Stay mindful of consent, legality, and the humans your work affects.\n\n### Development Status\n- Hootsight is firmly in alpha. Expect updates, experiments, and the occasional rough edge.\n- ResNet has full end-to-end validation. ResNeXt, EfficientNet, and the remaining architectures are still in long-form testing when time permits.\n- Found a bug? Please log it at [GitHub Issues](https://github.com/Tanathy/HootSight/issues). Clear reports help me fix things faster.\n\n### Technical Foundations\n- **Backend**: FastAPI services coordinate dataset discovery, training orchestration, and status endpoints.\n- **ML core**: PyTorch handles training loops, inference, and augmentation pipelines.\n- **Frontend**: A lightweight HTML/JS/CSS interface powered by a tiny helper library (`qte.js`) instead of a heavyweight framework.\n- **Configuration**: Everything is configuration-driven—no shadow defaults tucked in code.\n- **Offline operation**: The app works without internet access. Optional update checks call GitHub only when you ask.\n- **Memory management**: Custom utilities tune batch sizes on the fly and monitor GPU/CPU usage to avoid out-of-memory crashes.\n- **Data handling**: Projects, datasets, checkpoints, and logs stay under your filesystem control. No auto-sync, no remote mirrors.\n\n### Privacy & Compliance\n- Designed with GDPR expectations in mind: no personal data leaves your environment by default.\n- You decide what to import, and you keep full control over editing, exporting, or deleting it.\n- Configuration, logs, and checkpoints remain on disk unless you deliberately share them.\n- Update checks are opt-in and transmit only request metadata; project content never rides along.\n- If you're handling sensitive categories (biometric, medical, anything regulated), map those obligations against your own policies before training.\n- No analytics SDKs, crash reporters, or third-party trackers are bundled with the app.\n\n### Support\nI'm happy to share this project with you to use freely. If you'd like to support my work, you can buy me a coffee at [ko-fi.com/tanathy](https://ko-fi.com/tanathy).\n\n### License & Credits\nHootsight ships with the [Roboto](https://fonts.google.com/specimen/Roboto/license) font, distributed under the SIL Open Font License, Version 1.1."
  },
  "training_ui": {
    "page_title": "Training Setup",
    "page_description": "Configure model architecture, training parameters, and optimization settings.",
    "optimizer_params_title": "Optimizer Parameters",
    "scheduler_params_title": "Scheduler Parameters",
    "loss_params_title": "Loss Parameters",
    "select_type_first": "Select a type to view parameters.",
    "no_extra_params": "No additional parameters for this selection."
  },
  "dataset_ui": {
    "page_title": "Dataset",
    "page_description": "Explore and analyze your dataset structure, labels, and data distribution.",
    "summary": {
      "project": "Project",
      "dataset_type": "Dataset Type",
      "total_images": "Total Images",
      "total_labels": "Total Labels",
      "balance_status": "Balance Status",
      "balance_score": "Balance Score",
      "images_per_label_ideal": "Images per Label (Ideal)",
      "min_images": "Min Images",
      "max_images": "Max Images",
      "max_min_ratio": "Max/Min Ratio"
    },
    "table": {
      "label": "Label",
      "count": "Count",
      "percentage": "Percentage"
    }
  },
  "projects_ui": {
    "page_title": "Projects",
    "page_description": "Manage and switch between different machine learning projects and datasets.",
    "toolbar_hint": "Projects keep datasets, configs, and checkpoints isolated.",
    "toolbar_create": "Create New Project",
    "create_disabled_hint": "Project creation is currently unavailable.",
    "empty_title": "No projects yet",
    "empty_message": "Use Create New Project to scaffold dataset, data_source, model, and heatmap folders.",
    "create_title": "Create new project",
    "create_description": "Name your project to scaffold dataset, data_source, model, and heatmap folders.",
    "create_name_label": "Project name",
    "create_name_placeholder": "e.g. wildlife_classification",
    "create_name_hint": "Use letters, numbers, hyphens, and underscores only.",
    "create_cancel": "Cancel",
    "create_submit": "Create",
    "create_creating": "Creating...",
    "create_validation_required": "Project name is required.",
    "create_validation_length": "Project name must be between {min} and {max} characters.",
    "create_validation_pattern": "Use letters, numbers, hyphens, and underscores only.",
    "create_error_exists": "A project with this name already exists.",
    "create_success_status": "Project {name} created.",
    "create_error_unknown": "Project creation failed.",
    "create_network_error": "Network request failed.",
    "card": {
      "images": "Images",
      "labels": "Labels",
      "balance_score": "Balance Score",
      "balance_status": "Balance",
      "dataset_type": "Dataset Type",
      "status": {
        "balanced": "Balanced",
        "imbalanced": "Imbalanced",
        "critical": "Critical",
        "warning": "Warning",
        "good": "Good",
        "poor": "Poor",
        "excellent": "Excellent",
        "fair": "Fair",
        "ok": "OK",
        "unstable": "Unstable"
      }
    }
  },
  "status_ui": {
    "page_title": "Status",
    "page_description": "Monitor training progress, system status, and real-time performance metrics."
  },
  "heatmap_ui": {
    "page_title": "Heatmap",
    "page_description": "Generate and visualize model attention maps to understand prediction focus areas."
  },
  "projects": {
    "api": {
      "create_missing": "Project name is required.",
      "create_length": "Project name must be between {min} and {max} characters.",
      "create_invalid": "Project name must start with a letter or number and may contain letters, numbers, hyphens, and underscores.",
      "create_exists": "Project {name} already exists.",
      "create_success": "Project {name} created successfully.",
      "create_error": "Failed to create project: {error}",
      "delete_invalid": "Invalid project name.",
      "delete_not_found": "Project {name} does not exist.",
      "delete_success": "Project {name} deleted successfully.",
      "delete_error": "Failed to delete project: {error}",
      "rename_invalid": "Invalid project name.",
      "rename_not_found": "Project {name} does not exist.",
      "rename_missing": "New project name is required.",
      "rename_success": "Project renamed from {old} to {new}.",
      "rename_error": "Failed to rename project: {error}"
    }
  },
  "docs": {
    "api": {
      "missing_root": "Documentation directory is not available.",
      "not_found": "Documentation file {path} was not found.",
      "decode_error": "The requested documentation file could not be decoded.",
      "read_failed": "Documentation retrieval failed: {error}"
    }
  },
  "updates_ui": {
    "page_title": "System Updates",
    "page_description": "Keep your installation aligned with the upstream repository without overwriting project-specific configuration overrides.",
    "card_title": "Update Manager",
    "intro": "Compare local files with the reference repository and synchronize missing fixes while leaving config.json untouched.",
    "check_button": "Check for updates",
    "apply_button": "Apply updates",
    "apply_disabled_hint": "Run a check to enable updates.",
    "status_idle": "No update checks have been run yet.",
    "status_checking": "Checking for updates...",
    "status_ready": "Update summary prepared.",
    "status_up_to_date": "Everything is already up to date.",
    "status_failed": "Update check failed.",
    "status_applying": "Updating files...",
    "status_applied": "Updates applied successfully.",
    "status_apply_failed": "Some updates failed.",
    "table_header_file": "File",
    "table_header_status": "Status",
    "table_header_local": "Local",
    "table_header_remote": "Remote",
    "table_row_missing": "New file",
    "table_row_outdated": "Update available",
    "no_updates": "All tracked files are up to date.",
    "hash_missing": "—",
    "orphaned_title": "Untracked local files",
    "orphaned_none": "No extra local files detected.",
    "files_to_update": "files to update",
    "selected": "selected"
  },
  "docs_ui": {
    "page_title": "Documentation",
    "page_description": "Browse in-app documentation without leaving Hootsight.",
    "sidebar_title": "Documentation",
    "empty": "No documentation files found.",
    "empty_content": "No documentation files available in the docs folder.",
    "loading_placeholder": "Select a document to view.",
    "loading_list": "Loading documentation list...",
    "loading_file": "Loading document...",
    "list_failed": "Failed to load documentation list.",
    "open_externally": "Open raw file",
    "placeholder_title": "Documentation"
  },
  "schema": {
    "description": "JSON Schema for Hootsight config.json - defines types, ranges, and hierarchical structure for all configurable settings",
    "general_description": "General application settings",
    "general_language_description": "UI language code",
    "api_description": "API server configuration",
    "api_host_description": "API server host",
    "api_port_description": "API server port",
    "ui_description": "User interface settings",
    "ui_title_description": "Application window title",
    "ui_width_description": "Window width in pixels",
    "ui_height_description": "Window height in pixels",
    "ui_resizable_description": "Whether the window is resizable",
    "system_description": "System-level settings",
    "system_max_threads_description": "Maximum number of threads",
    "system_fallback_batch_size_description": "Fallback batch size when auto-calculation fails",
    "system_startup_wait_seconds_description": "Startup wait time in seconds",
    "memory_description": "Memory management settings",
    "memory_target_memory_usage_description": "Target memory usage ratio (0.0-1.0)",
    "memory_safety_margin_description": "Safety margin for memory calculations (0.0-1.0)",
    "memory_augmentation_threads_description": "Number of threads for data augmentation",
    "training_description": "Training configuration",
    "training_model_type_description": "Type of model to use",
    "training_model_name_description": "Specific model name",
    "training_pretrained_description": "Initializes the network with ImageNet pretrained weights when available; disable to train from scratch",
    "training_task_description": "Machine learning task type",
    "training_batch_size_description": "Batch size for training",
    "training_epochs_description": "Number of training epochs",
    "training_learning_rate_description": "Learning rate",
    "training_weight_decay_description": "Weight decay (L2 regularization)",
    "training_input_size_description": "Edge length in pixels for the square input tensor (must stay consistent with your augmentation resizing)",
    "training_normalize_description": "Image normalization parameters",
    "training_normalize_mean_description": "Mean values for RGB channels",
    "training_normalize_std_description": "Standard deviation values for RGB channels",
    "training_val_ratio_description": "Validation split ratio (0.0-1.0)",
    "training_dataloader_description": "DataLoader configuration",
    "training_dataloader_num_workers_description": "Number of worker processes",
    "training_dataloader_pin_memory_description": "Whether to pin memory for faster GPU transfer",
    "training_dataloader_persistent_workers_description": "Whether to keep workers alive between epochs",
    "training_dataloader_prefetch_factor_description": "Number of batches to prefetch per worker",
    "training_augmentation_description": "Data augmentation configuration",
    "training_augmentation_train_description": "Training augmentations",
    "training_augmentation_val_description": "Validation augmentations",
    "training_optimizer_type_description": "Optimizer type",
    "training_optimizer_params_description": "Optimizer parameters",
    "training_scheduler_type_description": "Learning rate scheduler type",
    "training_scheduler_params_description": "Scheduler parameters",
    "training_loss_type_description": "Loss function type",
    "training_loss_params_description": "Loss function parameters",
    "training_weight_init_description": "Weight initialization configuration for neural network layers. Proper initialization is crucial for training stability and convergence speed.",
    "training_weight_init_params_description": "Type-specific parameters for the selected weight initialization method. Parameters vary based on the initialization algorithm chosen.",
    "training_checkpoint_description": "Checkpoint configuration",
    "training_early_stopping_description": "Early stopping configuration",
    "training_gradient_description": "Gradient configuration",
    "training_runtime_description": "Runtime performance optimization settings",
    "training_runtime_mixed_precision_description": "Enable automatic mixed precision training",
    "training_runtime_channels_last_description": "Use channels-last memory format for better GPU utilization",
    "training_runtime_allow_tf32_description": "Enable TF32 for faster matrix operations on Ampere+ GPUs",
    "training_runtime_cudnn_benchmark_description": "Enable cuDNN benchmark for optimized convolution algorithms",
    "dataset_description": "Dataset configuration",
    "dataset_input_size_description": "Edge length in pixels for the square input tensor (images will be resized to this dimension)",
    "dataset_image_extensions_description": "Supported image file extensions",
    "dataset_discovery_description": "Dataset discovery heuristics and coverage validation settings",
    "dataset_discovery_annotation_formats_description": "Annotation format specific thresholds used to classify dataset structure",
    "dataset_discovery_txt_annotations_description": "Plain-text label file expectations (YOLO-style .txt alongside images)",
    "dataset_discovery_txt_annotations_min_coverage_percent_description": "Minimum percentage of images that must include .txt annotations before treating the project as text-annotated",
    "dataset_discovery_balance_analysis_description": "Balance analysis thresholds controlling recommendations and warnings",
    "dataset_discovery_balance_analysis_min_images_per_class_description": "Required samples per class before it is considered valid during training",
    "dataset_discovery_balance_analysis_critical_shortage_threshold_description": "Counts below this value are reported as critical shortages",
    "dataset_discovery_balance_analysis_over_representation_ratio_description": "Ratio above ideal distribution that marks classes as over-represented",
    "dataset_discovery_balance_analysis_under_representation_ratio_description": "Ratio below ideal distribution that marks classes as under-represented",
    "dataset_discovery_balance_analysis_severe_over_representation_ratio_description": "Multiplier where over-represented labels become severe warnings",
    "dataset_discovery_balance_analysis_hierarchical_balance_threshold_description": "Minimum balance score expected for hierarchical folder structures",
    "dataset_discovery_balance_analysis_dataset_size_warnings_description": "Dataset size thresholds that trigger small or tiny dataset recommendations",
    "dataset_discovery_balance_analysis_dataset_size_warnings_tiny_dataset_description": "Total image count considered critically small",
    "dataset_discovery_balance_analysis_dataset_size_warnings_small_dataset_description": "Total image count considered small but usable with caution",
  "dataset_discovery_balance_analysis_balance_score_thresholds_description": "Score cutoffs that categorize balance health",
  "dataset_discovery_balance_analysis_balance_score_thresholds_legendary_description": "Balance score required to be labeled legendary",
  "dataset_discovery_balance_analysis_balance_score_thresholds_excellent_description": "Balance score required to be labeled excellent",
  "dataset_discovery_balance_analysis_balance_score_thresholds_very_good_description": "Balance score required to be labeled very good",
  "dataset_discovery_balance_analysis_balance_score_thresholds_good_description": "Balance score required to be labeled good",
  "dataset_discovery_balance_analysis_balance_score_thresholds_balanced_description": "Minimum score still considered balanced",
  "dataset_discovery_balance_analysis_balance_score_thresholds_slightly_unbalanced_description": "Score where minor imbalance warnings begin",
  "dataset_discovery_balance_analysis_balance_score_thresholds_fair_description": "Balance score required to be labeled fair",
  "dataset_discovery_balance_analysis_balance_score_thresholds_poor_description": "Balance score below which balance is marked poor",
  "dataset_discovery_balance_analysis_balance_score_thresholds_very_poor_description": "Balance score below which datasets are extremely unbalanced",
  "dataset_discovery_balance_analysis_balance_score_thresholds_critical_description": "Balance score below which action is critical",
  "dataset_editor_description": "Dataset editor configuration",
  "dataset_editor_page_sizes_description": "Allowed page sizes for the dataset grid pagination.",
  "dataset_editor_default_page_size_description": "Initial page size applied when the dataset editor loads.",
  "dataset_editor_size_presets_description": "Named crop size presets that users can pick from the builder UI.",
  "dataset_editor_default_size_description": "Default crop size applied when no preset is selected.",
  "dataset_editor_build_workers_description": "Worker count used when generating crops in the dataset builder queue.",
  "dataset_editor_discovery_workers_description": "Worker count used while scanning the data_source directory for images.",
    "optimizers_description": "Optimizer defaults override",
    "optimizers_defaults_description": "Default parameters for optimizers",
    "schedulers_description": "Scheduler defaults override",
    "schedulers_defaults_description": "Default parameters for schedulers",
    "schedulers_defaults_lambda_lr_lr_lambda_description": "Lambda function as string, e.g., 'lambda epoch: 0.95 ** epoch'",
    "schedulers_defaults_multiplicative_lr_lr_lambda_description": "Lambda function as string, e.g., 'lambda epoch: 0.95'",
    "losses_description": "Loss defaults override",
    "losses_defaults_description": "Default parameters for losses",
    "activations_description": "Activation function configuration",
    "activations_defaults_description": "Default parameters for activation functions",
    "activations_properties_description": "Activation function properties metadata",
    "activations_defaults_leaky_relu_description": "Leaky ReLU activation parameters",
    "activations_defaults_leaky_relu_negative_slope_description": "Slope of negative region (controls gradient for negative inputs)",
    "activations_defaults_prelu_description": "Parametric ReLU activation parameters",
    "activations_defaults_prelu_num_parameters_description": "Number of learnable slope parameters (1 for shared, channels for per-channel)",
    "activations_defaults_prelu_init_description": "Initial value for the learnable slope parameter",
    "activations_defaults_elu_description": "Exponential Linear Unit parameters",
    "activations_defaults_elu_alpha_description": "Scale factor for negative region",
    "activations_defaults_celu_description": "Continuously Differentiable ELU parameters",
    "activations_defaults_celu_alpha_description": "Scale factor controlling the negative region curvature",
    "activations_defaults_hardtanh_description": "Hard Tanh activation parameters",
    "activations_defaults_hardtanh_min_val_description": "Minimum output value (clips below this)",
    "activations_defaults_hardtanh_max_val_description": "Maximum output value (clips above this)",
    "activations_defaults_hardshrink_description": "Hard Shrinkage activation parameters",
    "activations_defaults_hardshrink_lambd_description": "Threshold value for shrinkage",
    "activations_defaults_softshrink_description": "Soft Shrinkage activation parameters",
    "activations_defaults_softshrink_lambd_description": "Threshold value for soft shrinkage",
    "activations_defaults_threshold_description": "Threshold activation parameters",
    "activations_defaults_threshold_threshold_description": "Threshold value below which input is replaced",
    "activations_defaults_threshold_value_description": "Value to replace inputs below threshold",
    "activations_defaults_softplus_description": "Softplus activation parameters",
    "activations_defaults_softplus_beta_description": "Sharpness of the softplus approximation",
    "activations_defaults_softplus_threshold_description": "Threshold above which function reverts to linear",
    "augmentations_description": "Data augmentation configuration",
    "augmentations_defaults_description": "Default parameters for augmentation transforms",
    "augmentations_properties_description": "Augmentation transform properties metadata",
    "augmentations_defaults_random_crop_description": "Random crop augmentation parameters",
    "augmentations_defaults_random_crop_size_description": "Output crop size in pixels",
    "augmentations_defaults_random_crop_padding_description": "Optional padding before cropping",
    "augmentations_defaults_random_crop_pad_if_needed_description": "Pad image if smaller than crop size",
    "augmentations_defaults_random_crop_fill_description": "Fill value for padding (0-255)",
    "augmentations_defaults_random_crop_padding_mode_description": "Padding mode (constant, edge, reflect, symmetric)",
    "augmentations_defaults_random_resized_crop_description": "Random resized crop parameters",
    "augmentations_defaults_random_resized_crop_size_description": "Output size after crop and resize",
    "augmentations_defaults_random_resized_crop_scale_description": "Scale range for random area selection [min, max]",
    "augmentations_defaults_random_resized_crop_ratio_description": "Aspect ratio range [min, max]",
    "augmentations_defaults_random_resized_crop_interpolation_description": "Interpolation method for resizing",
    "augmentations_defaults_center_crop_description": "Center crop parameters",
    "augmentations_defaults_center_crop_size_description": "Output crop size from center",
    "augmentations_defaults_random_horizontal_flip_description": "Random horizontal flip parameters",
    "augmentations_defaults_random_horizontal_flip_p_description": "Probability of applying the flip",
    "augmentations_defaults_random_vertical_flip_description": "Random vertical flip parameters",
    "augmentations_defaults_random_vertical_flip_p_description": "Probability of applying the flip",
    "augmentations_defaults_random_rotation_description": "Random rotation parameters",
    "augmentations_defaults_random_rotation_degrees_description": "Rotation angle range [min, max] in degrees",
    "augmentations_defaults_random_rotation_interpolation_description": "Interpolation method for rotation",
    "augmentations_defaults_random_rotation_expand_description": "Expand image to fit rotated content",
    "augmentations_defaults_random_rotation_fill_description": "Fill value for areas outside the image",
    "augmentations_defaults_color_jitter_description": "Color jitter parameters",
    "augmentations_defaults_color_jitter_brightness_description": "Brightness variation factor (0 = no change)",
    "augmentations_defaults_color_jitter_contrast_description": "Contrast variation factor (0 = no change)",
    "augmentations_defaults_color_jitter_saturation_description": "Saturation variation factor (0 = no change)",
    "augmentations_defaults_color_jitter_hue_description": "Hue shift factor (0 = no change, max 0.5)",
    "augmentations_defaults_random_grayscale_description": "Random grayscale conversion parameters",
    "augmentations_defaults_random_grayscale_p_description": "Probability of converting to grayscale",
    "augmentations_defaults_random_erasing_description": "Random erasing parameters",
    "augmentations_defaults_random_erasing_p_description": "Probability of applying random erasing",
    "augmentations_defaults_random_erasing_scale_description": "Area scale range [min, max] of erased region",
    "augmentations_defaults_random_erasing_ratio_description": "Aspect ratio range [min, max] of erased region",
    "augmentations_defaults_random_erasing_value_description": "Fill value for erased region (0-255)",
    "augmentations_defaults_random_erasing_inplace_description": "Apply erasing in-place to save memory",
    "augmentations_defaults_normalize_description": "Normalization parameters",
    "augmentations_defaults_normalize_mean_description": "Channel-wise mean values [R, G, B]",
    "augmentations_defaults_normalize_std_description": "Channel-wise standard deviation [R, G, B]",
    "augmentations_defaults_random_invert_description": "Random color inversion parameters",
    "augmentations_defaults_random_invert_p_description": "Probability of inverting colors",
    "augmentations_defaults_random_posterize_description": "Random posterization parameters",
    "augmentations_defaults_random_posterize_bits_description": "Number of bits to keep (1-8)",
    "augmentations_defaults_random_posterize_p_description": "Probability of applying posterization",
    "augmentations_defaults_random_solarize_description": "Random solarization parameters",
    "augmentations_defaults_random_solarize_threshold_description": "Threshold above which pixels are inverted (0-255)",
    "augmentations_defaults_random_solarize_p_description": "Probability of applying solarization",
    "augmentations_defaults_random_adjust_sharpness_description": "Random sharpness adjustment parameters",
    "augmentations_defaults_random_adjust_sharpness_sharpness_factor_description": "Sharpness multiplier (0 = blur, 1 = original, 2+ = sharpen)",
    "augmentations_defaults_random_adjust_sharpness_p_description": "Probability of adjusting sharpness",
    "augmentations_defaults_random_autocontrast_description": "Random auto-contrast parameters",
    "augmentations_defaults_random_autocontrast_p_description": "Probability of applying auto-contrast",
    "augmentations_defaults_random_equalize_description": "Random histogram equalization parameters",
    "augmentations_defaults_random_equalize_p_description": "Probability of applying equalization",
    "augmentations_defaults_random_perspective_description": "Random perspective transformation parameters",
    "augmentations_defaults_random_perspective_distortion_scale_description": "Distortion intensity (0 = none, 1 = maximum)",
    "augmentations_defaults_random_perspective_p_description": "Probability of applying perspective transform",
    "augmentations_defaults_random_perspective_interpolation_description": "Interpolation method for transform",
    "augmentations_defaults_random_perspective_fill_description": "Fill value for areas outside the image",
    "ui_group": {
      "activations_defaults": "Activation Defaults",
      "augmentations_defaults": "Augmentation Defaults"
    },
    "models_description": "Model configurations",
    "models_resnet_description": "ResNet model family settings",
    "models_resnet_variants_description": "ResNet variants configuration",
    "models_resnext_description": "ResNeXt model family settings",
    "models_resnext_variants_description": "ResNeXt variants configuration",
    "models_mobilenet_description": "MobileNet model family settings",
    "models_mobilenet_variants_description": "MobileNet variants configuration",
    "models_shufflenet_description": "ShuffleNet model family settings",
    "models_shufflenet_variants_description": "ShuffleNet variants configuration",
    "models_squeezenet_description": "SqueezeNet model family settings",
    "models_squeezenet_variants_description": "SqueezeNet variants configuration",
    "models_efficientnet_description": "EfficientNet model family settings",
    "models_efficientnet_variants_description": "EfficientNet variants configuration",
    "models_supported_types_description": "Supported model types",
    "general_language_enum_descriptor": {
      "en": "English language - Controls the entire user interface localization including menu labels, error messages, tooltips, and validation text. Affects all text rendering in the web interface and API responses. Determines language pack loading at application startup. Currently the only supported language option, making it the default for all deployments."
    },
    "system_max_threads_enum_descriptor": {
      "auto": "Automatic thread count - Dynamically calculates optimal thread pool size based on available CPU cores (typically cores - 1). Affects parallel data loading, image preprocessing, model inference batching, and background task processing. Controls thread allocation for PyTorch DataLoader workers, image augmentation pipelines, and concurrent HTTP request handling. Automatically scales with hardware capabilities and adjusts based on available system memory."
    },
    "memory_augmentation_threads_enum_descriptor": {
      "auto": "Automatic augmentation thread count - Calculates optimal thread count for parallel image augmentation based on CPU cores and available RAM. Affects image transformation pipeline throughput including rotation, scaling, color jittering, and normalization operations. Controls memory allocation for augmentation buffers and intermediate image storage. Balances CPU utilization against memory pressure to prevent system overload during intensive preprocessing phases."
    },
    "dataset_editor_build_workers_enum_descriptor": {
      "auto": "Automatic builder worker count - Scales dataset build workers based on CPU cores to keep crop generation responsive without starving the main training process."
    },
    "dataset_editor_discovery_workers_enum_descriptor": {
      "auto": "Automatic discovery worker count - Picks a safe number of filesystem scanning workers from the available cores so project discovery stays fast without saturating the system."
    },
    "training_model_type_enum_descriptor": {
      "resnet": "ResNet (Residual Network) - Deep convolutional neural network using skip connections to enable training of very deep networks (18-152 layers). Affects gradient flow, training stability, feature representation depth, and model capacity. Uses residual blocks with batch normalization and ReLU activation. Controls architectural complexity from 11M parameters (ResNet-18) to 60M parameters (ResNet-152). Influences memory usage, training time, inference speed, and final model accuracy across image classification tasks.",
      "resnext": "ResNeXt (Aggregated Residual Transformations) - ResNet evolution using cardinality (grouped convolutions) to increase model capacity without significantly increasing parameter count. Affects feature learning diversity, model expressiveness, and computational efficiency. Controls parallel transformation pathways within each residual block. Impacts GPU memory usage, training duration, and achieves higher accuracy than standard ResNet with similar computational cost.",
      "mobilenet": "MobileNet - Lightweight CNN using depthwise separable convolutions to reduce model size and computational requirements. Affects inference latency, energy consumption, model storage size, and deployment feasibility on mobile devices. Controls trade-off between accuracy and efficiency through width multiplier and resolution parameters. Impacts battery life in mobile applications, real-time processing capability, and edge device compatibility.",
      "shufflenet": "ShuffleNet - Extremely efficient CNN using channel shuffle operations and pointwise group convolutions. Affects memory bandwidth utilization, computational cost per inference, model size, and processing speed. Controls channel communication between group convolutions to maintain information flow. Optimized for ARM processors and low-power devices. Impacts real-time performance requirements and resource-constrained deployment scenarios.",
      "squeezenet": "SqueezeNet - Ultra-compact CNN using Fire modules (squeeze + expand layers) to achieve AlexNet-level accuracy with 50x fewer parameters. Affects model storage requirements, download time, cache efficiency, and deployment bandwidth. Controls parameter count through aggressive dimensionality reduction followed by expansion. Minimizes disk footprint while maintaining reasonable accuracy for basic classification tasks.",
      "efficientnet": "EfficientNet - Compound scaling CNN that uniformly scales network depth, width, and resolution using neural architecture search. Affects computational efficiency, accuracy scaling, training resource requirements, and inference optimization. Controls model complexity through compound coefficient that balances all three dimensions simultaneously. Provides superior accuracy-efficiency trade-offs compared to traditional scaling methods."
    },
    "training_task_enum_descriptor": {
      "classification": "Single-label Classification - Assigns exactly one mutually exclusive class label to each input image. Affects final layer architecture (softmax activation), loss function selection (categorical cross-entropy), output dimensionality (number of classes), and prediction confidence interpretation. Controls model decision boundaries, class probability distribution, and training convergence patterns. Requires balanced dataset distribution and clear class separability for optimal performance.",
      "multi_label": "Multi-label Classification - Assigns zero, one, or multiple non-exclusive class labels simultaneously to each input image. Affects output layer activation (sigmoid per class), loss function composition (binary cross-entropy per label), threshold selection for positive predictions, and evaluation metrics (F1-score, mAP). Controls independent class prediction pathways, label correlation handling, and imbalanced class weight strategies. Handles complex real-world scenarios where images contain multiple semantic concepts.",
      "detection": "Object Detection - Simultaneously localizes and classifies multiple object instances within images using bounding box predictions. Affects model architecture complexity (feature pyramid networks, anchor generation), loss function composition (classification + bounding box regression), training data requirements (annotated bounding boxes), post-processing pipeline (non-maximum suppression), and computational overhead. Controls spatial feature extraction depth, multi-scale object recognition, region proposal mechanisms, and intersection-over-union calculations.",
      "segmentation": "Semantic Segmentation - Performs dense pixel-wise classification to assign semantic class labels to every pixel in the input image. Affects memory requirements (full-resolution feature maps), model architecture (encoder-decoder with skip connections), loss function design (pixel-wise cross-entropy, focal loss for class imbalance), training complexity (handling class imbalance at pixel level), and output resolution constraints. Controls upsampling strategies, boundary refinement quality, spatial precision, and contextual reasoning capabilities."
    },
    "training_epochs_enum_descriptor": {
      "auto": "Automatic epoch determination - Monitors validation loss and accuracy trends to determine optimal training duration using early stopping criteria. Affects total training time, model convergence quality, computational resource usage, and overfitting prevention. Tracks validation metric improvements over patience periods and automatically terminates training when no significant progress is detected. Balances training thoroughness against computational efficiency."
    },
    "training_optimizer_type_enum_descriptor": {
      "sgd": "Stochastic Gradient Descent - Deterministic gradient step with optional momentum and Nesterov lookahead. Exposes learning_rate, momentum, dampening, and weight_decay as the critical knobs. Works best when you can pre-plan a scheduler and want tight control over generalization. Expect strong results on large vision datasets when paired with cosine or step decay, but be ready to tune momentum (0.9 is a typical starting point) and keep learning rates in the 0.01-0.1 range depending on batch size.",
      "adam": "Adam Optimizer - Adaptive first-order method that stores moving averages of gradients (beta1) and squared gradients (beta2). Default betas of 0.9/0.999 and eps of 1e-8 suit most workloads. Handles noisy or sparse gradients without manual learning rate scaling, which makes it a reliable baseline for classification and transfer learning. Watch for sluggish convergence if weight decay is coupled to Adam's adaptive updates; consider AdamW when regularization matters.",
      "adamw": "AdamW Optimizer - Decouples weight decay from Adam's adaptive updates so L2 regularization behaves as intended. Keeps the same beta parameters and epsilon defaults as Adam while exposing weight_decay as a true regularizer. Preferred for vision transformers, ResNet fine-tuning, or any model where you care about stable training with predictable generalization. Start with weight_decay around 0.01 and tune learning_rate between 3e-5 and 3e-4 for transfer learning scenarios.",
      "adamax": "AdaMax Optimizer - Adam variant using the infinity norm for second moment tracking. Similar hyperparameters to Adam, but more resilient when gradients have sporadic spikes. Useful when Adam becomes unstable due to extreme gradient magnitudes, particularly in GAN or reinforcement workloads. Keep beta2 near 0.999 and treat learning_rate like standard Adam; expect slightly slower convergence but fewer catastrophic jumps.",
      "nadam": "Nesterov-accelerated Adam - Adds Nesterov momentum on top of Adam's adaptive scaling. Shares the same betas and epsilon but performs a lookahead gradient evaluation, which can tighten convergence on smooth objectives. Plan for a modest compute overhead per step. Recommended when Adam converges but plateaus early; tune learning_rate slightly lower than plain Adam to avoid overshooting (e.g., 1e-4 instead of 3e-4).",
      "radam": "Rectified Adam - Adam with an automatic warmup mechanism derived from variance rectification. Eliminates the need for a manual warmup schedule by shrinking step sizes until running variance stabilizes. Hyperparameters match Adam defaults. Leverage it when you need adaptive behavior but your training is sensitive to the first few hundred steps. Works well for small datasets where manual warmup would overfit.",
      "rmsprop": "RMSprop Optimizer - Maintains an exponential average of squared gradients (alpha) to normalize updates. Defaults to alpha=0.99 and eps=1e-8. Historically popular for recurrent networks and reinforcement learning, it still performs well when gradients oscillate heavily and Adam feels too aggressive. Pair it with a decaying learning_rate schedule; typical starting values land near 1e-3 with momentum disabled or set low (≤0.1).",
      "rprop": "Resilient Backpropagation - Sign-based optimizer that adapts per-parameter step sizes using only gradient sign flips. Ignores batch size because it assumes full-batch updates, so it is rarely appropriate for mini-batch CNN training. Only use it in deterministic settings (e.g., small datasets with full-batch passes) where you want quick second-order-like convergence without storing a Hessian. Hyperparameters eta_plus (1.2) and eta_minus (0.5) govern step adaptation.",
      "adagrad": "Adagrad Optimizer - Accumulates squared gradients, shrinking the learning rate for frequently updated weights. Almost maintenance-free on sparse features, but the cumulative sum forces the effective learning rate toward zero on long runs. Use it for feature embeddings or classical sparse NLP problems, not for deep CNNs that train for hundreds of epochs. Typical initial learning_rate is 1e-2 with epsilon around 1e-10 to avoid division-by-zero.",
      "adadelta": "Adadelta Optimizer - Fixes Adagrad's vanishing learning rate by tracking a moving window of squared gradients and updates. Requires almost no manual tuning beyond rho (0.9) and eps (1e-6). Works on noisy objectives where Adam may be too aggressive, though its final accuracy often trails AdamW. Prefer it when you must avoid manual learning rate schedules and still need adaptive behavior.",
      "sparse_adam": "Sparse Adam - Adam with updates applied only to indices that receive gradients, reducing memory and compute for embedding tables. Uses the same hyperparameters as Adam but assumes gradients are zero almost everywhere. Essential for NLP models with huge vocabularies. Skip it for dense convolutional models; the sparse update bookkeeping just wastes time.",
      "lbfgs": "L-BFGS Optimizer - Limited-memory quasi-Newton method that approximates the inverse Hessian using past gradients. Requires full-batch gradients and a line search per step, so you must implement a closure that recomputes loss and gradients. Excellent for fine-tuning small models or solving convex problems to high precision. Not viable for large mini-batch training because every step is expensive and memory grows with history size (max_iter and history_size control it).",
      "asgd": "Averaged SGD - Maintains a running average of parameters to dampen oscillations caused by noisy gradients. You still tune the base SGD learning_rate, but averaging kicks in after the averaging_start epoch to smooth convergence. Consider it when plain SGD wobbles at the end of training yet you want to avoid switching to Adam. Works best with constant or slowly decaying learning rates and momentum turned off."
    },
    "training_scheduler_type_enum_descriptor": {
      "step_lr": "Step Learning Rate Scheduler - Multiplies the learning rate by gamma every step_size epochs. Perfect when you already know the epochs where progress slows (e.g., 30/60/90 on ImageNet). Choose gamma between 0.1 and 0.3 and align step_size with your total epoch budget. Without prior knowledge it can feel abrupt, so monitor validation metrics to confirm the drops are helping.",
      "multi_step_lr": "Multi-Step Learning Rate Scheduler - Generalized step schedule that accepts a list of milestone epochs. Lets you stage multiple rate drops at arbitrary points, which is ideal for porting schedules from papers or previous experiments. Keep gamma identical across milestones unless you have a reason to vary it, and make sure milestones are strictly increasing integers.",
      "exponential_lr": "Exponential Learning Rate Scheduler - Applies lr_t = lr_0 * gamma^t, giving you smooth decay in exchange for careful gamma tuning. Works for very long runs where you want a gradual glide instead of discrete jumps. Typical gamma values sit between 0.97 and 0.995 for per-epoch updates. Combine with warmup if the initial slope is too steep for your model.",
      "cosine_annealing_lr": "Cosine Annealing Learning Rate Scheduler - Sweeps the learning rate down following a cosine curve over T_max epochs and optionally restarts at eta_min. Provides gentle landings that boost final accuracy on vision models. Set T_max to the number of epochs in a cycle and eta_min to a small floor such as lr_0 / 100. Use it when you want automatic fine-tuning near the end without manual milestones.",
      "cosine_annealing_warm_restarts": "Cosine Annealing with Warm Restarts - Repeats cosine decay cycles, resetting to the initial learning rate after each cycle. Great for escaping shallow minima during long training sessions. T_0 defines the first cycle length, and T_mult scales subsequent cycle lengths. Keep eta_min small but non-zero to avoid freezing the optimizer.",
      "reduce_lr_on_plateau": "Reduce Learning Rate on Plateau - Watches a metric (usually validation loss) and drops the learning rate by factor when improvement stalls for patience epochs. Essential when you cannot predict plateau timing. Configure cooldown to avoid consecutive triggers and use threshold to filter noisy metrics. Gamma between 0.1 and 0.5 typically strikes the right balance.",
      "cyclic_lr": "Cyclic Learning Rate Scheduler - Cycles the learning rate between base_lr and max_lr over short windows, optionally shrinking amplitude using mode. Useful for fast convergence on tough objectives or for LR range tests. Set step_size_up/down to the number of iterations per half-cycle; keep max_lr roughly 3-10× base_lr. Pair with momentum cycling if you enable cycle_momentum.",
      "one_cycle_lr": "One Cycle Learning Rate Policy - Single sweep that ramps learning rate up to max_lr then anneals to a fraction of the base value while inverting momentum. Delivers rapid convergence when total training steps are known. Provide either total_steps or (epochs × steps_per_epoch); set pct_start to define the warmup proportion (0.3 is common). Works best with SGD or AdamW and expects no additional schedulers.",
      "polynomial_lr": "Polynomial Learning Rate Scheduler - Decays learning rate to zero following (1 - t/T)^power. Choose total_iters as the number of optimizer steps in the schedule and power to control curvature (1 for linear, 2 for quadratic). Useful for segmentation and detection workloads where you want a deterministic glide to zero by the final iteration.",
      "linear_lr": "Linear Learning Rate Scheduler - Simple linear interpolation between start_factor and end_factor over total_iters steps. Ideal for warmup (start_factor < 1) or cool-down phases. Keep total_iters aligned with the number of iterations you want the ramp to cover; combine with another scheduler for the remaining training window.",
      "lambda_lr": "Lambda Learning Rate Scheduler - Direct hook that multiplies the base learning rate by your custom lambda(epoch) function. Gives full control for research schedules or curriculum learning. Provide a Python expression that evaluates to a float; remember it will be string-evaluated inside the training process. Validate the function carefully—syntax errors or negative outputs will kill your run.",
      "multiplicative_lr": "Multiplicative Learning Rate Scheduler - Similar to lambda_lr but expects a callable that returns a multiplier each step, often used for epoch-by-epoch scaling. Supply a lambda that depends on optimizer step count rather than epoch if you need per-iteration control. Keep multipliers positive and bounded; values >1 grow the learning rate and can destabilize training fast."
    },
    "training_loss_type_enum_descriptor": {
      "cross_entropy": "Cross-Entropy Loss - Softmax + negative log-likelihood in one call. The go-to choice for single-label classification. Accepts raw logits, handles class imbalance via weight or label_smoothing, and provides calibrated probabilities. Keep reduction='mean' for stable gradients and monitor label_smoothing so you do not erase minority classes.",
      "nll_loss": "Negative Log-Likelihood Loss - Same math as cross-entropy but expects you to call log_softmax yourself. Useful when the model already outputs log-probabilities (e.g., custom temperature scaling or mixed precision under manual control). Make sure inputs are log probabilities; feeding raw logits will silently give garbage.",
      "bce_loss": "Binary Cross-Entropy Loss - Works on probabilities in [0,1], so pair it with an explicit sigmoid. Suitable for binary classification when you need to control the activation separately. Beware of numerical underflow on extreme logits—clip the inputs or switch to BCEWithLogitsLoss if you see NaNs.",
      "bce_with_logits": "Binary Cross-Entropy with Logits - Numerically stable BCE that applies sigmoid internally. Default option for multi-label classification and binary tasks. Supports pos_weight for class imbalance without manual weighting hacks. Outputs unbounded loss if you forget to clamp targets to {0,1}.",
      "multi_margin": "Multi-Class Margin Loss - Margin-based classification objective (hinge-style) that pushes the correct class score above others by at least margin. Offers optional L1 or L2 norms via parameter p. Use it when you want large-margin behavior instead of probabilistic cross-entropy, but note that it can converge slower without careful learning rate control.",
      "multi_label_margin": "Multi-Label Margin Loss - Extends margin loss to multi-label problems by ranking positive classes ahead of negatives. Requires targets to be encoded as index lists and therefore is tricky to integrate with dense label tensors. Reserve it for research scenarios that explicitly call for margin ranking in multi-label space.",
      "multi_label_soft_margin": "Multi-Label Soft Margin Loss - Applies a soft-margin formulation over sigmoid activations, producing smoother gradients than hard margin losses. Better at handling overlapping labels and imbalance than vanilla BCE. Targets must still be {0,1}; consider threshold tuning at inference to exploit the smoother training landscape.",
      "mse_loss": "Mean Squared Error Loss - Classic L2 regression penalty. Penalizes large errors quadratically, which magnifies the impact of outliers. Great for autoencoders and low-noise regression, but consider clipping extreme targets or swapping to Huber when you see gradient explosions.",
      "l1_loss": "L1 Loss (Mean Absolute Error) - Linear penalty on absolute error, offering robustness to outliers at the cost of slower convergence near zero. Use it when you need median-like behavior or when your evaluation metric is MAE. Gradients are constant magnitude, so combine with smooth schedulers to avoid jitter.",
      "smooth_l1": "Smooth L1 Loss - Huber-style loss with a beta region that behaves like L2 near zero and L1 outside. Default choice for bounding-box regression (beta ≈ 1). Tune beta if your scale differs significantly; smaller beta tightens the quadratic window and gives sharper penalties to mid-sized errors.",
      "huber_loss": "Huber Loss - Similar to SmoothL1 but parameterized by delta instead of beta. Offers explicit control over the switch point between quadratic and linear penalties. Excellent for regression tasks with occasional outliers; set delta close to your expected noise standard deviation.",
      "kl_div": "Kullback-Leibler Divergence Loss - Measures divergence between a predicted distribution and a target distribution. Requires log-probabilities as input and raw probabilities as target by default (or vice versa with log_target). Essential for knowledge distillation and variational models. Double-check reduction mode; 'batchmean' preserves KL theory (summing over classes and averaging over batch).",
      "margin_ranking": "Margin Ranking Loss - Operates on pairs of scores (x1, x2) with ground-truth ordering y ∈ {−1, 1}. Trains the model to rank x1 above x2 by at least margin when y=1. Combine it with careful sampling of positive/negative pairs or triplets—random pairs rarely convey useful signal.",
      "hinge_embedding": "Hinge Embedding Loss - For similarity learning where labels indicate whether pairs should be close (+1) or far (−1). Penalizes distances that violate the specified margin. Use it when you only have binary same/different supervision and want embeddings clustered accordingly.",
      "triplet_margin": "Triplet Margin Loss - Consumes anchor, positive, and negative embeddings and enforces a margin between positive and negative distances. Requires hard or semi-hard triplet mining to shine; naive random triplets usually waste computation. Margin defaults to 1.0 but tune it based on embedding scale (smaller for normalized vectors).",
      "cosine_embedding": "Cosine Embedding Loss - Optimizes cosine similarity directly, emphasizing angular distance over magnitude. Ideal when vectors are normalized or when direction carries the semantics (e.g., face recognition). Ensure embeddings are normalized to avoid mixing magnitude effects back in.",
      "ctc_loss": "Connectionist Temporal Classification Loss - Aligns variable-length inputs to target label sequences without frame-level annotation. Requires log-probabilities with size (T, N, C) and target sequences without blanks inserted (the loss handles blanks). Configure blank index and ensure targets are sorted by sample; mis-sized target lengths will throw runtime errors.",
      "poisson_nll": "Poisson Negative Log-Likelihood Loss - For modeling count data where targets are non-negative integers. Accepts log_input to enforce positive predictions or full logits with clamp to stay above zero. Set full=True if your model predicts raw rates. Do not feed negative targets; the distribution assumption breaks immediately.",
      "gaussian_nll": "Gaussian Negative Log-Likelihood Loss - Trains a model to output both mean and variance for continuous targets. Expects the model to return (mean, variance) tensors. Supports full covariance via cholesky_factor; otherwise variance must stay positive. Great for uncertainty-aware regression; add a small epsilon to variance to avoid log(0) issues."
    },
    "training_loss_reduction_enum_descriptor": {
      "mean": "Mean Reduction - Computes average loss across all batch elements by dividing total loss by batch size. Affects gradient magnitude normalization, batch size independence, training stability, and learning rate sensitivity. Controls loss scaling to provide consistent gradients regardless of batch size variations. Standard choice for most training scenarios as it maintains gradient magnitudes proportional to individual sample errors rather than batch size.",
      "sum": "Sum Reduction - Computes total loss by summing all individual sample losses in the batch without normalization. Affects gradient magnitude scaling, batch size dependency, learning rate requirements, and training dynamics. Controls loss accumulation that results in larger gradients for bigger batches, requiring learning rate adjustment proportional to batch size. Useful when you want gradient magnitude to scale with the number of samples processed.",
      "none": "No Reduction - Returns individual loss values for each sample in the batch without any aggregation operation. Affects custom loss weighting capabilities, sample-specific analysis, manual loss combination, and advanced training strategies. Controls individual sample loss access for implementing custom reduction schemes, sample importance weighting, or detailed loss analysis. Essential for advanced applications requiring per-sample loss manipulation."
    },
    "training_early_stopping_monitor_enum_descriptor": {
      "val_loss": "Validation Loss Monitoring - Early stopping mechanism that tracks validation loss values to determine when training should halt due to lack of improvement. Affects overfitting prevention, training duration optimization, model generalization quality, and computational resource usage. Controls training termination based on loss plateauing, which typically indicates the model has learned the generalizable patterns and further training may lead to overfitting. Particularly effective for regression tasks and situations where loss minimization directly correlates with model quality.",
      "val_accuracy": "Validation Accuracy Monitoring - Early stopping mechanism that tracks validation accuracy metrics to determine optimal training termination point. Affects model performance optimization, overfitting detection, training efficiency, and final model quality. Controls training halt based on accuracy plateaus, focusing on classification performance rather than loss minimization. Most suitable for balanced classification tasks where accuracy is the primary success metric and correlates well with model generalization capability."
    },
    "weight_init_type_enum_descriptor": {
      "kaiming_normal": "Kaiming Normal (He Normal) - Initializes weights from a normal distribution with variance scaled by 2/fan_in. Designed for layers with ReLU activation, accounting for the fact that ReLU zeros out half the neurons. Best for deep networks using ReLU/LeakyReLU activations.",
      "kaiming_uniform": "Kaiming Uniform (He Uniform) - Initializes weights from a uniform distribution with bounds scaled by sqrt(6/fan_in). Variant of Kaiming initialization using uniform sampling. Good for ReLU-based networks when uniform distribution is preferred.",
      "xavier_normal": "Xavier Normal (Glorot Normal) - Initializes weights from a normal distribution with variance scaled by 2/(fan_in + fan_out). Designed for symmetric activations like tanh and sigmoid. Maintains variance across layers for proper gradient flow.",
      "xavier_uniform": "Xavier Uniform (Glorot Uniform) - Initializes weights from a uniform distribution with bounds calculated from fan_in and fan_out. Classic initialization for networks with symmetric activations. Widely used default for many architectures.",
      "normal": "Normal Distribution - Initializes weights from a standard normal distribution with specified mean and standard deviation. Simple initialization allowing direct control over weight statistics. Useful for custom initialization schemes.",
      "uniform": "Uniform Distribution - Initializes weights from a uniform distribution within specified bounds [a, b]. Basic initialization with direct control over weight range. Suitable when specific weight bounds are required.",
      "trunc_normal": "Truncated Normal - Initializes weights from a truncated normal distribution, clipping values beyond specified bounds. Prevents extreme weight values while maintaining normal-like distribution. Used in Vision Transformer (ViT) architectures.",
      "orthogonal": "Orthogonal Initialization - Initializes weight matrices to be orthogonal, preserving gradient norms during backpropagation. Excellent for RNNs and deep networks where gradient preservation is critical. Helps prevent vanishing/exploding gradients.",
      "sparse": "Sparse Initialization - Initializes weight matrices with a specified fraction of zero elements. Creates sparse connectivity patterns, reducing initial parameter influence. Useful for networks where sparsity is desired.",
      "constant": "Constant Value - Initializes all weights to a single constant value. Typically used for biases or specific layer requirements. Not recommended for weight matrices due to symmetry breaking issues.",
      "zeros": "Zero Initialization - Initializes all weights to zero. Generally only appropriate for bias terms. Not suitable for weight matrices as it prevents learning due to symmetry.",
      "ones": "Ones Initialization - Initializes all weights to one. Specialized use cases only, such as certain normalization layers. Not appropriate for general weight initialization.",
      "eye": "Identity (Eye) Matrix - Initializes weight matrices as identity matrices. Useful for skip connections or residual-style architectures. Preserves input dimensions through the layer initially.",
      "dirac": "Dirac Delta Initialization - Initializes convolutional kernels as Dirac delta functions (identity-like for convolutions). Creates initial identity mapping for convolutional layers. Useful in residual network designs."
    },
    "optimizers_defaults_lbfgs_line_search_fn_oneOf[1]_enum_descriptor": {
      "strong_wolfe": "Strong Wolfe Line Search - Advanced line search algorithm for L-BFGS optimization that ensures both sufficient decrease (Armijo condition) and curvature conditions (strong Wolfe conditions). Affects optimization convergence quality by guaranteeing appropriate step sizes that satisfy mathematical optimality criteria. Controls step length selection through rigorous mathematical conditions that ensure convergence properties while maintaining computational efficiency. Essential for L-BFGS theoretical guarantees and provides robust step size selection for quasi-Newton optimization methods."
    },
    "schedulers_defaults_reduce_lr_on_plateau_mode_enum_descriptor": {
      "min": "Minimum Mode - Monitors metrics where lower values indicate better performance (such as validation loss). Affects learning rate reduction trigger by tracking when monitored metric stops decreasing below the threshold for the specified patience period. Controls scheduler behavior to reduce learning rate when loss plateaus, preventing training stagnation. Optimal for loss-based monitoring where decreasing values represent training progress.",
      "max": "Maximum Mode - Monitors metrics where higher values indicate better performance (such as validation accuracy). Affects learning rate reduction trigger by tracking when monitored metric stops increasing above the threshold for the specified patience period. Controls scheduler behavior to reduce learning rate when accuracy plateaus, enabling further fine-tuning. Optimal for accuracy-based monitoring where increasing values represent training progress."
    },
    "schedulers_defaults_reduce_lr_on_plateau_threshold_mode_enum_descriptor": {
      "rel": "Relative Threshold Mode - Defines improvement threshold as a percentage of the current best metric value. Affects sensitivity to metric improvements by requiring proportional changes relative to current performance level. Controls adaptive threshold scaling that becomes more stringent as model performance improves. Useful when improvement magnitude should scale with current metric values, preventing premature learning rate reduction in high-performing models.",
      "abs": "Absolute Threshold Mode - Defines improvement threshold as a fixed absolute value that must be exceeded regardless of current metric level. Affects improvement detection sensitivity through constant threshold requirements independent of current performance. Controls uniform improvement standards throughout training regardless of metric magnitude. Useful when consistent improvement levels are required regardless of current model performance state."
    },
    "schedulers_defaults_cyclic_lr_mode_enum_descriptor": {
      "triangular": "Triangular Cycle Mode - Creates basic triangular learning rate cycles with constant amplitude throughout training. Affects learning rate oscillation pattern through linear increases and decreases between base_lr and max_lr boundaries. Controls consistent exploration-exploitation balance with fixed learning rate range. Provides simple cyclic learning rate patterns suitable for finding optimal learning rate ranges without decay.",
      "triangular2": "Triangular2 Cycle Mode - Creates triangular learning rate cycles with amplitude halving after each complete cycle. Affects learning rate range reduction over time while maintaining triangular oscillation pattern. Controls gradual learning rate decay within cyclical framework, combining benefits of cycling with progressive refinement. Enables aggressive initial exploration with increasingly conservative learning rate adjustments.",
      "exp_range": "Exponential Range Mode - Scales learning rate cycle amplitude exponentially using gamma factor for dynamic range adjustment. Affects learning rate bound modification through exponential scaling of max_lr relative to cycle number. Controls sophisticated amplitude evolution that can increase or decrease cycle magnitude based on gamma value. Provides advanced cyclic learning rate patterns with exponential amplitude modulation."
    },
    "schedulers_defaults_cyclic_lr_scale_mode_enum_descriptor": {
      "cycle": "Cycle-based Scaling Mode - Applies scaling function based on completed cycle count rather than individual iteration steps. Affects scale function evaluation frequency and learning rate amplitude modification rhythm. Controls scaling application at cycle boundaries, enabling different amplitude adjustments for each complete learning rate cycle. Useful when scaling behavior should change discretely between cycles rather than continuously throughout training.",
      "iterations": "Iteration-based Scaling Mode - Applies scaling function based on total iteration count since training start, providing continuous scaling evolution. Affects scale function evaluation at every step, enabling smooth amplitude transitions throughout training process. Controls fine-grained scaling application that evolves continuously rather than at discrete cycle boundaries. Useful when gradual, continuous scaling changes are preferred over step-wise cycle-based adjustments."
    },
    "schedulers_defaults_one_cycle_lr_anneal_strategy_enum_descriptor": {
      "cos": "Cosine Annealing Strategy - Uses cosine function for smooth learning rate transitions with gradual changes at extremes and steeper changes in middle regions. Affects learning rate trajectory smoothness by providing natural acceleration and deceleration phases. Controls sinusoidal learning rate evolution that mimics natural optimization dynamics. Particularly effective for achieving smooth convergence with reduced oscillations near learning rate boundaries.",
      "linear": "Linear Annealing Strategy - Uses linear interpolation for constant rate learning rate changes throughout the cycle. Affects learning rate transitions through uniform progression without acceleration or deceleration phases. Controls predictable, steady learning rate evolution with consistent change rate. Simpler alternative when smooth cosine transitions are not required and uniform learning rate progression is preferred."
    },
    "losses_defaults_multi_margin_p_enum_descriptor": {
      "1": "L1 Norm (Manhattan Distance) - Uses absolute differences for margin calculation in multi-margin loss function. Affects loss computation through linear penalty that treats all errors uniformly regardless of magnitude. Controls distance measurement using sum of absolute differences between predicted and target values. Provides robust margin calculation less sensitive to outliers compared to L2 norm, making it suitable when training data contains significant noise or extreme values.",
      "2": "L2 Norm (Euclidean Distance) - Uses squared differences for margin calculation in multi-margin loss function. Affects loss computation through quadratic penalty that heavily penalizes larger errors while being lenient on smaller ones. Controls distance measurement using sum of squared differences between predicted and target values. Provides smooth gradient characteristics and strong penalty for large margin violations, making it suitable for clean data where large errors should be heavily discouraged."
    },
    "losses_defaults_kl_div_reduction_enum_descriptor": {
      "none": "No Reduction - Returns individual KL divergence values for each sample without aggregation. Affects loss output dimensionality by preserving per-sample loss values for custom processing or analysis. Controls individual sample loss access enabling sample-specific weighting, filtering, or detailed loss examination. Essential for advanced training strategies requiring per-sample loss manipulation or when implementing custom reduction schemes.",
      "mean": "Mean Reduction - Computes average KL divergence across all elements in the batch including spatial dimensions. Affects gradient scaling by normalizing loss magnitude relative to total number of elements rather than batch size alone. Controls loss scaling that accounts for both batch size and spatial dimensions in dense prediction tasks. Provides consistent gradients regardless of input resolution or batch composition.",
      "sum": "Sum Reduction - Computes total KL divergence by summing all individual element divergences without normalization. Affects gradient magnitude scaling proportionally to total number of elements in batch and spatial dimensions. Controls loss accumulation that results in larger gradients for bigger batches or higher resolution inputs. Requires careful learning rate adjustment when batch sizes or input dimensions vary significantly.",
      "batchmean": "Batch Mean Reduction - Computes mean KL divergence over batch dimension only, preserving spatial dimension contributions. Affects loss computation by averaging across samples while maintaining full spatial loss contribution. Controls standard KL divergence reduction that focuses on sample-wise averaging rather than element-wise normalization. Recommended reduction method for KL divergence loss as it preserves theoretical properties while providing stable training dynamics."
    },
    "models_resnet_default_optimizer_type_enum_descriptor": {
      "adamw": "AdamW Optimizer for ResNet - Adam with decoupled weight decay specifically tuned for ResNet architectures. Affects regularization effectiveness and training stability through proper separation of gradient-based adaptation and L2 penalty. Controls weight decay independently from gradient updates, preventing regularization interference with adaptive learning rates. Recommended default choice for ResNet models due to superior generalization performance and stable training characteristics across various ResNet depths and datasets.",
      "adam": "Adam Optimizer for ResNet - Classic adaptive moment estimation algorithm providing automatic learning rate scaling for ResNet training. Affects convergence speed and hyperparameter sensitivity through per-parameter learning rate adaptation. Controls momentum and squared gradient estimates to balance exploration and exploitation during ResNet optimization. Good general-purpose choice offering reliable performance across different ResNet variants with minimal hyperparameter tuning requirements.",
      "sgd": "SGD with Momentum for ResNet - Traditional stochastic gradient descent with momentum specifically configured for ResNet training. Affects training dynamics through momentum accumulation and requires careful learning rate scheduling for optimal performance. Controls parameter updates through momentum-based acceleration while maintaining deterministic optimization behavior. Traditional choice that achieves excellent results with proper tuning but requires more careful hyperparameter selection compared to adaptive optimizers."
    },
    "models_resnet_default_scheduler_type_enum_descriptor": {
      "step_lr": "Step Learning Rate for ResNet - Step-based learning rate decay with predetermined milestone epochs optimized for ResNet training phases. Affects learning rate reduction at specific training stages corresponding to ResNet convergence patterns. Controls deterministic learning rate schedule that aligns with typical ResNet training progression and loss landscape characteristics. Suitable when optimal decay epochs are known from prior ResNet experiments or research papers with similar datasets and architectures.",
      "cosine_annealing_lr": "Cosine Annealing for ResNet - Smooth cosine-based learning rate schedule that often improves ResNet final accuracy through gradual learning rate reduction. Affects training dynamics by providing smooth transitions that help ResNet models achieve better final convergence. Controls sinusoidal learning rate progression that reduces training oscillations and enables fine-tuned parameter adjustment in later training phases. Frequently achieves superior final accuracy compared to step-based schedules for ResNet architectures.",
      "reduce_lr_on_plateau": "Adaptive Scheduling for ResNet - Plateau-based learning rate reduction that automatically responds to ResNet training stagnation periods. Affects learning rate adaptation through validation metric monitoring, reducing learning rate when ResNet training progress plateaus. Controls automatic schedule adjustment that responds to actual training dynamics rather than predetermined milestones. Optimal for ResNet training when optimal decay timing is unknown or when training characteristics vary across different datasets or experimental conditions."
    },
    "paths_description": "Paths configuration",
    "paths_projects_dir_description": "Directory containing project folders",
    "paths_ui_dir_description": "Directory containing UI assets",
    "paths_config_dir_description": "Directory containing configuration files",
    "paths_localizations_dir_description": "Directory containing localization files",
    "paths_packages_file_description": "Path to packages.jsonc file",
    "paths_cache_dir_description": "Directory for cache files",
    "system_http_timeout_description": "HTTP timeout in seconds for remote operations",
    "system_update_repository_url_description": "URL of the remote repository for system updates",
    "system_update_skip_paths_description": "List of paths to skip during system updates",
    "dataset_editor_project_name_validation_description": "Project name validation rules",
    "dataset_editor_project_name_validation_min_length_description": "Minimum length for project names",
    "dataset_editor_project_name_validation_max_length_description": "Maximum length for project names",
    "dataset_editor_project_name_validation_pattern_description": "Regular expression pattern for project name validation"
  },
  "status_graph": {
    "epoch_accuracy": "Epoch Accuracy",
    "epoch_loss": "Epoch Loss",
    "step_loss": "Step Loss",
    "learning_rate": "Learning Rate",
    "loss": "Loss",
    "no_data": "Waiting for updates",
    "no_training": "No active training.",
    "active_count": "Active trainings: {count}",
    "label_training_id": "Training ID",
    "label_status": "Status",
    "label_phase": "Phase",
    "label_epoch": "Epoch",
    "label_step": "Step",
    "badge_training": "Training: {project}",
    "footer_training": "Training {project} — Epoch {epoch} • Step {step}"
  },
  "updates": {
    "log": {
      "check_started": "Checking upstream checksums...",
      "check_complete": "Update check complete. Pending files: {count}",
      "check_failed": "Update check failed: {error}",
      "remote_config_failed": "Failed to download remote config.json: {error}",
      "remote_checksum_failed": "Failed to download remote checksum manifest: {error}",
      "remote_payload_invalid": "Remote payload from {url} was not a mapping.",
      "local_checksum_missing": "Local checksum.json missing; assuming empty manifest.",
      "local_checksum_invalid": "Failed to parse local checksum.json: {error}",
      "path_escape": "Blocked unsafe path {path}",
      "apply_started": "Applying updates...",
      "apply_failed": "Failed to apply updates: {error}",
      "apply_nothing": "No updates required.",
      "apply_file_success": "Updated {path}",
      "apply_file_failed": "Failed to update {path}: {error}",
      "apply_partial": "Applied {updated} updates with {failed} failures.",
      "apply_complete": "Applied {count} updates."
    },
    "api": {
      "check_success": "Update check completed. {count} file(s) pending.",
      "check_no_updates": "Everything is already up to date.",
      "check_failed": "Update check failed: {error}",
      "apply_success": "Updates applied successfully. {updated} file(s) updated.",
      "apply_partial": "Updates applied with {updated} success and {failed} failure(s).",
      "apply_failed": "Failed to apply updates: {error}",
      "apply_nothing": "No updates were necessary."
    },
    "status": {
      "missing": "New file",
      "outdated": "Update available"
    }
  },
  "status": {
    "project_load_failed": "Project load failed",
    "project_loading": "Loading project {projectName}...",
    "project_loaded_custom": "Loaded project {projectName} with custom config",
    "project_loaded_defaults": "Loaded project {projectName} with global defaults",
    "project_load_error": "Failed to load project {projectName}: {error}",
    "no_project_loaded": "No project loaded",
    "validation_errors": "Fix validation errors before saving",
    "saving_training_config": "Saving training config...",
    "training_config_saved": "Training config saved",
    "save_failed": "Save failed",
    "loading_schema": "Loading schema & config...",
    "init_failed": "Init failed",
    "checking_updates": "Checking for updates...",
    "updates_ready": "Updates available",
    "updates_none": "No updates available",
    "updates_check_failed": "Update check failed",
    "updates_applying": "Applying updates...",
    "updates_applied": "Updates applied successfully",
    "updates_apply_failed": "Update apply failed",
    "generating_heatmap": "Generating heatmap...",
    "heatmap_generated": "Heatmap generated",
    "heatmap_generation_failed": "Heatmap generation failed",
    "saving_system_settings": "Saving system settings...",
    "system_settings_saved": "System settings saved",
    "starting_training": "Starting training...",
    "training_started": "Training started",
    "training_stopping": "Stopping training...",
    "training_stop_requested": "Training stop requested",
    "training_stop_failed": "Training stop failed",
    "training_start_failed": "Training start failed",
    "switching_language": "Switching language...",
    "language_switched": "Language switched successfully",
    "language_switch_failed": "Language switch failed",
    "augmentation_preview_ready": "Augmentation preview generated"
  }
}
