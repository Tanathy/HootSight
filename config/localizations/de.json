{
  "language_name": "Deutsch",
  "app": {
    "page_not_found": {
      "title": "Seite nicht gefunden",
      "description": "Die angeforderte Seite existiert nicht"
    }
  },
  "updates": {
    "status": {
      "missing": "Fehlt",
      "outdated": "Veraltet",
      "orphaned": "Verwaist"
    },
    "api": {
      "check_failed": "Fehler beim Suchen nach Updates: {error}",
      "check_success": "{count} Updates verfügbar",
      "check_no_updates": "Keine Updates verfügbar",
      "apply_failed": "Fehler beim Anwenden der Updates: {error}",
      "apply_nothing": "Keine Updates anzuwenden",
      "apply_partial": "Teilweises Update: {updated} aktualisiert, {failed} fehlgeschlagen",
      "apply_success": "Update abgeschlossen: {updated} Datei(en) aktualisiert"
    }
  },
  "projects": {
    "api": {
      "create_missing": "Projektname ist erforderlich",
      "create_length": "Projektname muss zwischen {min} und {max} Zeichen lang sein",
      "create_invalid": "Ungültiger Projektname",
      "create_exists": "Projekt '{name}' existiert bereits",
      "create_error": "Fehler beim Erstellen des Projekts: {error}",
      "create_success": "Projekt '{name}' erfolgreich erstellt",
      "delete_invalid": "Ungültiger Projektname",
      "delete_not_found": "Projekt '{name}' nicht gefunden",
      "delete_success": "Projekt '{name}' erfolgreich gelöscht",
      "delete_error": "Fehler beim Löschen des Projekts: {error}",
      "rename_invalid": "Ungültiger Projektname",
      "rename_not_found": "Projekt '{name}' nicht gefunden",
      "rename_missing": "Neuer Projektname ist erforderlich",
      "rename_success": "Projekt erfolgreich in '{name}' umbenannt",
      "rename_error": "Fehler beim Umbenennen des Projekts: {error}"
    }
  },
  "dataset_editor": {
    "api": {
      "project_not_found": "Projekt '{project}' nicht gefunden",
      "image_not_found": "Keine Bilder im Projekt '{project}' gefunden",
      "invalid_page_size": "Ungültige Seitengröße. Erlaubt: {allowed}",
      "invalid_size": "Ungültige Größe. Erlaubt: {allowed}",
      "invalid_image_path": "Ungültiger Bildpfad",
      "image_missing": "Bilddatei nicht gefunden"
    }
  },
  "docs": {
    "api": {
      "missing_root": "Dokumentations-Root nicht konfiguriert",
      "not_found": "Dokument '{path}' nicht gefunden",
      "decode_error": "Fehler beim Dekodieren von '{path}'",
      "read_failed": "Fehler beim Lesen des Dokuments: {error}"
    }
  },
  "augmentation": {
    "preview_invalid_phase": "Ungültige Augmentationsphase: {phase}",
    "preview_no_images": "Keine Bilder im Projekt '{project}' gefunden",
    "preview_failed": "Fehler beim Generieren der Vorschau: {error}"
  },
  "augmentations": {
    "resize": "Größe ändern",
    "random_crop": "Zufälliger Zuschnitt",
    "random_resized_crop": "Zufälliger skalierter Zuschnitt",
    "center_crop": "Zentrierter Zuschnitt",
    "random_affine": "Zufällige affine Transformation",
    "random_horizontal_flip": "Zufälliges horizontales Spiegeln",
    "random_vertical_flip": "Zufälliges vertikales Spiegeln",
    "random_rotation": "Zufällige Rotation",
    "color_jitter": "Farb-Jitter",
    "random_grayscale": "Zufällige Graustufen",
    "random_erasing": "Zufälliges Löschen",
    "normalize": "Normalisieren",
    "random_invert": "Zufälliges Invertieren",
    "random_posterize": "Zufälliges Posterisieren",
    "random_solarize": "Zufälliges Solarisieren",
    "random_adjust_sharpness": "Zufällige Schärfeanpassung",
    "random_autocontrast": "Zufälliger Autokontrast",
    "random_equalize": "Zufällige Entzerrung",
    "random_perspective": "Zufällige Perspektive"
  },
  "common": {
    "project_label": "Projekt:",
    "cancel": "Abbrechen"
  },
  "params": {
    "lr": "Lernrate",
    "betas": "Betas",
    "eps": "Epsilon",
    "weight_decay": "Gewichtsabnahme (Weight Decay)",
    "amsgrad": "AMSGrad",
    "momentum": "Momentum",
    "dampening": "Dämpfung",
    "nesterov": "Nesterov",
    "alpha": "Alpha",
    "centered": "Zentriert",
    "etas": "Etas",
    "step_sizes": "Schrittgrößen",
    "lr_decay": "LR-Abnahme",
    "initial_accumulator_value": "Anfänglicher Akkumulator",
    "rho": "Rho",
    "max_iter": "Max. Iterationen",
    "max_eval": "Max. Evaluationen",
    "tolerance_grad": "Gradienten-Toleranz",
    "tolerance_change": "Änderungs-Toleranz",
    "history_size": "Verlaufsgröße",
    "line_search_fn": "Line-Search-Funktion",
    "lambd": "Lambda",
    "t0": "T0",
    "momentum_decay": "Momentum-Abnahme",
    "step_size": "Schrittgröße",
    "gamma": "Gamma",
    "milestones": "Meilensteine",
    "T_max": "T Max",
    "eta_min": "Eta Min",
    "T_0": "T0",
    "T_mult": "T Multiplikator",
    "mode": "Modus",
    "factor": "Faktor",
    "patience": "Geduld (Patience)",
    "threshold": "Schwellenwert",
    "threshold_mode": "Schwellenwert-Modus",
    "cooldown": "Abklingzeit",
    "min_lr": "Min. LR",
    "base_lr": "Basis LR",
    "max_lr": "Max. LR",
    "step_size_up": "Schrittgröße hoch",
    "step_size_down": "Schrittgröße runter",
    "scale_fn": "Skalierungsfunktion",
    "scale_mode": "Skalierungsmodus",
    "cycle_momentum": "Zyklus-Momentum",
    "base_momentum": "Basis-Momentum",
    "max_momentum": "Max. Momentum",
    "total_steps": "Gesamtschritte",
    "epochs": "Epochen",
    "steps_per_epoch": "Schritte pro Epoche",
    "pct_start": "Start-Prozentsatz",
    "anneal_strategy": "Annealing-Strategie",
    "div_factor": "Div-Faktor",
    "final_div_factor": "Finaler Div-Faktor",
    "three_phase": "Drei-Phasen",
    "total_iters": "Gesamtiterationen",
    "power": "Potenz",
    "start_factor": "Startfaktor",
    "end_factor": "Endfaktor",
    "lr_lambda": "LR Lambda",
    "reduction": "Reduktion",
    "p": "P",
    "margin": "Marge",
    "swap": "Tauschen",
    "size_average": "Größendurchschnitt",
    "reduce": "Reduzieren",
    "delta": "Delta",
    "beta": "Beta",
    "blank": "Leer",
    "zero_infinity": "Null Unendlichkeit",
    "log_input": "Log-Eingabe",
    "full": "Voll",
    "gain": "Verstärkung",
    "a": "A",
    "b": "B",
    "mean": "Mittelwert",
    "std": "Std",
    "val": "Wert",
    "sparsity": "Sparsamkeit",
    "groups": "Gruppen",
    "nonlinearity": "Nichtlinearität",
    "size": "Größe",
    "padding": "Padding",
    "pad_if_needed": "Auffüllen falls nötig",
    "fill": "Füllen",
    "padding_mode": "Padding-Modus",
    "scale": "Skala",
    "ratio": "Verhältnis",
    "interpolation": "Interpolation",
    "degrees": "Grad",
    "expand": "Erweitern",
    "center": "Zentrum",
    "translate": "Verschieben",
    "shear": "Scheren",
    "distortion_scale": "Verzerrungsskala",
    "brightness": "Helligkeit",
    "contrast": "Kontrast",
    "saturation": "Sättigung",
    "hue": "Farbton",
    "value": "Wert",
    "inplace": "In-Place",
    "bits": "Bits",
    "sharpness_factor": "Schärfefaktor",
    "transforms": "Transformationen"
  },
  "nav": {
    "projects": "Projekte",
    "training_setup": "Training Setup",
    "dataset": "Datensatz",
    "performance": "Leistung",
    "heatmap": "Heatmap",
    "updates": "Updates"
  },
  "ui": {
    "language_select_title": "Sprache"
  },
  "context_menu": {
    "view_image": "Bild anzeigen",
    "select": "Auswählen",
    "deselect": "Abwählen",
    "select_all": "Alles auswählen",
    "clear_selection": "Auswahl aufheben",
    "copy_filename": "Dateiname kopieren",
    "copy_path": "Pfad kopieren",
    "delete": "Löschen",
    "delete_selected": "Ausgewählte löschen ({count})",
    "open_folder": "Im Explorer öffnen",
    "new_subfolder": "Neuer Unterordner"
  },
  "training_controller": {
    "stop": "Stopp",
    "clear": "Leeren",
    "completed": "Abgeschlossen",
    "stopped": "Gestoppt",
    "error": "Fehler",
    "already_running": "Training läuft bereits",
    "mode": {
      "new": "Neues Modell",
      "resume": "Fortsetzen",
      "finetune": "Feinabstimmung"
    }
  },
  "projects_page": {
    "title": "Projekte",
    "description": "Verwalte deine Bilderkennungsprojekte",
    "empty": {
      "title": "Keine Projekte gefunden",
      "description": "Erstelle ein neues Projekt, um zu beginnen"
    },
    "error": {
      "title": "Fehler beim Laden der Projekte"
    },
    "card": {
      "unknown_type": "Unbekannt",
      "no_stats": "Keine Statistiken verfügbar",
      "loading": "Laden",
      "error": "Fehler"
    },
    "stats": {
      "total_images": "Gesamtbilder",
      "balance_score": "Balance-Score",
      "balance_status": "Balance-Status",
      "balance_status_excellent": "Exzellent",
      "balance_status_very_good": "Sehr gut",
      "balance_status_good": "Gut",
      "balance_status_decent": "Anständig",
      "balance_status_fair": "Fair",
      "balance_status_mediocre": "Mittelmäßig",
      "balance_status_poor": "Schlecht",
      "balance_status_bad": "Miserabel",
      "balance_status_terrible": "Furchtbar",
      "balance_status_nonsense": "Unsinn"
    },
    "buttons": {
      "refresh": "Aktualisieren",
      "load": "Laden",
      "loaded": "Geladen",
      "start_training": "Training starten",
      "new_training": "Neues Training",
      "resume_training": "Training fortsetzen",
      "finetune_training": "Feinabstimmung",
      "stop_training": "Training stoppen",
      "new_project": "Neues Projekt",
      "rename_project": "Umbenennen",
      "delete_project": "Löschen"
    },
    "training": {
      "stop_error": "Fehler beim Stoppen des Trainings",
      "start_error": "Fehler beim Starten des Trainings",
      "no_project": "Kein Projekt ausgewählt",
      "finetune_toggle": "Bestehendes Modell feinabstimmen",
      "resume_missing_checkpoint": "Kein Checkpoint gefunden. Starte einen neuen Trainingslauf.",
      "resume_title": "Bestehendes Modell feinabstimmen?",
      "resume_prompt": "Ein trainiertes Modell wurde gefunden. Möchtest du vom letzten Checkpoint feinabstimmen?",
      "resume_yes": "Feinabstimmen",
      "resume_no": "Neu starten"
    },
    "new_project": {
      "title": "Neues Projekt erstellen",
      "prompt": "Projektname eingeben:",
      "error": "Fehler beim Erstellen des Projekts"
    },
    "delete_project": {
      "title": "Projekt löschen",
      "confirm": "Bist du sicher, dass du das Projekt '{name}' löschen möchtest? Diese Aktion kann nicht rückgängig gemacht werden.",
      "no_selection": "Kein Projekt ausgewählt",
      "error": "Fehler beim Löschen des Projekts"
    },
    "rename_project": {
      "title": "Projekt umbenennen",
      "prompt": "Neuen Projektnamen eingeben:",
      "no_selection": "Kein Projekt ausgewählt",
      "error": "Fehler beim Umbenennen des Projekts"
    },
    "dataset_types": {
      "unknown": "Unbekannt",
      "multi_label": "Multi-Label",
      "folder_classification": "Ordner-Klassifizierung",
      "annotation": "Annotation"
    }
  },
  "training_page": {
    "tabs": {
      "presets": "Voreinstellungen",
      "model": "Modell",
      "hyperparameters": "Hyperparameter",
      "dataloader": "Data Loader",
      "augmentation": "Augmentation",
      "optimizer": "Optimierer",
      "scheduler": "Scheduler",
      "loss": "Verlust (Loss)",
      "checkpoint": "Checkpoint",
      "early_stopping": "Early Stopping",
      "gradient": "Gradient",
      "runtime": "Laufzeit"
    },
    "no_project": {
      "title": "Kein Projekt ausgewählt",
      "description": "Bitte wähle ein Projekt auf der Projektseite aus, um die Trainingseinstellungen zu konfigurieren.",
      "button": "Zu den Projekten"
    },
    "load_defaults_button": "Standards laden",
    "load_project_button": "Projekt laden",
    "save_button": "Speichern",
    "saving": "Speichern...",
    "saved": "Gespeichert",
    "save_error": "Fehler beim Speichern",
    "defaults_loaded": "Standards geladen",
    "project_loaded": "Projekt geladen",
    "load_error": "Ladefehler",
    "no_settings": "Keine Einstellungen verfügbar",
    "augmentation": {
      "train_title": "Trainings-Augmentationen",
      "train_description": "Augmentationen, die während des Trainings angewendet werden, um die Modellgeneralisierung zu verbessern",
      "val_title": "Validierungs-Augmentationen",
      "val_description": "Minimale Augmentationen für Validierungsdaten (typischerweise nur Größe ändern und normalisieren)",
      "preview_placeholder": "Bild hier ablegen oder auf Zufall klicken, um Augmentationen zu sehen",
      "btn_random": "Zufall",
      "btn_train": "Training",
      "btn_val": "Val",
      "no_params": "Keine Parameter"
    },
    "presets": {
      "title": "Trainings-Voreinstellungen",
      "description": "Schnellkonfigurationsvorlagen für gängige Trainingsszenarien",
      "search_placeholder": "Suche Voreinstellungen nach Name, Beschreibung, Aufgabe...",
      "task_filter_label": "Aufgabe",
      "task_filter_all": "Alle Aufgaben",
      "task_filter_classification": "Single-Label / Binär",
      "task_filter_multi_label": "Multi-Label",
      "category.classification": "Klassifizierung",
      "category.multi_label": "Multi-Label",
      "only_compatible": "Nur kompatible",
      "search_results": "Voreinstellungen gefunden",
      "loading": "Lade Voreinstellungen...",
      "no_presets": "Keine Voreinstellungen verfügbar",
      "apply_error": "Fehler beim Anwenden der Voreinstellung",
      "applied": "Voreinstellung erfolgreich angewendet",
      "incompatible_dataset": "Inkompatibel mit aktuellem Datensatz",
      "dataset_size": "Bilder",
      "recommended": "Empfohlen",
      "apply_button": "Anwenden"
    }
  },
  "dataset_page": {
    "no_project": {
      "title": "Kein Projekt ausgewählt",
      "description": "Bitte wähle ein Projekt auf der Projektseite aus, um den Datensatz anzuzeigen.",
      "button": "Zu den Projekten"
    },
    "type_label": "Datensatztyp",
    "types": {
      "unknown": "Unbekannt",
      "multi_label": "Multi-Label",
      "folder_classification": "Ordner-Klassifizierung",
      "annotation": "Annotation"
    },
    "sync_button": "Datensatz synchronisieren",
    "build_button": "Datensatz erstellen",
    "progress_discovery": "Entdecke Bilder",
    "progress_starting": "Starte...",
    "progress_complete": "Abgeschlossen",
    "new_folder": "Neuer Ordner",
    "rename_folder": "Ordner umbenennen",
    "delete_folder": "Ordner löschen",
    "per_page": "Pro Seite",
    "search_filename": "Dateiname",
    "search_annotation": "Annotation",
    "search_placeholder": "Bilder suchen...",
    "show_duplicates": "Duplikate anzeigen",
    "duplicates_none": "Keine doppelten Bilder gefunden",
    "duplicates_error": "Fehler beim Prüfen auf Duplikate",
    "folders": "Ordner",
    "drop_images": "Bilder hier ablegen zum Hochladen",
    "root_folder": "Root",
    "delete_image": "Bild löschen",
    "duplicate_count": "{count} Duplikate",
    "tag_placeholder": "Tags hinzufügen...",
    "annotation_placeholder": "Annotation hinzufügen...",
    "confirm_delete": "Bist du sicher, dass du dieses Bild löschen möchtest?",
    "uploading": "Hochladen...",
    "upload_error": "Upload fehlgeschlagen",
    "enter_folder_name": "Ordnernamen eingeben:",
    "folder_create_error": "Fehler beim Erstellen des Ordners",
    "enter_new_name": "Neuen Namen eingeben:",
    "folder_rename_error": "Fehler beim Umbenennen des Ordners",
    "delete_folder_confirm_with_images": "Dieser Ordner enthält {count} Bilder. Bist du sicher, dass du ihn löschen möchtest?",
    "delete_folder_confirm": "Bist du sicher, dass du diesen Ordner löschen möchtest?",
    "folder_delete_error": "Fehler beim Löschen des Ordners",
    "build_error": "Erstellung fehlgeschlagen",
    "status_count": "{count} Bilder",
    "clear_selection": "Auswahl aufheben",
    "select_all": "Alles auswählen",
    "bulk_add_tags_placeholder": "Tags hinzufügen...",
    "bulk_add": "Hinzufügen",
    "bulk_remove_tags_placeholder": "Tags entfernen...",
    "bulk_remove": "Entfernen",
    "bulk_delete": "Ausgewählte löschen",
    "selected_count": "{count} ausgewählt",
    "bulk_error": "Massenoperation fehlgeschlagen",
    "bulk_delete_confirm": "Bist du sicher, dass du {count} Bilder löschen möchtest?"
  },
  "performance_page": {
    "tabs": {
      "training": "Training",
      "system": "System"
    },
    "training": {
      "title": "Trainingsfortschritt",
      "no_active": "Keine aktive Trainingssitzung",
      "no_data": "Keine Trainingsdaten",
      "description": "Starte das Training, um Fortschrittsgrafiken zu sehen",
      "running": "Training läuft",
      "completed": "Training abgeschlossen",
      "stopped": "Training gestoppt",
      "train": "Training",
      "validation": "Validierung",
      "train_step_loss": "Trainings-Schritt-Verlust",
      "val_step_loss": "Validierungs-Schritt-Verlust",
      "step_accuracy": "Schritt-Genauigkeit",
      "learning_rate": "Lernrate",
      "epoch_loss": "Epochen-Verlust",
      "epoch_accuracy": "Epochen-Genauigkeit",
      "current": "Aktuell",
      "step": "Schritt",
      "train_step_accuracy": "Train Schritt-Genauigkeit",
      "val_step_accuracy": "Val Schritt-Genauigkeit",
      "current_lr": "Aktuelle LR",
      "train_loss": "Train Verlust",
      "val_loss": "Val Verlust",
      "train_accuracy": "Train Genauigkeit",
      "val_accuracy": "Val Genauigkeit"
    },
    "system": {
      "title": "Systemmonitor",
      "monitoring_active": "Überwachung aktiv",
      "monitoring_paused": "Überwachung pausiert",
      "cpu_usage": "CPU-Auslastung",
      "system_memory": "Systemspeicher",
      "gpu_usage": "GPU {index} Auslastung",
      "gpu_memory": "GPU {index} Speicher",
      "speed": "Geschwindigkeit",
      "cores_threads": "Kerne/Threads",
      "temperature": "Temperatur",
      "max_memory": "Max. Speicher",
      "available": "Verfügbar",
      "power": "Leistung",
      "gpu_clock": "GPU-Takt",
      "mem_clock": "Speichertakt",
      "fan": "Lüfter",
      "dedicated_memory": "Dedizierter Speicher",
      "used_memory": "Genutzter Speicher"
    }
  },
  "heatmap_page": {
    "no_project": {
      "title": "Kein Projekt ausgewählt",
      "description": "Bitte wähle ein Projekt auf der Projektseite aus, um Heatmaps zu generieren.",
      "button": "Zu den Projekten"
    },
    "drop_zone": {
      "text": "Bild hier ablegen",
      "hint": "oder klicken zum Auswählen"
    },
    "alpha_label": "Overlay Alpha",
    "results": {
      "title": "Ergebnisse",
      "placeholder": "Bild ablegen, um Vorhersagen und Heatmap zu sehen",
      "no_predictions": "Keine Vorhersagen verfügbar"
    },
    "live_model_switch": "Live-Modell verwenden",
    "multi_label_switch": "Multi-Label",
    "random_button": "Zufall",
    "refresh_button": "Aktualisieren",
    "checkpoint_label": "Checkpoint:"
  },
  "updates_ui": {
    "page_title": "Updates",
    "page_description": "Nach Systemupdates suchen und anwenden",
    "intro": "Suche nach Updates, um dein System mit den neuesten Funktionen und Korrekturen aktuell zu halten.",
    "check_button": "Nach Updates suchen",
    "apply_button": "Updates anwenden",
    "status_idle": "Bereit zur Updatesuche",
    "status_checking": "Suche nach Updates...",
    "status_ready": "Updates verfügbar",
    "status_up_to_date": "System ist auf dem neuesten Stand",
    "status_applying": "Wende Updates an...",
    "status_applied": "Updates erfolgreich angewendet",
    "status_failed": "Update-Suche fehlgeschlagen",
    "no_updates": "Keine Updates verfügbar",
    "files_to_update": "Dateien zu aktualisieren",
    "orphaned_count": "verwaiste Dateien",
    "table_header_file": "Datei",
    "table_header_status": "Status"
  },
  "schema": {
    "description": "Konfigurationsschema für das Hootsight Bilderkennungssystem",
    "ui_group": {
      "general": "Allgemein",
      "api": "API-Einstellungen",
      "ui_settings": "Benutzeroberfläche",
      "paths": "Pfade",
      "system": "System",
      "memory": "Speicherverwaltung",
      "dataset": "Datensatz",
      "dataset_editor": "Datensatz-Editor",
      "training_model": "Modell",
      "training_hyperparameters": "Hyperparameter",
      "training_dataloader": "Data Loader",
      "training_augmentation": "Augmentation",
      "training_optimizer": "Optimierer",
      "training_scheduler": "Scheduler",
      "training_loss": "Verlustfunktion",
      "training_checkpoint": "Checkpointing",
      "training_early_stopping": "Early Stopping",
      "training_gradient": "Gradient",
      "training_runtime": "Laufzeit",
      "activations_defaults": "Aktivierungs-Standards",
      "augmentations_defaults": "Augmentations-Standards",
      "optimizers": "Optimierer",
      "schedulers": "Scheduler",
      "losses": "Verluste",
      "activations": "Aktivierungen",
      "augmentations": "Augmentationen",
      "regularization": "Regularisierung",
      "normalization": "Normalisierung",
      "pooling": "Pooling",
      "models": "Modelle"
    },
    "general_description": "Allgemeine Anwendungseinstellungen",
    "general_language_description": "Sprache der Benutzeroberfläche",
    "general_language_enum_descriptor": {
      "en": "Englisch",
      "de": "Deutsch"
    },
    "api_description": "API-Server-Konfiguration",
    "api_host_description": "API-Server-Hostadresse",
    "api_port_description": "API-Server-Portnummer",
    "ui_description": "Einstellungen der Benutzeroberfläche",
    "ui_title_description": "Titel des Anwendungsfensters",
    "ui_width_description": "Fensterbreite in Pixeln",
    "ui_height_description": "Fensterhöhe in Pixeln",
    "ui_resizable_description": "Fenstergröße änderbar",
    "paths_description": "Datei- und Verzeichnispfade",
    "paths_projects_dir_description": "Verzeichnis mit Projekten",
    "paths_ui_dir_description": "Verzeichnis mit UI-Dateien",
    "paths_config_dir_description": "Verzeichnis mit Konfigurationsdateien",
    "paths_localizations_dir_description": "Verzeichnis mit Lokalisierungsdateien",
    "paths_packages_file_description": "Pfad zur Paketkonfigurationsdatei",
    "paths_cache_dir_description": "Verzeichnis für zwischengespeicherte Dateien",
    "paths_docs_dir_description": "Verzeichnis für Dokumentation",
    "system_description": "Systemkonfigurationseinstellungen",
    "system_max_threads_description": "Maximale Anzahl von Worker-Threads",
    "system_max_threads_enum_descriptor": {
      "auto": "Automatisch (basierend auf CPU-Kernen)"
    },
    "system_fallback_batch_size_description": "Fallback-Batch-Größe, wenn die automatische Erkennung fehlschlägt",
    "system_startup_wait_seconds_description": "Sekunden warten vor dem Start der UI",
    "system_http_timeout_description": "HTTP-Anfrage-Timeout in Sekunden",
    "system_update_repository_url_description": "URL für das Update-Repository",
    "system_update_skip_paths_description": "Pfade, die bei Updates übersprungen werden",
    "dataset_editor_description": "Konfiguration des Datensatz-Editors",
    "dataset_editor_page_sizes_description": "Verfügbare Seitengrößen-Optionen",
    "dataset_editor_default_page_size_description": "Standardbilder pro Seite",
    "dataset_editor_size_presets_description": "Bildgrößen-Voreinstellungen nach Modelltyp",
    "dataset_editor_default_size_description": "Standardbildgröße",
    "dataset_editor_build_workers_description": "Anzahl der Worker für die Datensatzerstellung",
    "dataset_editor_build_workers_enum_descriptor": {
      "auto": "Automatisch (basierend auf CPU-Kernen)"
    },
    "dataset_editor_discovery_workers_description": "Anzahl der Worker für die Bilderkennung",
    "dataset_editor_discovery_workers_enum_descriptor": {
      "auto": "Automatisch (basierend auf CPU-Kernen)"
    },
    "dataset_editor_project_name_validation_description": "Validierungsregeln für Projektnamen",
    "dataset_editor_project_name_validation_min_length_description": "Minimale Länge des Projektnamens",
    "dataset_editor_project_name_validation_max_length_description": "Maximale Länge des Projektnamens",
    "dataset_editor_project_name_validation_pattern_description": "Erlaubtes Muster für Projektnamen (Regex)",
    "memory_description": "Speicherverwaltungskonfiguration",
    "memory_target_memory_usage_description": "Ziel-GPU-Speichernutzungsverhältnis",
    "memory_safety_margin_description": "Sicherheitsmarge für Speicherzuweisung",
    "memory_augmentation_threads_description": "Threads für Augmentationsverarbeitung",
    "memory_augmentation_threads_enum_descriptor": {
      "auto": "Automatisch (basierend auf CPU-Kernen)"
    },
    "memory_reserved_memory_ratio_description": "Reserviertes Speicherverhältnis",
    "memory_per_sample_multiplier_description": "Speichermultiplikator pro Sample",
    "memory_min_batch_size_description": "Minimale Batch-Größe",
    "memory_max_batch_size_description": "Maximale Batch-Größe",
    "memory_thresholds_description": "Speichernutzungsschwellenwerte",
    "memory_thresholds_high_usage_description": "Schwellenwert für hohe Speichernutzung",
    "memory_thresholds_moderate_usage_description": "Schwellenwert für moderate Speichernutzung",
    "memory_thresholds_low_usage_description": "Schwellenwert für niedrige Speichernutzung",
    "memory_batch_size_limits_description": "Warnlimits für Batch-Größe",
    "memory_batch_size_limits_small_description": "Warnschwelle für kleine Batch-Größe",
    "memory_batch_size_limits_large_description": "Warnschwelle für große Batch-Größe",
    "training_description": "Trainingskonfiguration",
    "training_model_type_title": "Modelltyp",
    "training_model_type_description": "Wähle die neuronale Netzwerkarchitekturfamilie. Jede Architektur bietet einzigartige Eigenschaften in Bezug auf Genauigkeit, Inferenzgeschwindigkeit, Speichernutzung und Modellgröße. Deine Wahl sollte auf deinem Einsatzziel (Server, Mobilgerät, Edge-Gerät) und den Genauigkeitsanforderungen basieren.",
    "training_model_type_enum_descriptor": {
      "resnet": "ResNet (Residual Networks) - Die grundlegende Deep-Learning-Architektur, die Skip-Connections einführte, das Problem des verschwindenden Gradienten löste und das Training sehr tiefer Netzwerke (bis zu 152 Schichten) ermöglichte. ResNet ist der Industriestandard mit bewährter Zuverlässigkeit in unzähligen Anwendungen. Bietet eine hervorragende Balance zwischen Genauigkeit und Rechenaufwand. ResNet50 ist die beliebteste Variante und erreicht ~76% ImageNet Top-1-Genauigkeit. Ideal für: allgemeine Bildklassifizierung, Transfer-Learning-Basis, medizinische Bildgebung, Qualitätsprüfung, Gesichtserkennung. Wähle ResNet18/34 für schnellere Inferenz, ResNet101/152, wenn maximale Genauigkeit entscheidend ist.",
      "resnext": "ResNeXt (Residual Networks with Aggregated Transformations) - Eine Weiterentwicklung von ResNet, die Kardinalität (Anzahl paralleler Pfade) als neue Dimension neben Tiefe und Breite einführt. Verwendet gruppierte Faltungen, um reichhaltigere Merkmalsrepräsentationen zu lernen. Erreicht 1-2% höhere Genauigkeit als äquivalente ResNet-Modelle bei ähnlichem Rechenaufwand. Die 32x4d-Konfiguration bedeutet 32 parallele Pfade mit 4-dimensionalen Transformationen. Ideal für: feinkörnige visuelle Erkennung (Vogelarten, Automodelle), komplexe Multi-Attribut-Klassifizierung, Mode-/Stilanalyse, Texturerkennung, Fälle, in denen die ResNet-Genauigkeit stagniert. Am besten, wenn du diesen zusätzlichen Genauigkeitsschub ohne große architektonische Änderungen benötigst.",
      "alexnet": "AlexNet - Der klassische ImageNet-Gewinner von 2012. Einfache Architektur mit großen Feature-Maps und ReLU-Aktivierungen. Schwerer als moderne leichte Modelle, aber einfach und zuverlässig für schnelle Baselines. Gut für Bildungszwecke, schnelle Experimente oder wenn du ein flaches Netzwerk ohne fortgeschrittene Blöcke benötigst.",
      "vgg": "VGG - Tiefe Stapel von 3x3-Faltungen ohne Residual-Connections. Liefert starke Genauigkeit, ist aber parameterlastig und langsamer als ResNet. Gut für Transfer-Learning, wenn du glatte Feature-Maps und eine einfache Topologie möchtest. Bevorzuge Batch-Norm-Varianten (vgg*_bn) für Stabilität.",
      "densenet": "DenseNet - Jede Schicht speist in alle nachfolgenden Schichten ein, was die Wiederverwendung von Merkmalen und den Gradientenfluss verbessert. Erreicht typischerweise eine bessere Genauigkeit als einfaches ResNet mit weniger Parametern. Stark für feinkörnige Aufgaben und wenn du kompakte, aber genaue Modelle möchtest.",
      "mobilenet": "MobileNet (Mobile Networks) - Speziell für mobile und eingebettete Geräte entwickelt, unter Verwendung von tiefenweise separierbaren Faltungen, die die Berechnung drastisch reduzieren. MobileNetV3 integriert Neural Architecture Search (NAS) und Squeeze-and-Excitation-Blöcke. Erreicht 75-80% der ResNet50-Genauigkeit, ist dabei aber 3-5x schneller bei 10x kleinerer Modellgröße. Typische Inferenz: <10ms auf modernen Telefonen. Ideal für: iOS/Android-Apps, Raspberry Pi, Jetson Nano, Echtzeit-Videoverarbeitung, AR/VR-Anwendungen, Drohnenvision, IoT-Sensoren, intelligente Kameras, Einzelhandelsanalytik. Wähle V3-Small für ultraschnelle Inferenz, V3-Large für bessere Genauigkeit bei gleichzeitiger Mobilfreundlichkeit.",
      "shufflenet": "ShuffleNet - Entwickelt für maximale Effizienz auf CPUs und Geräten mit geringer Leistung unter Verwendung von Channel-Shuffle-Operationen und punktweisen Gruppenfaltungen. Erreicht ein hervorragendes Verhältnis von Geschwindigkeit zu Genauigkeit durch effizientes Mischen von Informationen zwischen Kanalgruppen. Noch schneller als MobileNet auf reinen CPU-Geräten. Modellgrößen reichen von ultraleicht (x0.5, ~1MB) bis leistungsfähiger (x2.0, ~7MB). Ideal für: strenge Latenzanforderungen (<5ms), Robotik-Vision, tragbare Geräte, Always-on-Smart-Kameras, Verkehrsüberwachung, industrielle Inspektion auf ressourcenbeschränkter Hardware, batteriebetriebene Geräte. Nicht empfohlen für Aufgaben, die maximale Genauigkeit oder feinkörnige Detailerkennung erfordern.",
      "squeezenet": "SqueezeNet - Die kompakteste Architektur, die AlexNet-Level-Genauigkeit mit 50x weniger Parametern unter Verwendung innovativer Fire-Module (Squeeze- und Expand-Schichten) erreicht. Modellgröße so klein wie ~5MB (oder ~0.5MB mit tiefer Kompression). Entwickelt für extreme Modellkompression bei gleichzeitiger Beibehaltung einer angemessenen Genauigkeit. Ideal für: Mikrocontroller mit <10MB Speicher, FPGA-Einsatz, Over-the-Air-Modellupdates auf Geräten mit begrenzter Bandbreite, eingebettete Systeme mit strengen Speicherbeschränkungen, Always-on-Vision-Anwendungen, bei denen der Stromverbrauch kritisch ist. SqueezeNet 1.1 ist 2,4x schneller als 1.0. Nicht empfohlen für komplexe Aufgaben oder große Datensätze - begrenzte Kapazität führt zu Underfitting.",
      "efficientnet": "EfficientNet - State-of-the-Art-Architektur unter Verwendung von Compound Scaling, das Netzwerktiefe, -breite und -auflösung mit festen Verhältnissen skaliert, die aus der Neural Architecture Search abgeleitet wurden. Erreicht erstklassige Genauigkeit und ist dabei 8-10x effizienter als frühere Architekturen. EfficientNet-B0 entspricht der ResNet50-Genauigkeit mit 5x weniger Parametern. B4-B7-Varianten erreichen bis zu 84%+ ImageNet-Genauigkeit. EfficientNetV2 bietet schnelleres Training mit progressivem Lernen. Ideal für: maximale Genauigkeitsanforderungen, medizinische Bildanalyse (Röntgen, MRT, Pathologie), feinkörnige Erkennung (Artenidentifikation, Fehlererkennung), Satelliten-/Luftbilder, wissenschaftliche Bildgebung, Kunstauthentifizierung, forensische Analyse. Der Goldstandard, wenn Genauigkeit am wichtigsten ist.",
      "convnext": "ConvNeXt - Ein reines ConvNet-Modell, das günstig mit Transformern konkurriert. Modernisiert die Standard-ResNet-Architektur mit Designentscheidungen von Vision Transformers (ViT). Bietet hervorragende Genauigkeit und Skalierbarkeit. Ideal für: allgemeine Vision-Aufgaben, bei denen du State-of-the-Art-Genauigkeit ohne die Komplexität von Transformern möchtest.",
      "vit": "Vision Transformer (ViT) - Wendet die Transformer-Architektur direkt auf Sequenzen von Bildpatches an. Kann auf großen Datensätzen State-of-the-Art-Ergebnisse erzielen, erfordert aber möglicherweise mehr Daten oder starke Regularisierung auf kleineren. Ideal für: groß angelegte Datensätze, Forschung und Aufgaben, bei denen globaler Kontext entscheidend ist.",
      "swin": "Swin Transformer - Ein hierarchischer Vision Transformer mit verschobenen Fenstern. Adressiert die Skalierungs- und Auflösungsprobleme von Standard-ViTs. Effizient und genau für eine Vielzahl von Vision-Aufgaben, einschließlich dichter Vorhersage. Ideal für: hochauflösende Bilder und Aufgaben, die ein detailliertes räumliches Verständnis erfordern."
    },
    "training_model_name_title": "Modellname",
    "training_model_name_description": "Spezifische Modellvariante innerhalb der gewählten Architekturfamilie. Varianten unterscheiden sich in Tiefe, Breite und Rechenanforderungen. Kleinere Zahlen (z.B. ResNet18) bieten schnellere Inferenz, größere Zahlen (z.B. ResNet152) bieten bessere Genauigkeit.",
    "training_model_name_enum_descriptor": {
      "resnet18": "ResNet-18: Die leichteste ResNet-Variante. Schnelles Training und Inferenz, geringer Speicherverbrauch. Gut für einfache Klassifizierungsaufgaben oder mobilen/Edge-Einsatz. Genauigkeit: ~69,7% Top-1 auf ImageNet.",
      "resnet34": "ResNet-34: Tiefer als ResNet-18, aber immer noch relativ leicht. Bietet eine gute Balance zwischen Geschwindigkeit und Genauigkeit für Aufgaben mittlerer Komplexität. Genauigkeit: ~73,3% Top-1 auf ImageNet.",
      "resnet50": "ResNet-50: Das Arbeitspferd der Industrie. Hervorragende Balance zwischen Genauigkeit und Rechenaufwand. Geeignet für die meisten Allzweck-Vision-Aufgaben. Genauigkeit: ~76,1% Top-1 auf ImageNet.",
      "resnet101": "ResNet-101: Tiefere Variante für höhere Genauigkeit bei komplexen Datensätzen. Erfordert mehr Speicher und Rechenleistung. Verwenden, wenn ResNet-50 underfitted. Genauigkeit: ~77,3% Top-1 auf ImageNet.",
      "resnet152": "ResNet-152: Das tiefste Standard-ResNet. Maximale Genauigkeit für diese Familie, aber rechenintensiv. Am besten für sehr schwierige feinkörnige Klassifizierung. Genauigkeit: ~78,3% Top-1 auf ImageNet.",
      "wide_resnet50_2": "Wide ResNet-50-2: Eine breitere Version von ResNet-50. Übertrifft oft tiefere Netzwerke durch mehr Kanäle pro Schicht. Gut, um mehr Merkmale zu erfassen, ohne tiefer zu gehen. Genauigkeit: ~78,5% Top-1 auf ImageNet.",
      "wide_resnet101_2": "Wide ResNet-101-2: Eine breitere Version von ResNet-101. Sehr hohe Genauigkeit, aber speicherintensiv. Verwenden für State-of-the-Art-Leistung bei schwierigen Aufgaben. Genauigkeit: ~78,8% Top-1 auf ImageNet.",
      "resnext50_32x4d": "ResNeXt-50 (32x4d): Führt 'Kardinalität' (gruppierte Faltungen) in ResNet-50 ein. Bessere Genauigkeit als ResNet-50 bei ähnlicher Komplexität. Großartig für feinkörnige Erkennung. Genauigkeit: ~77,6% Top-1 auf ImageNet.",
      "resnext101_32x8d": "ResNeXt-101 (32x8d): Hochkapazitätsmodell mit hoher Kardinalität. Hervorragend für komplexe Multi-Attribut- oder feinkörnige Aufgaben. Hoher Rechenbedarf. Genauigkeit: ~79,3% Top-1 auf ImageNet.",
      "resnext101_64x4d": "ResNeXt-101 (64x4d): Eine weitere Hochkapazitätsvariante. Sehr starke Leistung auf großen Datensätzen. Genauigkeit: ~79,6% Top-1 auf ImageNet.",
      "alexnet": "AlexNet: Der klassische Pionier des Deep Learning. Sehr einfache Architektur, schnell zu trainieren, aber geringere Genauigkeit im Vergleich zu modernen Modellen. Gut für Bildungszwecke oder sehr einfache Baselines. Genauigkeit: ~56,5% Top-1 auf ImageNet.",
      "vgg11": "VGG-11: Einfache, tiefe Architektur mit 3x3-Faltungen. Guter Feature-Extraktor, aber parameterlastig und langsam. Genauigkeit: ~69,0% Top-1 auf ImageNet.",
      "vgg13": "VGG-13: Tiefere VGG-Variante. Bessere Merkmale als VGG-11. Genauigkeit: ~69,9% Top-1 auf ImageNet.",
      "vgg16": "VGG-16: Sehr beliebter Feature-Extraktor. Hervorragend für Style-Transfer und Aufgaben, die reichhaltige Texturmerkmale benötigen. Schwer und langsame Inferenz. Genauigkeit: ~71,6% Top-1 auf ImageNet.",
      "vgg19": "VGG-19: Das tiefste VGG. Sehr reichhaltige Merkmale, aber extrem schwer. Oft in künstlerischen Anwendungen verwendet. Genauigkeit: ~72,4% Top-1 auf ImageNet.",
      "vgg11_bn": "VGG-11 (Batch Norm): VGG-11 mit Batch-Normalisierung. Konvergiert viel schneller und ist stabiler als Standard-VGG-11. Genauigkeit: ~70,4% Top-1 auf ImageNet.",
      "vgg13_bn": "VGG-13 (Batch Norm): VGG-13 mit Batch-Normalisierung. Verbesserte Stabilität und Genauigkeit. Genauigkeit: ~71,6% Top-1 auf ImageNet.",
      "vgg16_bn": "VGG-16 (Batch Norm): VGG-16 mit Batch-Normalisierung. Die bevorzugte Version von VGG-16 für Klassifizierung. Genauigkeit: ~73,4% Top-1 auf ImageNet.",
      "vgg19_bn": "VGG-19 (Batch Norm): VGG-19 mit Batch-Normalisierung. Maximale VGG-Genauigkeit. Genauigkeit: ~74,2% Top-1 auf ImageNet.",
      "densenet121": "DenseNet-121: Verbindet jede Schicht mit jeder anderen Schicht. Sehr parametereffizient und genau. Gut für kleine Datensätze, um Overfitting zu verhindern. Genauigkeit: ~75,0% Top-1 auf ImageNet.",
      "densenet161": "DenseNet-161: Breitere DenseNet-Variante. Hohe Genauigkeit, vergleichbar mit ResNet-50/101, aber mit anderen Eigenschaften. Genauigkeit: ~77,6% Top-1 auf ImageNet.",
      "densenet169": "DenseNet-169: Tieferes DenseNet. Starke Leistung, guter Gradientenfluss. Genauigkeit: ~76,2% Top-1 auf ImageNet.",
      "densenet201": "DenseNet-201: Tiefstes Standard-DenseNet. Sehr starke Wiederverwendung von Merkmalen. Genauigkeit: ~77,4% Top-1 auf ImageNet.",
      "mobilenet_v2": "MobileNetV2: Optimiert für Mobil- und Edge-Geräte. Invertierte Residual-Blöcke machen es sehr schnell und klein. Gut für Echtzeit-Apps. Genauigkeit: ~71,8% Top-1 auf ImageNet.",
      "mobilenet_v3_small": "MobileNetV3-Small: Durch Architektursuche auf ultraniedrige Latenz und Größe abgestimmt. Am besten für sehr eingeschränkte Hardware. Genauigkeit: ~67,4% Top-1 auf ImageNet.",
      "mobilenet_v3_large": "MobileNetV3-Large: Größere V3-Variante. Bessere Genauigkeit als V2 bei ähnlicher Geschwindigkeit. Hervorragende moderne mobile Baseline. Genauigkeit: ~75,2% Top-1 auf ImageNet.",
      "shufflenet_v2_x0_5": "ShuffleNetV2 x0.5: Extrem leichtgewichtig. Verwendet Channel-Shuffling für Geschwindigkeit. Für Geräte mit sehr geringer Leistung. Genauigkeit: ~60,5% Top-1 auf ImageNet.",
      "shufflenet_v2_x1_0": "ShuffleNetV2 x1.0: Standard ShuffleNet. Sehr schnelle Inferenz auf CPU. Konkurrenzfähig mit MobileNetV2. Genauigkeit: ~69,4% Top-1 auf ImageNet.",
      "shufflenet_v2_x1_5": "ShuffleNetV2 x1.5: Breitere Version für bessere Genauigkeit bei gleichzeitiger Beibehaltung der Geschwindigkeitsvorteile. Genauigkeit: ~72,6% Top-1 auf ImageNet.",
      "shufflenet_v2_x2_0": "ShuffleNetV2 x2.0: Breiteste Version. Nähert sich der ResNet-50-Genauigkeit mit viel weniger FLOPs. Genauigkeit: ~74,5% Top-1 auf ImageNet.",
      "squeezenet1_0": "SqueezeNet 1.0: Entwickelt für minimale Modellgröße (Parameter). Sehr kleine Dateigröße, gut für eingebettete Updates. Genauigkeit: ~58,1% Top-1 auf ImageNet.",
      "squeezenet1_1": "SqueezeNet 1.1: Optimierte Version von 1.0. Erfordert weniger Berechnungen für ähnliche Genauigkeit. Genauigkeit: ~58,2% Top-1 auf ImageNet.",
      "efficientnet_b0": "EfficientNet-B0: Die Baseline der effizienten Skalierungsfamilie. Übertrifft seine Gewichtsklasse. Großartiger Ausgangspunkt. Genauigkeit: ~77,1% Top-1 auf ImageNet.",
      "efficientnet_b1": "EfficientNet-B1: Hochskaliertes B0. Bessere Genauigkeit, etwas mehr Rechenaufwand. Genauigkeit: ~79,1% Top-1 auf ImageNet.",
      "efficientnet_b2": "EfficientNet-B2: Ausgewogene Skalierung. Gut für moderate Ressourcenbudgets. Genauigkeit: ~80,1% Top-1 auf ImageNet.",
      "efficientnet_b3": "EfficientNet-B3: Stärkere Leistung. Erfordert größere Eingabegrößen (300px+). Genauigkeit: ~81,6% Top-1 auf ImageNet.",
      "efficientnet_b4": "EfficientNet-B4: Modell mit hoher Genauigkeit. Gut für feinkörnige Aufgaben. Speicherintensiv. Genauigkeit: ~82,9% Top-1 auf ImageNet.",
      "efficientnet_b5": "EfficientNet-B5: Sehr hohe Genauigkeit. Anspruchsvoll an Ressourcen. Genauigkeit: ~83,6% Top-1 auf ImageNet.",
      "efficientnet_b6": "EfficientNet-B6: Nahe am State-of-the-Art für diese Familie. Sehr schwer. Genauigkeit: ~84,0% Top-1 auf ImageNet.",
      "efficientnet_b7": "EfficientNet-B7: Größtes Standard-EfficientNet. Maximale Genauigkeit, sehr langsames Training. Genauigkeit: ~84,3% Top-1 auf ImageNet.",
      "efficientnet_v2_s": "EfficientNetV2-S: Verbesserte Version von EfficientNet. Trainiert viel schneller und ist parametereffizienter. Genauigkeit: ~83,9% Top-1 auf ImageNet.",
      "efficientnet_v2_m": "EfficientNetV2-M: Mittlere V2-Variante. Hervorragender Kompromiss für High-End-Aufgaben. Genauigkeit: ~85,1% Top-1 auf ImageNet.",
      "efficientnet_v2_l": "EfficientNetV2-L: Große V2-Variante. Erstklassige Genauigkeit für schwierige Probleme. Genauigkeit: ~85,7% Top-1 auf ImageNet.",
      "convnext_tiny": "ConvNeXt-Tiny: Modernes 'ConvNet für die 2020er'. Konkurriert mit Vision Transformers. Hervorragendes Verhältnis von Genauigkeit zu Geschwindigkeit. Genauigkeit: ~82,1% Top-1 auf ImageNet.",
      "convnext_small": "ConvNeXt-Small: Größere Variante. Sehr starke Leistung, moderne Architektur. Genauigkeit: ~83,1% Top-1 auf ImageNet.",
      "convnext_base": "ConvNeXt-Base: Basisvariante. Vergleichbar mit ResNet-50/101, aber viel genauer. Genauigkeit: ~83,8% Top-1 auf ImageNet.",
      "convnext_large": "ConvNeXt-Large: Große Variante. State-of-the-Art Convolutional-Leistung. Genauigkeit: ~84,3% Top-1 auf ImageNet.",
      "vit_b_16": "ViT-B/16: Vision Transformer Base (16x16 Patches). Reine Transformer-Architektur. Benötigt viele Daten oder starkes Pretraining. Exzellenter globaler Kontext. Genauigkeit: ~81,0% Top-1 auf ImageNet.",
      "vit_b_32": "ViT-B/32: Vision Transformer Base (32x32 Patches). Schneller als B/16, aber gröbere Aufmerksamkeit. Genauigkeit: ~76,0% Top-1 auf ImageNet.",
      "vit_l_16": "ViT-L/16: Vision Transformer Large. Riesige Kapazität, State-of-the-Art-Potenzial auf massiven Datensätzen. Genauigkeit: ~79,0% (von Grund auf) / Höher mit Pretraining.",
      "vit_l_32": "ViT-L/32: Vision Transformer Large (32x32 Patches). Schnelleres großes Modell. Genauigkeit: ~77,0% (von Grund auf).",
      "vit_h_14": "ViT-H/14: Vision Transformer Huge. Massives Modell für Forschung oder extreme Leistungsanforderungen. Sehr langsam.",
      "swin_t": "Swin-T: Swin Transformer Tiny. Hierarchischer Transformer mit verschobenen Fenstern. Großartiges Allzweck-Vision-Backbone. Genauigkeit: ~81,3% Top-1 auf ImageNet.",
      "swin_s": "Swin-S: Swin Transformer Small. Tiefer/breiter. Sehr starke Genauigkeit. Genauigkeit: ~83,0% Top-1 auf ImageNet.",
      "swin_b": "Swin-B: Swin Transformer Base. Hochkapazitäts-Transformer. Genauigkeit: ~83,5% Top-1 auf ImageNet.",
      "swin_v2_t": "SwinV2-T: Verbessertes Swin Tiny. Bessere Skalierung und Stabilität. Genauigkeit: ~81,8% Top-1 auf ImageNet.",
      "swin_v2_s": "SwinV2-S: Verbessertes Swin Small. Genauigkeit: ~83,7% Top-1 auf ImageNet.",
      "swin_v2_b": "SwinV2-B: Verbessertes Swin Base. Genauigkeit: ~84,2% Top-1 auf ImageNet."
    },
    "training_pretrained_title": "Vortrainiert",
    "training_pretrained_description": "Verwende ImageNet-vortrainierte Gewichte als Ausgangspunkt. Für die meisten Anwendungsfälle sehr empfehlenswert, da es die Konvergenz und die endgültige Genauigkeit dramatisch verbessert, insbesondere bei kleinen Datensätzen. Das Modell hat bereits allgemeine visuelle Merkmale (Kanten, Texturen, Formen) gelernt, die auf deine neue Aufgabe übertragbar sind.",
    "training_task_title": "Aufgabe",
    "training_task_description": "Definiere, wie das Modell Bilder interpretieren und vorhersagen soll. Dies bestimmt grundlegend das Ausgabeformat und die Verlustfunktion, die während des Trainings verwendet werden.",
    "training_task_enum_descriptor": {
      "classification": "Single-Label-Klassifizierung - Jedes Bild gehört zu genau EINER Klasse aus einer vordefinierten Menge. Das Modell gibt eine Wahrscheinlichkeitsverteilung über alle Klassen aus und wählt die höchste als Vorhersage. Verwendet Softmax-Aktivierung und Cross-Entropy-Loss. Ideal für: sich gegenseitig ausschließende Kategorien (Katze vs. Hund, Produkttypen, Ziffernerkennung 0-9, Stimmung aus Gesichtern, Pass/Fail-Inspektion). Erwartete Ausgabe: einzelnes Klassenlabel mit Konfidenzscore. Genauigkeit typischerweise 85-99% je nach Aufgabenkomplexität und Datenqualität.",
      "multi_label": "Multi-Label-Klassifizierung - Jedes Bild kann MEHRERE Tags/Labels gleichzeitig haben. Das Modell behandelt jedes Label als unabhängige binäre Entscheidung. Verwendet Sigmoid-Aktivierung und Binary-Cross-Entropy-Loss. Ideal für: Bild-Tagging (draußen + sonnig + Menschen), Inhaltsmoderation (Gewalt + Nacktheit), Produktattribute (rot + Leder + groß), medizinische Symptome (mehrere Bedingungen vorhanden). Erwartete Ausgabe: Menge anwendbarer Labels mit individuellen Konfidenzscores. Jeder Label-Schwellenwert kann unabhängig abgestimmt werden.",
      "detection": "Objekterkennung - Lokalisiere und klassifiziere MEHRERE Objekte innerhalb eines Bildes mit Bounding Boxes. Das Modell sagt Objektpositionen (x, y, Breite, Höhe), Klassenlabels und Konfidenzscores für jede erkannte Instanz vorher. Ideal für: Objekte zählen, Überwachung, autonome Fahrzeuge, Regalanalysen im Einzelhandel, Dokumentenelementerkennung. Erwartete Ausgabe: Liste erkannter Objekte mit Bounding Boxes und Klassenlabels. Hinweis: Erfordert spezialisierte Architekturen (YOLO, Faster R-CNN) - Standardklassifizierer funktionieren nicht.",
      "segmentation": "Semantische Segmentierung - Klassifiziere JEDES PIXEL im Bild in vordefinierte Kategorien. Erstellt eine dichte Vorhersagekarte, bei der jedem Pixel ein Klassenlabel zugewiesen wird. Ideal für: medizinische Bildanalyse (Tumorgrenzen), autonomes Fahren (Straße/Gehweg/Fahrzeugregionen), Satellitenbilder (Landnutzungskartierung), industrielle Inspektion (Fehlerbereichsmessung). Erwartete Ausgabe: pixelweise Klassenkarte in gleicher Größe wie die Eingabe. Hinweis: Erfordert spezialisierte Architekturen (U-Net, DeepLab) - rechenintensiv."
    },
    "training_batch_size_title": "Batch-Größe",
    "training_batch_size_description": "Anzahl der Bilder, die zusammen in einem Trainingsschritt verarbeitet werden. Größere Batches sorgen für stabilere Gradienten und schnelleres Training, erfordern aber mehr GPU-Speicher. Zu klein (1-4) verursacht verrauschte Updates, zu groß kann die Generalisierung beeinträchtigen. Typische Werte: 16-64 für normale GPUs, 8-16 für größere Bilder oder begrenzten Speicher.",
    "training_epochs_title": "Epochen",
    "training_epochs_description": "Wie oft das Modell den gesamten Datensatz durchlaufen soll. Mehr Epochen können das Lernen verbessern, aber zu viele führen zu Overfitting. Early Stopping stoppt das Training automatisch, wenn sich die Validierungsleistung nicht mehr verbessert. Typischer Bereich: 10-50 für kleine Datensätze, 50-200 für größere.",
    "training_epochs_enum_descriptor": {
      "auto": "Automatisch (basierend auf Datensatzgröße)"
    },
    "training_learning_rate_title": "Lernrate",
    "training_learning_rate_description": "Wie groß die Gewichtsaktualisierungsschritte bei jeder Iteration sind. Der kritischste Hyperparameter im Deep Learning. Zu hoch: instabiles Training, Verlust sinkt nicht oder oszilliert. Zu niedrig: sehr langsame Konvergenz, Steckenbleiben in lokalen Minima. Typische Startwerte: 0,001-0,01 für Adam, 0,01-0,1 für SGD mit Momentum.",
    "training_weight_decay_title": "Gewichtsabnahme (Weight Decay)",
    "training_weight_decay_description": "L2-Regularisierungsstärke, die große Gewichtswerte bestraft, um Overfitting zu verhindern. Höhere Werte bedeuten stärkere Regularisierung. Typischer Bereich: 0,0001-0,01. Verwende höhere Werte (0,01) für kleine Datensätze, niedrigere (0,0001) für große Datensätze. Funktioniert am besten mit AdamW-Optimierer.",
    "training_input_size_title": "Eingabegröße",
    "training_input_size_description": "Bildgröße in Pixeln (Breite = Höhe). Standard: 224px für die meisten Modelle. Größere Größen (320, 384, 512) erfassen mehr Details, erfordern aber mehr Speicher und Rechenleistung. Für EfficientNet-B4+ Modelle wird 380-528px empfohlen. Größere Größen begünstigen feinkörnige Erkennung und kleine Objekte.",
    "training_normalize_title": "Normalisieren",
    "training_normalize_description": "Bildnormalisierungsparameter zur Standardisierung von Eingabewerten. Stellt sicher, dass Eingabewerte in einem konsistenten Bereich für stabiles Training liegen. Für ImageNet-vortrainierte Modelle ImageNet-Statistiken verwenden (Mittelwert: [0.485, 0.456, 0.406], Std: [0.229, 0.224, 0.225]).",
    "training_normalize_mean_title": "Mittelwert",
    "training_normalize_mean_description": "Mittelwerte pro Kanal (RGB) für die Normalisierung. ImageNet-Standardwerte: [0.485, 0.456, 0.406]. Für benutzerdefinierte Datensätze kann dies als Durchschnitt aller Bilder pro Kanal berechnet werden.",
    "training_normalize_std_title": "Std",
    "training_normalize_std_description": "Standardabweichungswerte pro Kanal (RGB) für die Normalisierung. ImageNet-Standardwerte: [0.229, 0.224, 0.225]. Für benutzerdefinierte Datensätze kann dies als Standardabweichung aller Bilder pro Kanal berechnet werden.",
    "training_val_ratio_title": "Validierungsverhältnis",
    "training_val_ratio_description": "Anteil des gesamten Datensatzes, der als Validierungsset verwendet werden soll (0,0-1,0). Das Validierungsset bewertet die Leistung während des Trainings und wird nicht für Gewichtsaktualisierungen verwendet. Typische Werte: 0,1-0,2 (10-20%). Verwende niedrigere Verhältnisse (0,1) für kleine Datensätze, höhere (0,2) für große Datensätze.",
    "training_dataloader_title": "Dataloader",
    "training_dataloader_description": "Der Dataloader konfiguriert, wie Bilder geladen und für das Training vorbereitet werden. Richtige Einstellungen können das Training erheblich beschleunigen, indem die GPU-Auslastung maximiert wird.",
    "training_dataloader_num_workers_title": "Anzahl Worker",
    "training_dataloader_num_workers_description": "Anzahl paralleler Datenladeprozesse. Mehr Worker bedeuten schnelleres Datenladen, verbrauchen aber mehr CPU und RAM. Empfohlen: CPU-Kerne / 2, maximal 8-16. Zu viele Worker können Speicherprobleme verursachen. Unter Windows kann 0 für Multiprocessing-Probleme erforderlich sein.",
    "training_dataloader_pin_memory_title": "Pin Memory",
    "training_dataloader_pin_memory_description": "Verwende gepinnten (page-locked) Speicher für schnelleren CPU-GPU-Datentransfer. Für GPU-Training immer aktivieren - reduziert die Datentransferzeit erheblich. Nur für reines CPU-Training deaktivieren.",
    "training_dataloader_persistent_workers_title": "Persistente Worker",
    "training_dataloader_persistent_workers_description": "Halte Worker-Prozesse zwischen Epochen am Leben, anstatt sie nach jeder Epoche neu zu starten. Beschleunigt das Training durch Vermeidung von Neustart-Overhead, verbraucht aber mehr Speicher. Empfohlen für längere Trainingsläufe.",
    "training_dataloader_prefetch_factor_title": "Prefetch-Faktor",
    "training_dataloader_prefetch_factor_description": "Wie viele Batches jeder Worker im Hintergrund vorladen soll, bevor sie benötigt werden. Höhere Werte (2-4) sorgen für einen reibungsloseren Datenfluss, verbrauchen aber mehr Speicher. Standardwert 2 funktioniert in den meisten Fällen gut.",
    "training_augmentation_title": "Augmentation",
    "training_augmentation_description": "Datenaugmentationskonfiguration zur Erstellung künstlicher Datenvariationen. Augmentation wendet zufällige Transformationen auf Bilder an (Rotation, Spiegelung, Farbänderungen), was die Modellgeneralisierung verbessert und Overfitting reduziert.",
    "training_augmentation_train_title": "Trainings-Augmentationen",
    "training_augmentation_train_description": "Liste der Augmentationen, die auf Trainingsdaten angewendet werden. Diese zufälligen Transformationen erhöhen künstlich die Datenvielfalt. Stärkere Augmentation für kleine Datensätze empfohlen, schwächere oder keine für große Datensätze.",
    "training_augmentation_val_title": "Validierungs-Augmentationen",
    "training_augmentation_val_description": "Minimale Augmentationen, die auf Validierungsdaten angewendet werden. Normalerweise sind nur Größenänderung und Normalisierung erforderlich - Validierungsergebnisse sollten deterministisch und reproduzierbar für eine objektive Bewertung der Modellleistung sein.",
    "training_optimizer_type_title": "Optimierertyp",
    "training_optimizer_type_description": "Der Optimierungsalgorithmus bestimmt, wie Modellgewichte während des Trainings aktualisiert werden. Jeder Optimierer hat unterschiedliche Eigenschaften hinsichtlich Konvergenzgeschwindigkeit, Stabilität und Speichernutzung. Die richtige Wahl hängt von deiner Modellgröße, dem Datensatz und den Trainingszielen ab.",
    "training_optimizer_type_enum_descriptor": {
      "sgd": "SGD (Stochastic Gradient Descent) - Der klassische, grundlegende Optimierer. Aktualisiert Gewichte, indem er sich in Richtung des negativen Gradienten bewegt, skaliert mit der Lernrate. Mit Momentum akkumuliert er Geschwindigkeit für schnellere Konvergenz und glattere Updates. Einfach, speichereffizient und gut verstanden. Am besten für: groß angelegtes Training, wenn du Reproduzierbarkeit benötigst, Feinabstimmung vortrainierter Modelle, ConvNets mit richtigem LR-Scheduling. Erwartete Ergebnisse: zuverlässige Konvergenz, erreicht oft die beste Endgenauigkeit bei richtiger Abstimmung. Erfordert sorgfältige Lernratenauswahl und benötigt typischerweise LR-Scheduling.",
      "adam": "Adam (Adaptive Moment Estimation) - Kombiniert Momentum (erstes Moment) mit RMSprops adaptiven Lernraten (zweites Moment). Behält parameterweise Lernraten bei, die sich basierend auf der Gradientenhistorie anpassen. Schnelle Konvergenz mit minimaler Hyperparameter-Abstimmung. Am besten für: schnelles Prototyping, Transformer, NLP-Aufgaben, spärliche Gradienten, wenn du gute Ergebnisse ohne umfangreiche Abstimmung möchtest. Erwartete Ergebnisse: schnelle anfängliche Konvergenz, gute Standardleistung. Kann bei einigen Vision-Aufgaben etwas schlechter generalisieren als gut abgestimmtes SGD.",
      "adamw": "AdamW (Adam with Decoupled Weight Decay) - Korrigiert Adams Implementierung der Gewichtsabnahme, indem sie von Gradienten-Updates entkoppelt wird. Dies ist der KORREKTE Weg, L2-Regularisierung mit adaptiven Optimierern anzuwenden. Für die meisten Anwendungsfälle gegenüber Standard-Adam empfohlen. Am besten für: jede Aufgabe, bei der du Adam verwenden würdest, insbesondere mit Gewichtsabnahme/Regularisierung, Transformer, moderne Architekturen. Erwartete Ergebnisse: bessere Generalisierung als Adam, effektivere Regularisierung, oft die beste Standardwahl für Deep Learning.",
      "adamax": "Adamax - Adam-Variante, die die Unendlichkeitsnorm (max) anstelle der L2-Norm für das zweite Moment verwendet. Stabiler bei großen oder spärlichen Gradienten. Weniger empfindlich gegenüber der Wahl der Lernrate. Am besten für: Embeddings mit großem Vokabular, NLP-Aufgaben, wenn Adam instabiles Verhalten zeigt, spärliche oder verrauschte Gradienten. Erwartete Ergebnisse: stabileres Training als Adam in Grenzfällen, ähnliche Konvergenzgeschwindigkeit.",
      "nadam": "NAdam (Nesterov-accelerated Adam) - Integriert Nesterov-Momentum in Adam und bietet vorausschauende Gradientenberechnung. Kombiniert schnelles adaptives Lernen mit verbessertem Momentum. Am besten für: Aufgaben, die von Nesterov-Momentum profitieren, RNNs, Sequenzmodelle, wenn du schnellere Konvergenz als Adam möchtest. Erwartete Ergebnisse: etwas schnellere Konvergenz als Adam, besserer Umgang mit Gradientenrauschen.",
      "radam": "RAdam (Rectified Adam) - Adressiert Adams Varianzproblem im frühen Training durch Einführung eines Rektifizierungsterms. Bietet automatisches Warmup, ohne explizite LR-Warmup-Pläne zu benötigen. Stabileres frühes Training. Am besten für: Training von Grund auf ohne Warmup, wenn Adam erratisches frühes Verhalten zeigt, automatisierte Pipelines, bei denen manuelles Warmup-Tuning nicht machbar ist. Erwartete Ergebnisse: stabiles Training ab Schritt 1, eliminiert Notwendigkeit für Warmup, ähnliche Endleistung wie Adam.",
      "rmsprop": "RMSprop (Root Mean Square Propagation) - Teilt die Lernrate durch den gleitenden Durchschnitt der jüngsten Gradientenmagnituden. Passt die Lernrate pro Parameter an. Vorläufer von Adam ohne Momentum-Komponente. Am besten für: RNNs und rekurrente Architekturen, nicht-stationäre Ziele, Online-Lernen. Erwartete Ergebnisse: gut für rekurrente Netzwerke, weniger effektiv als Adam für die meisten CNN-Aufgaben.",
      "rprop": "Rprop (Resilient Propagation) - Verwendet nur das Vorzeichen der Gradienten, nicht die Magnitude. Jeder Parameter hat seine eigene adaptive Schrittgröße, die sich erhöht, wenn das Gradientenvorzeichen konsistent ist, und bei Vorzeichenwechseln verringert. Am besten für: nur Full-Batch-Training, kleine Datensätze, die in den Speicher passen, wenn Gradientenmagnituden unzuverlässig sind. Erwartete Ergebnisse: schnelle Konvergenz für Full-Batch, NICHT geeignet für Mini-Batch-Training (wird fehlschlagen).",
      "adagrad": "Adagrad (Adaptive Gradient) - Akkumuliert alle vergangenen quadrierten Gradienten, wodurch häufig aktualisierte Parameter kleinere Lernraten erhalten. Gut für spärliche Merkmale. Am besten für: spärliche Daten (NLP, Empfehlungen), Merkmale mit sehr unterschiedlichen Häufigkeiten, wenn einige Parameter viel kleinere Updates benötigen. Erwartete Ergebnisse: handhabt spärliche Gradienten gut. Nachteil: Lernrate nimmt kontinuierlich ab, kann bei dichten Aufgaben zu früh aufhören zu lernen.",
      "adadelta": "Adadelta - Adressiert Adagrads abnehmende Lernrate durch Verwendung von gefensterten akkumulierten Gradienten anstelle aller vergangenen Gradienten. Keine Notwendigkeit, die anfängliche Lernrate festzulegen. Am besten für: wenn du die Lernrate nicht abstimmen möchtest, Fortsetzung von Adagrad ohne Lernratenabnahme. Erwartete Ergebnisse: nachhaltigeres Lernen als Adagrad, aber im Allgemeinen von der Adam-Familie übertroffen.",
      "sparse_adam": "Sparse Adam - Adam-Variante, optimiert für spärliche Gradiententensoren. Aktualisiert nur Parameter, die Gradienten ungleich Null erhalten haben. Speichereffizient für große Embedding-Tabellen. Am besten für: große Embedding-Schichten, spärliche NLP-Aufgaben, Empfehlungssysteme mit riesigen Artikelkatalogen. Erwartete Ergebnisse: gleich wie Adam, aber mit besserer Speichereffizienz für spärliche Updates.",
      "lbfgs": "L-BFGS (Limited-memory BFGS) - Optimierer zweiter Ordnung, der die Hesse-Matrix unter Verwendung von begrenztem Speicher approximiert. Leistungsstark, erfordert aber Full-Batch-Gradienten. Am besten für: kleine Datensätze, Neural Style Transfer, physik-informierte Netzwerke, wenn du Full-Batch-Gradienten berechnen kannst. Erwartete Ergebnisse: sehr schnelle Konvergenz, wenn anwendbar. NICHT geeignet für Mini-Batch-Training oder große Datensätze.",
      "asgd": "ASGD (Averaged SGD) - Behält den gleitenden Durchschnitt der Parameter während des Trainings bei und verwendet gemittelte Gewichte für das endgültige Modell. Theoretische Konvergenzgarantien. Am besten für: konvexe oder fast konvexe Probleme, wenn du theoretische Garantien möchtest, einfache Modelle. Erwartete Ergebnisse: gute Konvergenz für einfachere Modelle, weniger effektiv für tiefe Netzwerke im Vergleich zu Adam/SGD mit Momentum."
    },
    "training_optimizer_lr_title": "Optimierer LR",
    "training_optimizer_lr_description": "Die Lernrate des Optimierers, die die Schrittgröße der Gewichtsaktualisierung bestimmt. Zu hoch verursacht instabiles Training, zu niedrig verursacht langsame Konvergenz. Typische Werte: 0,001 für Adam/AdamW, 0,01-0,1 für SGD mit Momentum.",
    "training_optimizer_weight_decay_title": "Optimierer Gewichtsabnahme",
    "training_optimizer_weight_decay_description": "L2-Regularisierung im Optimierer. Drückt Gewichte gegen Null, um Overfitting zu verhindern. Am effektivsten mit AdamW (entkoppelte Gewichtsabnahme). Typische Werte: 0,01-0,1 für starke Regularisierung, 0,0001-0,001 für schwache.",
    "training_optimizer_params_title": "Optimierer-Parameter",
    "training_optimizer_params_description": "Optimiererspezifische fortgeschrittene Parameter wie Momentum, Betas, Epsilon. Diese dienen der Feinabstimmung des Optimiererverhaltens. Standardwerte funktionieren in den meisten Fällen gut - nur ändern, wenn du ein erfahrener Benutzer bist.",
    "training_scheduler_type_title": "Scheduler-Typ",
    "training_scheduler_type_description": "Lernraten-Scheduling steuert, wie sich die Lernrate während des Trainings ändert. Richtiges Scheduling kann Konvergenz, Endgenauigkeit und Trainingsstabilität dramatisch verbessern. Unterschiedliche Scheduler passen zu unterschiedlichen Trainingsszenarien und Modellarchitekturen.",
    "training_scheduler_type_enum_descriptor": {
      "step_lr": "Step LR - Verringert die Lernrate um einen festen Faktor (Gamma) alle N Epochen. Einfach und vorhersehbar. Am besten für: Standard-Trainingspläne, wenn du ungefähr weißt, wann LR reduziert werden soll, Baseline-Experimente. Erwartete Ergebnisse: stetiges Training mit periodischen Sprüngen im Verlust, wenn LR fällt, dann fortgesetzte Verbesserung. Typischerweise LR alle 30-50 Epochen mit 0,1 multiplizieren.",
      "multi_step_lr": "Multi-Step LR - Verringert die Lernrate bei angegebenen Epochen-Meilensteinen. Mehr Kontrolle als Step LR. Am besten für: wenn du genaue Epochen kennst, bei denen LR fallen soll, Reproduktion veröffentlichter Trainingspläne, feinkörnige Kontrolle. Erwartete Ergebnisse: ähnlich wie Step LR, aber mit benutzerdefiniertem Timing. Gängiges Muster: Abfall bei 60%, 80% der Gesamtepochen.",
      "exponential_lr": "Exponential LR - Multipliziert die Lernrate jede Epoche mit Gamma für kontinuierlichen glatten Abfall. Am besten für: schrittweise Feinabstimmung, wenn schrittweise Abfälle zu abrupt sind, lange Trainingsläufe. Erwartete Ergebnisse: glatte, kontinuierliche LR-Reduktion. Erfordert sorgfältige Gamma-Auswahl (typischerweise 0,95-0,99), um zu schnellen Abfall zu vermeiden.",
      "cosine_annealing_lr": "Cosine Annealing - Lernrate folgt einer Kosinuskurve vom Anfangs- zum Minimalwert. Glatter Abfall, der sich gegen Ende verlangsamt. Sehr beliebt für modernes Training. Am besten für: Training mit fester Länge, Erreichen der besten Endgenauigkeit, die meisten CNN-Trainings, Wettbewerbsmodelle. Erwartete Ergebnisse: hervorragende Endgenauigkeit, glattes Training. Der sanfte Abfall nahe dem Minimum ermöglicht feine Konvergenz.",
      "cosine_annealing_warm_restarts": "Cosine with Warm Restarts - Cosine Annealing, das periodisch auf die anfängliche LR zurückgesetzt wird. Jeder Neustart erkundet verschiedene Bereiche der Verlustoberfläche. Am besten für: Entkommen aus lokalen Minima, ensemble-artiges Einzelmodelltraining, wenn einzelner Kosinus stagniert. Erwartete Ergebnisse: kann bessere Optima finden als einzelner Abfall, jeder Neustart kann sich verbessern oder anders erkunden. Gut für längeres Training.",
      "reduce_lr_on_plateau": "Reduce on Plateau - Überwacht eine Metrik (normalerweise val_loss) und reduziert LR, wenn sie sich nicht mehr verbessert. Adaptiv und erfordert keine Epochenplanung. Am besten für: wenn du den optimalen Zeitplan nicht kennst, Training mit variabler Länge, wenn das Verhalten des Validierungsverlusts unvorhersehbar ist. Erwartete Ergebnisse: automatische Anpassung an die Trainingsdynamik. Kann länger trainieren, findet aber automatisch gute LR.",
      "cyclic_lr": "Cyclic LR - Lernrate oszilliert zwischen minimalen und maximalen Grenzen. Kann dreieckige, dreieckige2 oder exp_range Richtlinien verwenden. Am besten für: Entkommen aus lokalen Minima, wenn du mehrere LR-Bereiche erkunden möchtest, Super-Konvergenz-Experimente. Erwartete Ergebnisse: periodische Verlustoszillation, potenziell bessere Generalisierung. Erfordert sorgfältige Grenzwertauswahl.",
      "one_cycle_lr": "One Cycle - Startet niedrig, steigt auf max. LR an, fällt dann ab. Ermöglicht Super-Konvergenz mit sehr hohen Lernraten. Am besten für: schnelles Training mit hoher LR, schnelles Erreichen guter Genauigkeit, wenn die Trainingszeit begrenzt ist. Erwartete Ergebnisse: schnelle Konvergenz, entspricht oder übertrifft oft längere Zeitpläne in weniger Zeit. Erfordert richtige Wahl der max. LR (LR-Range-Test empfohlen).",
      "polynomial_lr": "Polynomial LR - Verringert die Lernrate unter Verwendung einer Polynomfunktion mit angegebener Potenz. Potenz=1 ist linear, höhere Potenzen fallen anfangs schneller ab. Am besten für: feinkörnige Kontrolle über die Abfallkurvenform, Anpassung an spezifische veröffentlichte Zeitpläne. Erwartete Ergebnisse: anpassbare Abfallform. Potenz=2 (quadratisch) ergibt schnelleren frühen Abfall, langsameren späten Abfall.",
      "linear_lr": "Linear LR - Einfache lineare Interpolation zwischen Start- und Endlernraten. Kann Warmup (steigend) oder Decay (fallend) implementieren. Am besten für: Warmup-Phasen, einfache interpretierbare Zeitpläne, Kombination mit anderen Schedulern. Erwartete Ergebnisse: vorhersehbare, stetige LR-Änderung. Oft für die ersten paar Epochen als Warmup verwendet.",
      "lambda_lr": "Lambda LR - Benutzerdefinierte Funktion bestimmt LR in jeder Epoche. Maximale Flexibilität. Am besten für: benutzerdefinierte Zeitpläne, Forschungsexperimente, wenn kein eingebauter Scheduler deinen Bedürfnissen entspricht. Erwartete Ergebnisse: was auch immer deine Funktion definiert. Erfordert Programmierung einer benutzerdefinierten Lambda-Funktion.",
      "multiplicative_lr": "Multiplicative LR - Multipliziert die aktuelle LR jede Epoche mit einem Faktor, der von einer Benutzerfunktion zurückgegeben wird. Kumulativer Effekt. Am besten für: benutzerdefinierte Abfallmuster, wenn der Zeitplan von der aktuellen LR abhängen soll. Erwartete Ergebnisse: hängt von deiner multiplikativen Funktion ab. Nützlich für die Implementierung benutzerdefinierter adaptiver Zeitpläne."
    },
    "training_scheduler_step_size_title": "Schrittgröße",
    "training_scheduler_step_size_description": "Anzahl der Epochen zwischen Lernratenreduktionen (für StepLR). Kleinere Werte bedeuten häufigere Reduktionen. Typische Werte: 10-30 Epochen. Erwäge, LR zuerst bei 1/3 oder 1/2 der gesamten Trainingszeit zu reduzieren.",
    "training_scheduler_gamma_title": "Gamma",
    "training_scheduler_gamma_description": "Lernratenmultiplikationsfaktor bei jeder Reduktion. Wert von 0,1 bedeutet 10-fache Reduktion (z.B. 0,01 -> 0,001). Typische Werte: 0,1 für aggressive Reduktion, 0,5 für graduelle. Für exponentielle Scheduler ist 0,95-0,99 üblich.",
    "training_scheduler_params_title": "Scheduler-Parameter",
    "training_scheduler_params_description": "Schedulerspezifische fortgeschrittene Parameter wie T_max, eta_min, Meilensteine. Diese dienen der Feinabstimmung des Schedulerverhaltens für den spezifischen Schedulertyp. Standards funktionieren in den meisten Fällen gut.",
    "training_loss_type_title": "Verlusttyp",
    "training_loss_type_description": "Verlustfunktionen messen, wie gut Modellvorhersagen mit der Grundwahrheit übereinstimmen. Die Wahl der Verlustfunktion prägt grundlegend, was das Modell lernt. Unterschiedliche Verluste haben unterschiedliche Gradienten, Empfindlichkeiten und Verhaltensweisen. Falsche Wahl kann zu Trainingsfehlern, schlechter Generalisierung oder verzerrten Vorhersagen führen.",
    "training_loss_type_enum_descriptor": {
      "cross_entropy": "Cross Entropy - Standardverlust für Multi-Class-Klassifizierung. Kombiniert Log-Softmax und NLL-Loss. Bestraft zuversichtliche falsche Vorhersagen stark. Am besten für: Bildklassifizierung, die meisten Multi-Class-Probleme, sich gegenseitig ausschließende Kategorien. Erwartete Ergebnisse: gut kalibrierte Wahrscheinlichkeiten, schnelle Konvergenz bei ausgewogenen Daten. NEGATIVE EFFEKTE: Kämpft mit Klassenungleichgewicht (seltene Klassen werden ignoriert), hochempfindlich gegenüber Labelrauschen (falsch gelabelte Proben verursachen große Gradienten), kann bei Out-of-Distribution-Daten übermäßig zuversichtlich werden.",
      "nll_loss": "NLL Loss (Negative Log Likelihood) - Erwartet Log-Wahrscheinlichkeiten als Eingabe (zuerst log_softmax anwenden). Mathematisch äquivalent zu Cross Entropy, wenn mit log_softmax kombiniert. Am besten für: wenn du explizites Log-Softmax für andere Zwecke benötigst, benutzerdefinierte Wahrscheinlichkeitsbehandlung. Erwartete Ergebnisse: gleich wie Cross Entropy. NEGATIVE EFFEKTE: Gleich wie Cross Entropy. Zusätzlich führt das Vergessen von log_softmax zu stillem Versagen mit falschen Gradienten.",
      "bce_loss": "BCE Loss (Binary Cross Entropy) - Für binäre Klassifizierung oder Multi-Label-Probleme. Erwartet Wahrscheinlichkeiten (zuerst Sigmoid anwenden). Jede Ausgabe ist eine unabhängige binäre Entscheidung. Am besten für: binäre Klassifizierung, Multi-Label-Klassifizierung, bei der Elemente mehrere Labels haben können. Erwartete Ergebnisse: unabhängige Wahrscheinlichkeit pro Klasse, gut für Multi-Label. NEGATIVE EFFEKTE: Numerisch instabil bei extremen Vorhersagen (verwende stattdessen bce_with_logits), empfindlich gegenüber Klassenungleichgewicht in Multi-Label-Einstellungen, erfordert sorgfältige Schwellenwertauswahl für Vorhersagen.",
      "bce_with_logits": "BCE with Logits - Numerisch stabiles BCE, das Sigmoid und BCE in einer Operation kombiniert. Bevorzugt gegenüber separatem Sigmoid + BCE. Am besten für: alle Fälle, in denen du BCE-Loss verwenden würdest, binäre und Multi-Label-Klassifizierung. Erwartete Ergebnisse: stabiles Training, gleiche Ergebnisse wie BCE, aber robuster. NEGATIVE EFFEKTE: Gleiche konzeptionelle Probleme wie BCE (Klassenungleichgewicht, Schwellenwertauswahl), aber numerisch stabil. Kämpft immer noch mit extremem Positiv/Negativ-Ungleichgewicht.",
      "multi_margin": "Multi-Margin Loss - Hinge-basierter Verlust für Multi-Class-SVM-artige Klassifizierung. Erzeugt Marge zwischen korrekter Klasse und anderen. Am besten für: SVM-artige Klassifizierer, wenn du maximale Margentrennung möchtest, robuste Klassifizierung. Erwartete Ergebnisse: größere Margen zwischen Klassen, potenziell robuster gegenüber Ausreißern als Cross Entropy. NEGATIVE EFFEKTE: Schwerer abzustimmender Margenparameter, produziert keine kalibrierten Wahrscheinlichkeiten (Ausgaben sind nicht als Konfidenz interpretierbar), kann langsamer konvergieren als Cross Entropy.",
      "multi_label_margin": "Multi-Label Margin Loss - Margenbasierter Verlust für Multi-Label-Klassifizierung. Stellt sicher, dass positive Labels um eine Marge höher bewertet werden als negative Labels. Am besten für: Multi-Label-Ranking, bei dem die relative Reihenfolge zählt, Multi-Label-SVMs. Erwartete Ergebnisse: positive Labels punkten konsistent über negativen. NEGATIVE EFFEKTE: Liefert keine kalibrierten Wahrscheinlichkeiten, empfindlich gegenüber Margen-Hyperparameter, kann kämpfen, wenn positive und negative Labels sehr unterschiedliche Häufigkeiten haben.",
      "multi_label_soft_margin": "Multi-Label Soft Margin - Sigmoid Cross Entropy für Multi-Label, behandelt jedes Label als unabhängig binär. Im Wesentlichen BCE über alle Labels. Am besten für: Multi-Label-Klassifizierung, Standardwahl für Multi-Label-Probleme. Erwartete Ergebnisse: ähnlich wie BCE, handhabt mehrere Labels gut. NEGATIVE EFFEKTE: Jedes unabhängig trainierte Label ignoriert Labelkorrelationen, unausgewogene Labels können das Training dominieren, kann inkohärente Labelkombinationen vorhersagen.",
      "mse_loss": "MSE Loss (Mean Squared Error) - Quadratische Differenz zwischen Vorhersagen und Zielen. Standard-Regressionsverlust. Bestraft große Fehler stark (quadratisch). Am besten für: Regressionsaufgaben, Vorhersage kontinuierlicher Werte, wenn Fehler normalverteilt sind. Erwartete Ergebnisse: Vorhersagen zentriert auf Mittelwert, empfindlich gegenüber Ausreißern. NEGATIVE EFFEKTE: Sehr empfindlich gegenüber Ausreißern (ein einzelner Ausreißer kann den Verlust dominieren), neigt dazu, in mehrdeutigen Fällen Mittelwerte vorherzusagen, kann zu Gradientenexplosion bei großen Fehlern früh im Training führen.",
      "l1_loss": "L1 Loss (Mean Absolute Error) - Absolute Differenz zwischen Vorhersagen und Zielen. Lineare Strafe, robuster gegenüber Ausreißern als MSE. Am besten für: Regression mit Ausreißern, wenn du Medianvorhersagen möchtest, robuste Schätzung. Erwartete Ergebnisse: Vorhersagen näher am Median, weniger von Ausreißern beeinflusst. NEGATIVE EFFEKTE: Nicht-glatter Gradient bei Null (Diskontinuität), kann instabile Updates nahe korrekter Vorhersagen verursachen, langsamere Konvergenz als MSE auf sauberen Daten.",
      "smooth_l1": "Smooth L1 Loss - Kombiniert L1 und L2: quadratisch, wenn Fehler klein ist, linear, wenn groß. Das Beste aus beiden Welten. Am besten für: Objekterkennung (Bounding-Box-Regression), robuste Regression, wenn du MSE-Vorteile ohne Ausreißerempfindlichkeit möchtest. Erwartete Ergebnisse: stabiles Training, robust gegenüber Ausreißern, glatte Gradienten. NEGATIVE EFFEKTE: Erfordert Abstimmung des Beta-Parameters für Übergangspunkt, immer noch etwas empfindlich gegenüber Ausreißern (nur weniger als MSE), fügt Hyperparameter-Komplexität hinzu.",
      "huber_loss": "Huber Loss - Ähnlich wie Smooth L1. Quadratisch für kleine Fehler, linear für große. Robuster Regressionsstandard. Am besten für: Regression mit potenziellen Ausreißern, Finanzvorhersagen, jede Regression, bei der Ausreißer möglich sind. Erwartete Ergebnisse: robuste Vorhersagen, glatte Konvergenz. NEGATIVE EFFEKTE: Delta-Parameter erfordert Abstimmung auf deine Fehlerskala, falsches Delta macht es äquivalent zu reinem L1 oder MSE und negiert Vorteile.",
      "kl_div": "KL Divergence (Kullback-Leibler) - Misst, wie eine Wahrscheinlichkeitsverteilung von einer anderen abweicht. Verwendet für Verteilungsanpassung. Am besten für: Knowledge Distillation, VAE-Regularisierung, Anpassung der Ausgabe an Zielverteilung. Erwartete Ergebnisse: Ausgabeverteilung nähert sich Zielverteilung an. NEGATIVE EFFEKTE: Asymmetrisch (KL(P||Q) != KL(Q||P)), unendlich, wenn Ziel Nullen hat, wo Vorhersage keine hat, erfordert sorgfältige Log-Wahrscheinlichkeitsbehandlung, Mode-Seeking-Verhalten kann multimodale Ziele verfehlen.",
      "margin_ranking": "Margin Ranking Loss - Lernt, Paare zu ordnen: x1 sollte höher als x2 eingestuft werden, wenn y=1. Margenbasiertes paarweises Ranking. Am besten für: Learning to Rank, Empfehlungssysteme, wenn relative Reihenfolge wichtiger ist als absolute Werte. Erwartete Ergebnisse: korrekt geordnete Paare mit Margentrennung. NEGATIVE EFFEKTE: Erfordert Paargenerierung (quadratische Komplexität), optimiert nicht direkt listenweise Ranking-Metriken, Margenparameter muss abgestimmt werden, empfindlich gegenüber Paar-Sampling-Strategie.",
      "hinge_embedding": "Hinge Embedding Loss - Zum Lernen von Embeddings, bei denen ähnliche Elemente nahe beieinander liegen sollten, unähnliche weit voneinander entfernt. Verwendet Hinge-Loss-Formulierung. Am besten für: Embedding-Lernen, Ähnlichkeitslernen, metrisches Lernen mit Paaren. Erwartete Ergebnisse: sinnvoller Embedding-Raum mit Margentrennung. NEGATIVE EFFEKTE: Schwer abzustimmende Marge, kann Embeddings kollabieren lassen, wenn Marge zu groß, erfordert sorgfältiges Mining positiver/negativer Paare.",
      "triplet_margin": "Triplet Margin Loss - Nimmt Anker-, positive und negative Proben. Lernt Embeddings, bei denen Anker näher an positiv als an negativ um Marge ist. Am besten für: Gesichtserkennung, Bildabruf, feinkörnige Ähnlichkeit. Erwartete Ergebnisse: starker Embedding-Raum für Ähnlichkeitssuche. NEGATIVE EFFEKTE: Erfordert teures Triplet-Mining, viele Triplets werden uninformativ (zu einfach), Training kann langsam sein, Marge und Mining-Strategie kritisch für Erfolg, benötigt möglicherweise Hard-Negative-Mining.",
      "cosine_embedding": "Cosine Embedding Loss - Lernt Embeddings unter Verwendung von Kosinusähnlichkeit. Ähnliche Paare sollten hohe Kosinusähnlichkeit haben, unähnliche niedrige. Am besten für: Text-Embeddings, wenn Magnitude keine Rolle spielen sollte, semantische Ähnlichkeitsaufgaben. Erwartete Ergebnisse: richtungsbasierte Ähnlichkeit im Embedding-Raum. NEGATIVE EFFEKTE: Ignoriert Magnitudeninformationen (manchmal wichtig), empfindlich gegenüber Initialisierung, kann mit feinkörnigen Unterscheidungen kämpfen.",
      "ctc_loss": "CTC Loss (Connectionist Temporal Classification) - Für Sequenz-zu-Sequenz, wo Ausrichtung unbekannt ist. Summiert über alle gültigen Ausrichtungen. Am besten für: Spracherkennung, OCR, Handschrifterkennung, jede Sequenzaufgabe ohne explizite Ausrichtung. Erwartete Ergebnisse: lernt Ausrichtung implizit, handhabt variable Länge. NEGATIVE EFFEKTE: Nimmt an, dass Ausgabesequenz kürzer als Eingabe ist, rechenintensiv, kann mit langen Sequenzen kämpfen, erfordert Blank-Token-Behandlung, spitze Ausgabeverteilungen können Erkennungsfehler verursachen.",
      "poisson_nll": "Poisson NLL Loss - Negative Log Likelihood unter Annahme Poisson-verteilter Ziele. Für nicht-negative ganzzahlige Zähldaten. Am besten für: Ereigniszählung, Ratenschätzung, jede nicht-negative Zählvorhersage. Erwartete Ergebnisse: angemessen für Zähldaten, handhabt Null-Inflation besser als MSE. NEGATIVE EFFEKTE: Nimmt an, dass Varianz gleich Mittelwert ist (reale Daten oft überdispers), erfordert positive Vorhersagen (verwende exp-Transformation), nicht geeignet für kontinuierliche Ziele.",
      "gaussian_nll": "Gaussian NLL Loss - NLL unter Annahme Gaußscher Ziele. Modell sagt sowohl Mittelwert als auch Varianz vorher, was Unsicherheitsschätzung ermöglicht. Am besten für: Regression mit Unsicherheit, Konfidenzintervalle, heteroskedastische Regression. Erwartete Ergebnisse: kalibrierte Unsicherheitsschätzungen neben Vorhersagen. NEGATIVE EFFEKTE: Kann hohe Varianz vorhersagen, um Strafe zu vermeiden (Varianzkollaps), erfordert sorgfältige Initialisierung des Varianzkopfes, verdoppelt Ausgabegröße, Training kann instabil sein, wenn Varianzvorhersagen schlecht initialisiert sind.",
      "focal_loss": "Focal Loss - Entwickelt, um extremes Klassenungleichgewicht (z.B. 1:1000) zu adressieren. Gewichtet einfache Beispiele herunter und konzentriert das Training auf harte Negative. Am besten für: Objekterkennung, stark unausgewogene Klassifizierung. Erwartete Ergebnisse: bessere Leistung bei seltenen Klassen.",
      "label_smoothing": "Label Smoothing - Regularisierungstechnik, die verhindert, dass das Modell zu zuversichtlich wird. Statt 0 und 1 Zielen verwendet es z.B. 0,1 und 0,9. Am besten für: Verbesserung der Generalisierung, Verhinderung von Overfitting. Erwartete Ergebnisse: bessere Kalibrierung, etwas höhere Genauigkeit auf dem Validierungsset.",
      "soft_target_cross_entropy": "Soft Target Cross Entropy - Cross Entropy, die kontinuierliche Wahrscheinlichkeitsverteilungen als Ziele anstelle von harten Klassenlabels akzeptiert. Am besten für: MixUp, CutMix, Knowledge Distillation. Erwartete Ergebnisse: ermöglicht Training mit augmentierten Labels."
    },
    "training_loss_reduction_title": "Reduktion",
    "training_loss_reduction_description": "Wie individuelle Verluste innerhalb eines Batches aggregiert werden. Mean: Durchschnitt über Batch liefert normalisierte Gradienten. Sum: summiert alle Verluste, skaliert mit Batch-Größe. None: behält individuelle Verluste für Spezialfälle.",
    "training_loss_reduction_enum_descriptor": {
      "mean": "Mean - Durchschnitt über Batch (empfohlen, Batch-Größen-unabhängige Gradienten)",
      "sum": "Sum - Summe über Batch (größerer Batch = größerer Gradient)",
      "none": "None - Keine Reduktion (behalte individuelle Verluste)"
    },
    "training_loss_params_title": "Verlustparameter",
    "training_loss_params_description": "Verlustfunktionsspezifische fortgeschrittene Parameter wie Klassengewichte, Margenwerte, Glättungsfaktoren. Diese dienen der Feinabstimmung des Verlustfunktionsverhaltens für Spezialfälle.",
    "training_weight_init_title": "Gewichtsinitialisierung",
    "training_weight_init_description": "Wie neuronale Netzwerk-Gewichte vor dem Training initialisiert werden. Richtige Initialisierung ist entscheidend für stabiles Training - schlechte Initialisierung kann zu verschwindenden oder explodierenden Gradienten führen. Bei vortrainierten Modellen betrifft dies nur neu hinzugefügte Schichten.",
    "training_weight_init_type_title": "Typ",
    "training_weight_init_params_title": "Init-Parameter",
    "training_weight_init_params_description": "Initialisierungsmethodenspezifische Parameter wie Verstärkung, Std, Sparsamkeit. Diese dienen der Feinabstimmung des Initialisierungsverhaltens. Standards funktionieren im Allgemeinen gut.",
    "weight_init_type_enum_descriptor": {
      "kaiming_normal": "Kaiming Normal - He-Initialisierung (normal)",
      "kaiming_uniform": "Kaiming Uniform - He-Initialisierung (uniform)",
      "xavier_normal": "Xavier Normal - Glorot-Initialisierung (normal)",
      "xavier_uniform": "Xavier Uniform - Glorot-Initialisierung (uniform)",
      "normal": "Normal - Gaußsche Initialisierung",
      "uniform": "Uniform - Gleichverteilung",
      "trunc_normal": "Truncated Normal - Begrenzte Gaußsche",
      "orthogonal": "Orthogonal - Orthogonale Matrix",
      "sparse": "Sparse - Spärliche Initialisierung",
      "constant": "Constant - Fester Wert",
      "zeros": "Zeros - Alles Nullen",
      "ones": "Ones - Alles Einsen",
      "eye": "Eye - Einheitsmatrix",
      "dirac": "Dirac - Delta-Funktion"
    },
    "training_checkpoint_title": "Checkpoint",
    "training_checkpoint_description": "Modell-Checkpoint-Konfiguration zur Erhaltung des Trainingsfortschritts. Checkpoints ermöglichen die Wiederaufnahme des Trainings nach Unterbrechung und bewahren das beste Modell basierend auf der Validierungsleistung.",
    "training_checkpoint_save_best_only_title": "Nur Bestes speichern",
    "training_checkpoint_save_frequency_title": "Speicherhäufigkeit",
    "training_checkpoint_best_model_filename_title": "Dateiname bestes Modell",
    "training_checkpoint_model_filename_title": "Dateiname Modell",
    "training_early_stopping_title": "Early Stopping",
    "training_early_stopping_description": "Automatische Trainingsunterbrechung, wenn sich die Validierungsleistung nicht mehr verbessert. Verhindert Overfitting und spart unnötige Rechenzeit. Das System überwacht die gewählte Metrik und stoppt das Training, wenn keine Verbesserung für 'Patience' Epochen erfolgt.",
    "training_early_stopping_enabled_title": "Aktiviert",
    "training_early_stopping_patience_title": "Geduld (Patience)",
    "training_early_stopping_min_delta_title": "Min Delta",
    "training_early_stopping_monitor_title": "Monitor",
    "training_early_stopping_monitor_enum_descriptor": {
      "val_loss": "Validierungsverlust",
      "val_accuracy": "Validierungsgenauigkeit"
    },
    "training_gradient_title": "Gradient",
    "training_gradient_description": "Gradientenbehandlungseinstellungen für verbesserte Trainingsstabilität. Gradient Clipping verhindert explodierende Gradienten, Akkumulation ermöglicht größere effektive Batch-Größen mit begrenztem Speicher.",
    "training_gradient_clip_norm_title": "Clip Norm",
    "training_gradient_clip_value_title": "Clip Wert",
    "training_gradient_accumulation_steps_title": "Akkumulationsschritte",
    "training_runtime_title": "Laufzeit",
    "training_runtime_description": "Laufzeitoptimierungseinstellungen zur Beschleunigung des Trainings und effizienteren GPU-Speichernutzung. Diese Einstellungen sind hardwarespezifisch und können die Trainingsgeschwindigkeit erheblich beeinflussen.",
    "training_runtime_mixed_precision_title": "Mixed Precision",
    "training_runtime_mixed_precision_description": "Aktiviere FP16/FP32 Mixed Precision Training. Reduziert die GPU-Speichernutzung erheblich und beschleunigt das Training auf modernen GPUs (Volta/Turing/Ampere und neuer). Erwarte ~1,5-2x Beschleunigung und ~50% Speicherreduzierung. Sehr empfehlenswert.",
    "training_runtime_channels_last_title": "Channels Last",
    "training_runtime_channels_last_description": "Verwende Channels-Last (NHWC) Speicherformat anstelle von Standard Channels-First (NCHW). Kann zu schnelleren Faltungsoperationen auf modernen GPUs (Volta+) führen. Natives Format für NVIDIA GPUs, das eine bessere Tensor-Core-Auslastung bietet.",
    "training_runtime_allow_tf32_title": "TF32 erlauben",
    "training_runtime_allow_tf32_description": "Aktiviere TensorFloat-32 Präzision auf NVIDIA Ampere und neueren GPUs (RTX 30xx, A100, etc.). Bietet schnellere Matrixoperationen bei nahezu voller FP32-Präzision. Auf kompatibler Hardware sehr empfehlenswert.",
    "training_runtime_cudnn_benchmark_title": "cuDNN Benchmark",
    "training_runtime_cudnn_benchmark_description": "Aktiviere automatische cuDNN-Faltungsalgorithmus-Auswahl. Testet verschiedene Algorithmen in den ersten paar Iterationen und verwendet dann den schnellsten. Beschleunigt das Training bei festen Eingabegrößen. Deaktivieren bei variablen Eingabegrößen.",
    "dataset_description": "Datensatzkonfiguration",
    "dataset_image_extensions_description": "Unterstützte Bilddateierweiterungen",
    "dataset_discovery_description": "Datensatzerkennungseinstellungen",
    "dataset_discovery_annotation_formats_description": "Annotationsformaterkennung",
    "dataset_discovery_txt_annotations_description": "Textannotationserkennung",
    "dataset_discovery_txt_annotations_min_coverage_percent_description": "Minimale Abdeckung für Textannotationen",
    "dataset_discovery_balance_analysis_description": "Datensatz-Balance-Analyse",
    "dataset_discovery_balance_analysis_min_images_per_class_description": "Minimale Bilder pro Klasse",
    "dataset_discovery_balance_analysis_critical_shortage_threshold_description": "Kritische Mangel-Schwelle",
    "dataset_discovery_balance_analysis_over_representation_ratio_description": "Überrepräsentationsverhältnis",
    "dataset_discovery_balance_analysis_under_representation_ratio_description": "Unterrepräsentationsverhältnis",
    "dataset_discovery_balance_analysis_severe_over_representation_ratio_description": "Schweres Überrepräsentationsverhältnis",
    "dataset_discovery_balance_analysis_hierarchical_balance_threshold_description": "Hierarchische Balance-Schwelle",
    "dataset_discovery_balance_analysis_dataset_size_warnings_description": "Datensatzgrößen-Warnschwellen",
    "dataset_discovery_balance_analysis_dataset_size_warnings_tiny_dataset_description": "Warnschwelle für winzige Datensätze",
    "dataset_discovery_balance_analysis_dataset_size_warnings_small_dataset_description": "Warnschwelle für kleine Datensätze",
    "dataset_discovery_balance_analysis_balance_score_thresholds_description": "Balance-Score-Klassifizierungsschwellen",
    "dataset_discovery_balance_analysis_balance_score_thresholds_excellent_description": "Exzellente Balance-Schwelle (95%+)",
    "dataset_discovery_balance_analysis_balance_score_thresholds_very_good_description": "Sehr gute Balance-Schwelle (85%+)",
    "dataset_discovery_balance_analysis_balance_score_thresholds_good_description": "Gute Balance-Schwelle (75%+)",
    "dataset_discovery_balance_analysis_balance_score_thresholds_decent_description": "Anständige Balance-Schwelle (65%+)",
    "dataset_discovery_balance_analysis_balance_score_thresholds_fair_description": "Faire Balance-Schwelle (55%+)",
    "dataset_discovery_balance_analysis_balance_score_thresholds_mediocre_description": "Mittelmäßige Balance-Schwelle (45%+)",
    "dataset_discovery_balance_analysis_balance_score_thresholds_poor_description": "Schlechte Balance-Schwelle (35%+)",
    "dataset_discovery_balance_analysis_balance_score_thresholds_bad_description": "Miserable Balance-Schwelle (25%+)",
    "dataset_discovery_balance_analysis_balance_score_thresholds_terrible_description": "Furchtbare Balance-Schwelle (15%+)",
    "dataset_discovery_balance_analysis_balance_score_thresholds_nonsense_description": "Unsinnige Balance-Schwelle (0%+)",
    "optimizers_description": "Optimiererkonfigurationen",
    "optimizers_defaults_description": "Standard-Optimiererparameter",
    "optimizers_defaults_lbfgs_line_search_fn_enum_descriptor": {
      "strong_wolfe": "Starke Wolfe-Bedingungen"
    },
    "schedulers_description": "Lernraten-Scheduler-Konfigurationen",
    "schedulers_defaults_description": "Standard-Schedulerparameter",
    "schedulers_defaults_lambda_lr_lr_lambda_description": "Lambda-Funktion für LR-Berechnung",
    "schedulers_defaults_multiplicative_lr_lr_lambda_description": "Lambda-Funktion für multiplikative LR",
    "schedulers_defaults_reduce_lr_on_plateau_mode_enum_descriptor": {
      "min": "Metrik minimieren",
      "max": "Metrik maximieren"
    },
    "schedulers_defaults_reduce_lr_on_plateau_threshold_mode_enum_descriptor": {
      "rel": "Relativer Schwellenwert",
      "abs": "Absoluter Schwellenwert"
    },
    "schedulers_defaults_cyclic_lr_mode_enum_descriptor": {
      "triangular": "Triangular - Lineare Oszillation",
      "triangular2": "Triangular2 - Halbierende Amplitude",
      "exp_range": "Exp Range - Exponentieller Abfall"
    },
    "schedulers_defaults_cyclic_lr_scale_mode_enum_descriptor": {
      "cycle": "Pro Zyklus",
      "iterations": "Pro Iteration"
    },
    "schedulers_defaults_one_cycle_lr_anneal_strategy_enum_descriptor": {
      "cos": "Cosine Annealing",
      "linear": "Lineares Annealing"
    },
    "losses_description": "Verlustfunktionskonfigurationen",
    "losses_defaults_description": "Standard-Verlustfunktionsparameter",
    "losses_defaults_multi_margin_p_enum_descriptor": {
      "1": "L1-Norm",
      "2": "L2-Norm"
    },
    "losses_defaults_kl_div_reduction_enum_descriptor": {
      "none": "Keine Reduktion",
      "mean": "Mittelwert-Reduktion",
      "sum": "Summen-Reduktion",
      "batchmean": "Batch-Mittelwert-Reduktion"
    },
    "models_description": "Modellarchitekturkonfigurationen",
    "models_resnet_description": "ResNet-Modellfamilie",
    "models_resnet_variants_description": "Verfügbare ResNet-Varianten",
    "models_resnet_default_optimizer_type_enum_descriptor": {
      "adamw": "AdamW-Optimierer",
      "adam": "Adam-Optimierer",
      "sgd": "SGD-Optimierer"
    },
    "models_resnet_default_scheduler_type_enum_descriptor": {
      "step_lr": "Step LR Scheduler",
      "cosine_annealing_lr": "Cosine Annealing Scheduler",
      "reduce_lr_on_plateau": "Reduce on Plateau Scheduler"
    },
    "models_resnext_description": "ResNeXt-Modellfamilie",
    "models_resnext_variants_description": "Verfügbare ResNeXt-Varianten",
    "models_alexnet_description": "AlexNet-Modellfamilie",
    "models_alexnet_variants_description": "Verfügbare AlexNet-Varianten",
    "models_vgg_description": "VGG-Modellfamilie",
    "models_vgg_variants_description": "Verfügbare VGG-Varianten",
    "models_densenet_description": "DenseNet-Modellfamilie",
    "models_densenet_variants_description": "Verfügbare DenseNet-Varianten",
    "models_mobilenet_description": "MobileNet-Modellfamilie",
    "models_mobilenet_variants_description": "Verfügbare MobileNet-Varianten",
    "models_shufflenet_description": "ShuffleNet-Modellfamilie",
    "models_shufflenet_variants_description": "Verfügbare ShuffleNet-Varianten",
    "models_squeezenet_description": "SqueezeNet-Modellfamilie",
    "models_squeezenet_variants_description": "Verfügbare SqueezeNet-Varianten",
    "models_efficientnet_description": "EfficientNet-Modellfamilie",
    "models_efficientnet_variants_description": "Verfügbare EfficientNet-Varianten",
    "models_supported_types_description": "Liste der unterstützten Modellarchitekturen",
    "activations_description": "Aktivierungsfunktionskonfigurationen",
    "activations_defaults_description": "Standard-Aktivierungsparameter",
    "activations_properties_description": "Aktivierungsfunktionseigenschaften",
    "activations_defaults_leaky_relu_description": "Leaky ReLU Aktivierung",
    "activations_defaults_leaky_relu_negative_slope_description": "Steigung für negative Werte",
    "activations_defaults_prelu_description": "PReLU Aktivierung",
    "activations_defaults_prelu_num_parameters_description": "Anzahl der lernbaren Parameter",
    "activations_defaults_prelu_init_description": "Anfänglicher Steigungswert",
    "activations_defaults_elu_description": "ELU Aktivierung",
    "activations_defaults_elu_alpha_description": "Alpha-Wert für negative Eingaben",
    "activations_defaults_celu_description": "CELU Aktivierung",
    "activations_defaults_celu_alpha_description": "Alpha-Wert",
    "activations_defaults_hardtanh_description": "Hardtanh Aktivierung",
    "activations_defaults_hardtanh_min_val_description": "Minimaler Ausgabewert",
    "activations_defaults_hardtanh_max_val_description": "Maximaler Ausgabewert",
    "activations_defaults_hardshrink_description": "Hard Shrink Aktivierung",
    "activations_defaults_hardshrink_lambd_description": "Lambda-Schwellenwert",
    "activations_defaults_softshrink_description": "Soft Shrink Aktivierung",
    "activations_defaults_softshrink_lambd_description": "Lambda-Schwellenwert",
    "activations_defaults_threshold_description": "Threshold Aktivierung",
    "activations_defaults_threshold_threshold_description": "Schwellenwert",
    "activations_defaults_threshold_value_description": "Ersatzwert unterhalb des Schwellenwerts",
    "activations_defaults_softplus_description": "Softplus Aktivierung",
    "activations_defaults_softplus_beta_description": "Beta-Skalierungsfaktor",
    "activations_defaults_softplus_threshold_description": "Linearer Übergangsschwellenwert",
    "augmentations_description": "Datenaugmentationskonfigurationen",
    "augmentations_defaults_description": "Standard-Augmentationsparameter",
    "augmentations_properties_description": "Augmentationseigenschaften",
    "augmentations_defaults_random_crop_description": "Random Crop Augmentation",
    "augmentations_defaults_random_crop_size_description": "Ausgabe-Zuschnittgröße",
    "augmentations_defaults_random_crop_padding_description": "Padding vor dem Zuschnitt",
    "augmentations_defaults_random_crop_pad_if_needed_description": "Auffüllen, wenn kleiner als Zuschnittgröße",
    "augmentations_defaults_random_crop_fill_description": "Füllwert für Padding",
    "augmentations_defaults_random_crop_padding_mode_description": "Padding-Modus",
    "augmentations_defaults_random_resized_crop_description": "Random Resized Crop Augmentation",
    "augmentations_defaults_random_resized_crop_size_description": "Ausgabegröße",
    "augmentations_defaults_random_resized_crop_scale_description": "Skalierungsbereich (min, max)",
    "augmentations_defaults_random_resized_crop_ratio_description": "Seitenverhältnisbereich",
    "augmentations_defaults_random_resized_crop_interpolation_description": "Interpolationsmethode",
    "augmentations_defaults_center_crop_description": "Center Crop Augmentation",
    "augmentations_defaults_center_crop_size_description": "Ausgabe-Zuschnittgröße",
    "augmentations_defaults_random_horizontal_flip_description": "Zufälliges horizontales Spiegeln",
    "augmentations_defaults_random_horizontal_flip_p_description": "Spiegelwahrscheinlichkeit",
    "augmentations_defaults_random_vertical_flip_description": "Zufälliges vertikales Spiegeln",
    "augmentations_defaults_random_vertical_flip_p_description": "Spiegelwahrscheinlichkeit",
    "augmentations_defaults_random_rotation_description": "Random Rotation Augmentation",
    "augmentations_defaults_random_rotation_degrees_description": "Rotationsbereich in Grad",
    "augmentations_defaults_random_rotation_interpolation_description": "Interpolationsmethode",
    "augmentations_defaults_random_rotation_expand_description": "Erweitern, um rotiertes Bild anzupassen",
    "augmentations_defaults_random_rotation_fill_description": "Füllwert für leere Bereiche",
    "augmentations_defaults_color_jitter_description": "Color Jitter Augmentation",
    "augmentations_defaults_color_jitter_brightness_description": "Helligkeitsvariation",
    "augmentations_defaults_color_jitter_contrast_description": "Kontrastvariation",
    "augmentations_defaults_color_jitter_saturation_description": "Sättigungsvariation",
    "augmentations_defaults_color_jitter_hue_description": "Farbtonvariation",
    "augmentations_defaults_random_grayscale_description": "Zufällige Graustufenkonvertierung",
    "augmentations_defaults_random_grayscale_p_description": "Konvertierungswahrscheinlichkeit",
    "augmentations_defaults_random_erasing_description": "Random Erasing Augmentation",
    "augmentations_defaults_random_erasing_p_description": "Löschwahrscheinlichkeit",
    "augmentations_defaults_random_erasing_scale_description": "Skalierungsbereich des gelöschten Bereichs",
    "augmentations_defaults_random_erasing_ratio_description": "Seitenverhältnis des gelöschten Bereichs",
    "augmentations_defaults_random_erasing_value_description": "Füllwert für gelöschten Bereich",
    "augmentations_defaults_random_erasing_inplace_description": "In-Place löschen",
    "augmentations_defaults_normalize_description": "Normalize Augmentation",
    "augmentations_defaults_normalize_mean_description": "Mittelwerte (RGB)",
    "augmentations_defaults_normalize_std_description": "Standardabweichung (RGB)",
    "augmentations_defaults_random_invert_description": "Zufällige Farbinvertierung",
    "augmentations_defaults_random_invert_p_description": "Invertierungswahrscheinlichkeit",
    "augmentations_defaults_random_posterize_description": "Zufälliges Posterisieren",
    "augmentations_defaults_random_posterize_bits_description": "Bits pro Kanal",
    "augmentations_defaults_random_posterize_p_description": "Posterisierungswahrscheinlichkeit",
    "augmentations_defaults_random_solarize_description": "Zufälliges Solarisieren",
    "augmentations_defaults_random_solarize_threshold_description": "Solarisierungsschwellenwert",
    "augmentations_defaults_random_solarize_p_description": "Solarisierungswahrscheinlichkeit",
    "augmentations_defaults_random_adjust_sharpness_description": "Zufällige Schärfeanpassung",
    "augmentations_defaults_random_adjust_sharpness_sharpness_factor_description": "Schärfefaktor",
    "augmentations_defaults_random_adjust_sharpness_p_description": "Anpassungswahrscheinlichkeit",
    "augmentations_defaults_random_autocontrast_description": "Zufälliger Autokontrast",
    "augmentations_defaults_random_autocontrast_p_description": "Autokontrastwahrscheinlichkeit",
    "augmentations_defaults_random_equalize_description": "Zufällige Histogramm-Entzerrung",
    "augmentations_defaults_random_equalize_p_description": "Entzerrungswahrscheinlichkeit",
    "augmentations_defaults_random_perspective_description": "Zufällige Perspektiventransformation",
    "augmentations_defaults_random_perspective_distortion_scale_description": "Verzerrungsskala",
    "augmentations_defaults_random_perspective_p_description": "Transformationswahrscheinlichkeit",
    "augmentations_defaults_random_perspective_interpolation_description": "Interpolationsmethode",
    "augmentations_defaults_random_perspective_fill_description": "Füllwert für leere Bereiche",
    "regularization_description": "Regularisierungskonfigurationen",
    "regularization_defaults_description": "Standard-Regularisierungsparameter",
    "regularization_properties_description": "Regularisierungseigenschaften",
    "normalization_description": "Normalisierungsschichtkonfigurationen",
    "normalization_defaults_description": "Standard-Normalisierungsparameter",
    "normalization_properties_description": "Normalisierungseigenschaften",
    "pooling_description": "Pooling-Schichtkonfigurationen",
    "pooling_defaults_description": "Standard-Pooling-Parameter",
    "pooling_properties_description": "Pooling-Eigenschaften",
    "training_ema_title": "Modell EMA",
    "training_ema_description": "Exponential Moving Average (EMA) der Modellgewichte. Behält eine Schattenkopie des Modells mit geglätteten Gewichten bei, was oft zu besserer Generalisierung und Stabilität führt.",
    "training_ema_enabled_title": "EMA aktivieren",
    "training_ema_enabled_description": "Ob EMA-Tracking aktiviert werden soll.",
    "training_ema_decay_title": "Zerfallsrate",
    "training_ema_decay_description": "Die Zerfallsrate für den gleitenden Durchschnitt. Höhere Werte (z.B. 0,9999) bedeuten glattere Updates und längeres Gedächtnis.",
    "training_shuffle_every_epoch_title": "Jede Epoche mischen",
    "training_shuffle_every_epoch_description": "Zufällige Reihenfolge der Trainingsproben zu Beginn jeder Epoche. Dies verhindert, dass das Modell die Reihenfolge der Daten lernt, und verbessert die Generalisierung."
  },
  "presets": {
    "binary_multiclass_classification": {
      "name": "Binäre/Multi-Class-Klassifizierung",
      "description": "Klassische Single-Label-Klassifizierung für sich gegenseitig ausschließende Klassen. Funktioniert am besten, wenn jedes Bild eindeutig zu einer Kategorie gehört und du klare Entscheidungen benötigst. Passt zu alltäglichen Aufteilungen wie Katze vs. Hund, Pass/Fail-Qualitätsprüfungen oder Auswahl einer Katalogkategorie. Beginne mit ResNet oder EfficientNet für ausgewogene Genauigkeit; wechsle zu MobileNet/ShuffleNet/SqueezeNet, wenn Latenz oder Modellgröße dominieren. Gibt ein Label mit einer kalibrierten Konfidenz aus, die du als Schwellenwert verwenden oder anzeigen kannst."
    },
    "alexnet_classic_baseline": {
      "name": "AlexNet Klassische Baseline",
      "description": "Einfaches Starter-Netzwerk, das auf bescheidener Hardware schnell trainiert. Gut für schnelle Baselines, Bildung oder flache Probleme, bei denen große Tiefe unnötig ist. Handhabt saubere, niedrig aufgelöste Datensätze ohne Aufwand. Wechsle zu tieferen Backbones, wenn du feine Details, knifflige Texturen oder enge Genauigkeitsziele benötigst. Hält Experimente leichtgewichtig, wenn du Ergebnisse in Minuten möchtest."
    },
    "vgg_feature_rich": {
      "name": "VGG Feature-Rich",
      "description": "Tiefe 3x3-Faltungsstapel, die Textur- und Formdetails intakt halten. Glänzt, wenn dir visueller Reichtum wichtiger ist als Latenz oder Dateigröße. Erwarte solide Genauigkeit bei detailempfindlichen Klassen, aber langsameres Training und höhere VRAM-Nutzung. Regularisierung und Early Stopping sind wichtig, da die Parameteranzahl hoch ist. Verwende es, wenn du einfache Blöcke möchtest und langsamere Läufe tolerieren kannst. Bevorzuge Batch-Norm-Varianten für Stabilität auf realen Daten."
    },
    "densenet_compact_accuracy": {
      "name": "DenseNet Kompakte Genauigkeit",
      "description": "Feature-Sharing zwischen Schichten sorgt für starke Genauigkeit pro Parameter. Funktioniert gut für Single- oder Multi-Label-Aufgaben, wenn du kompakte Modelle ohne Detailverlust möchtest. Besser als ultraleichte Backbones auf kleinen oder attributlastigen Datensätzen bei nur moderatem Rechenaufwand. Halte Batch-Größen angemessen, um Batch-Norm stabil zu halten, insbesondere bei höheren Auflösungen. Achte auf VRAM, wenn du Eingabegröße oder Tiefe erhöhst."
    },
    "wide_resnet_balanced_depth": {
      "name": "Wide ResNet Ausgewogene Tiefe",
      "description": "Verbreiterte Residual-Blöcke fügen Kapazität hinzu, ohne das vertraute ResNet-Trainingsverhalten zu ändern. Hilft, wenn Standard-ResNet50 auf größeren oder kniffligeren Datensätzen stagniert. Liefert stetigere Gewinne als der Sprung zu sehr tiefen Varianten und bleibt dabei handhabbar abzustimmen. Benötigt mehr VRAM und Rechenleistung als einfaches ResNet50, also passe Batch-Größe oder Auflösung an, wenn du an Grenzen stößt. Ein guter Mittelweg, wenn du zusätzliche Kapazität ohne architektonische Überraschungen benötigst."
    },
    "confidence_based_classification": {
      "name": "Konfidenzbasierte Klassifizierung",
      "description": "Single-Label-Klassifizierer, abgestimmt auf zuverlässige Konfidenzscores, nicht nur Top-1-Genauigkeit. Verwende es, wenn Schwellenwerte und menschliche Überprüfungsregeln davon abhängen, dass die Wahrscheinlichkeit ehrlich ist. Bevorzuge EfficientNet oder gut regularisiertes ResNet/ResNeXt, um die Kalibrierung eng zu halten; vermeide die leichtesten Modelle für sicherheitskritische Abläufe. Kombiniere es mit Validierung, die Zuverlässigkeitskurven prüft, nicht nur Genauigkeit. Ideal für medizinische Triage, Qualitäts-Gates, Betrugsmarkierungen und jeden Workflow, bei dem 90% Konfidenz ungefähr 90% korrekt bedeuten sollte."
    },
    "content_moderation_safety": {
      "name": "Inhaltsmoderation / Sicherheit",
      "description": "Multi-Label-Sicherheits-Gate, das Richtlinienverstöße und riskante Inhalte in einem Durchgang markiert. Handhabt Inhalte für Erwachsene, Gewalt, Hasssymbole, Spam und andere Vertrauens- und Sicherheitssignale zusammen. Trainiere auf diversen, aktuellen Beispielen und halte Schwellenwerte konservativ, um Fehler zu minimieren. EfficientNet oder ResNet/ResNeXt erfassen Nuancen; MobileNet deckt Echtzeit-Scans im großen Maßstab ab. Plane menschliche Überprüfung für Grenzfälle ein und aktualisiere das Modell, wenn sich Gegner anpassen."
    },
    "document_classification": {
      "name": "Dokumenten- / Textbildklassifizierung",
      "description": "Zielt auf Dokumente, Formulare und textlastige Bilder ab, bei denen Layout und feine Kanten zählen. Klassifiziert Typen wie Rechnungen, Quittungen, Ausweise, Pässe oder Formulare, ohne vollständige OCR zu benötigen. Funktioniert mit Standard-224px-Zuschnitten für die meisten Workflows, skaliert nur hoch, wenn winziger Text die Genauigkeit bestimmt. ResNet ist eine stabile Baseline; EfficientNet hilft, wenn du schärfere Textdetails benötigst; MobileNet hält den Durchsatz für Massenaufnahme hoch. Großartig als Routing-Schritt vor OCR oder nachgelagerter Automatisierung."
    },
    "efficientnet_balanced_scaling": {
      "name": "EfficientNet-Familie - Ausgewogene Skalierung",
      "description": "Compound Scaling hält Tiefe, Breite und Auflösung synchron für effiziente Genauigkeitsgewinne. Wähle B0-B1 für ausgewogene Starts, B4-B7, wenn Genauigkeit dominiert, und V2, wenn du schnelleres Training benötigst. Zeichnet sich bei medizinischen Bildern, feinkörnigen Kategorien, wissenschaftlichen und Satellitenbildern und jedem Fall aus, bei dem kleine Details das Label entscheiden. Erfordert mehr VRAM, wenn du die Skala erklimmst, also dimensioniere Eingaben sinnvoll. Eine zuverlässige Wahl, wenn du erstklassige Genauigkeit möchtest, ohne ein Backbone von Hand abzustimmen."
    },
    "fast_mobile_inference": {
      "name": "Schnelle mobile Inferenz",
      "description": "Priorisiert Latenz, Modellgröße und Stromverbrauch gegenüber Spitzen-Genauigkeit. Gebaut für Telefone, Edge-Geräte, Browser und Batch-Jobs, die Millionen von schnellen Aufrufen benötigen. MobileNetV3 ist der Sweet Spot; ShuffleNet ist schneller; SqueezeNet gewinnt beim Platzbedarf. Erwarte 3-10x Beschleunigung gegenüber schweren Backbones und plane ein, ein paar Punkte Genauigkeit zu opfern. Perfekt, wenn Antworten unter 10ms oder winzige Binaries wichtiger sind als das letzte Prozent herauszuquetschen."
    },
    "feature_extraction_embedding": {
      "name": "Feature-Extraktion / Embedding-Lernen",
      "description": "Trainiert für Embeddings anstelle von direkten Labels, sodass ähnliche Bilder im Vektorraum nahe beieinander landen. Ideal für Suche, Deduplizierung, Empfehlungen und Abruf-Pipelines. ResNet50 ist eine bewährte Baseline; EfficientNet und ResNeXt liefern reichhaltigere, kompakte Merkmale. Exportiere Merkmale aus der vorletzten Schicht und vergleiche mit Kosinus oder L2, dann indiziere mit FAISS/Annoy für Geschwindigkeit. Liefert Vektoren fester Größe, die du über Produkte hinweg wiederverwenden kannst, ohne neu zu labeln."
    },
    "embedding_retrieval_balanced": {
      "name": "Embedding-Abruf - Ausgewogen",
      "description": "Ausgewogener Embedding-Retriever, der auf solide Recall und Präzision abzielt, ohne schwere Hardware zu benötigen. Erstellt dichte Vektoren für semantische Suche, Deduplizierung, Ähnlichkeitsbewertung und Kaltstart-Empfehlungen. Funktioniert mit moderaten Eingaben und ResNet/ResNeXt/EfficientNet-Backbones, sodass du vom Prototyp zur Produktion skalieren kannst. Verwende Kosinus- oder L2-Distanz mit FAISS/Annoy oder einer Vektordatenbank und halte Labels konsistent, auch wenn sich Klassen entwickeln. Ein sicherer Standard, wenn du wiederverwendbare Embeddings möchtest, die sich über Produktlinien hinweg vorhersehbar verhalten."
    },
    "embedding_retrieval_high_fidelity": {
      "name": "Embedding-Abruf - High Fidelity",
      "description": "Optimiert für hochdetaillierte Embeddings, wenn kleine visuelle Hinweise über eine Übereinstimmung entscheiden. Verwendet größere Eingaben und stärkere EfficientNet/ResNeXt/ResNet-Stapel, um Textur und Struktur im Vektorraum zu bewahren. Passt zum Abruf für feinkörnige Elemente, Qualitätsprüfung, Kunst- oder Medienarchive und wissenschaftliche Bildgebung. Erwarte höhere VRAM-Nutzung und längeres Training; trimme Batch-Größe, bevor du die Auflösung senkst, um das Signal zu halten. Kombiniere mit Kosinus- oder L2-Suche plus enger Validierung, um sicherzustellen, dass Vektoren über die Zeit scharf bleiben."
    },
    "finegrained_recognition": {
      "name": "Feinkörnige visuelle Erkennung",
      "description": "Konzentriert sich auf subtile Unterschiede innerhalb großer Familien ähnlicher Klassen. Größere Eingaben und tiefere Backbones erfassen die Textur-, Farb- und Formhinweise, die nahe Verwandte trennen. EfficientNet-B4+ oder ResNeXt/ResNet101+ sind sicherere Wahlen; vermeide ultraleichte Modelle, die Details glätten. Kuratiere hochwertige Labels und halte die Auflösung höher (380-528px), um Nuancen zu bewahren. Erwarte besseren Rasse-/Arten-/Varianten-Recall, wenn der Datensatz sauber und gut beleuchtet ist."
    },
    "highres_detail_preservation": {
      "name": "Hohe Auflösung / Detailerhaltung",
      "description": "Hält die Eingabeauflösung hoch, damit winzige Defekte und Texturen die Vorverarbeitung überleben. Großartig für Inspektion, Satellitenarbeit, Kunstwerkprüfungen und jeden Job, bei dem 224px die Beweise verbergen. Benötigt mehr VRAM und erfordert möglicherweise das Trimmen von Batch-Größen, um zu passen. EfficientNet-B4/B5/B6 oder detailfreundliche ResNeXt-Varianten profitieren am meisten von den zusätzlichen Pixeln. Verwende es, wenn feine Details wirklich über die Korrektheit entscheiden."
    },
    "image_quality_assessment": {
      "name": "Bildqualitätsbewertung",
      "description": "Bewertet technische und wahrgenommene Qualität statt Inhalt. Erkennt Unschärfe, Rauschen, Belichtungsprobleme und kann ästhetische Anziehungskraft für Kuration bewerten. Mittlere Eingabegrößen reichen aus; EfficientNet führt, wobei ResNet und MobileNet Durchsatzanforderungen abdecken. Nützlich für automatisches Aussortieren von Fotosets, Kameratests, Drucktauglichkeitsprüfungen oder Social-Feed-Optimierung. Gibt Qualitätsnoten oder Scores aus, die du für Behalten/Ablehnen-Pipelines als Schwellenwert verwenden kannst."
    },
    "medical_scientific_analysis": {
      "name": "Medizinische / Wissenschaftliche Bildanalyse",
      "description": "Entwickelt für Bildgebung mit hohem Einsatz, bei der Korrektheit wichtiger ist als Geschwindigkeit. Verwende konservatives Training, schwere Validierung und Überprüfung durch Fachexperten vor dem Einsatz. EfficientNet und ResNeXt erfassen komplexe Muster; ResNet bleibt ein vertrauenswürdiges Backbone. Behandle Ausgaben als Entscheidungsunterstützung mit klarer Unsicherheitsbehandlung, nicht als autonome Diagnose. Erfordert rigoroses Testen auf In-Distribution-Daten vor klinischer oder wissenschaftlicher Verwendung."
    },
    "mobilenet_edge_deployment": {
      "name": "MobileNet-Familie - Edge-Deployment",
      "description": "MobileNet V2/V3 abgestimmt auf Edge-Geräte mit tiefenweise separierbaren Faltungen und invertierten Residuals. Hervorragend für Echtzeit-Apps auf Telefonen, Tablets, Kameras, Robotern oder IoT-Boxen. Wähle V3-Small für ultraniedrige Latenz und V3-Large, wenn du etwas mehr Genauigkeit benötigst, ohne Budgets zu sprengen. Erwarte 3-5x schnellere Inferenz als ResNet50 bei etwa 75-80% seiner Genauigkeit. Ideal, wenn Batterie, thermische Grenzen und Bandbreite schwerere Modelle unpraktisch machen."
    },
    "multi_object_detection": {
      "name": "Szenenklassifizierung / Objektpräsenz",
      "description": "Szenen- und Präsenzklassifizierer auf Bildebene ohne Bounding Boxes. Beantwortet, was im Rahmen ist oder welche Art von Szene es ist, nicht wo Dinge sind. Schneller und einfacher als volle Erkennung, wenn du nur Tags wie enthaelt_auto oder innen/buero benötigst. ResNet oder EfficientNet handhaben Szenenvielfalt gut, und leichtere Backbones funktionieren immer noch für durchsatzstarke Jobs. Großartig als Vorläufer für nachgelagerte Workflows, die nur groben Kontext benötigen."
    },
    "multi_object_multi_attribute": {
      "name": "Komplexe Multi-Attribut-Analyse",
      "description": "Sagt viele Attribute auf einmal vorher, sodass ein einziger Durchgang ein reichhaltiges Eigenschaftsset liefert. Lernt Beziehungen zwischen Labels für Kataloge, Personenanalyse, Fahrzeuge, Immobilien und Mode. ResNeXt ist stark für Attributinteraktionen; EfficientNet und ResNet balancieren Kapazität und Kosten. Tiefe hilft, wenn du mit Dutzenden von Ausgaben jonglierst, also dimensioniere das Backbone nach deiner Attributanzahl. Gibt ein Wörterbuch von Attributen mit Konfidenzen zurück, die du pro Feld als Schwellenwert verwenden kannst."
    },
    "multilabel_boolean": {
      "name": "Multi-Label-Klassifizierung (Boolesche Tags)",
      "description": "Multi-Label-Setup, das einfache Ja/Nein-Tags für jedes Attribut zurückgibt. Einfach, wenn dich nur Anwesenheit oder Abwesenheit interessiert und du feste Schwellenwerte möchtest. Funktioniert über Tagging, Moderationsmarkierungen, Produkteigenschaften, Dokumenteneigenschaften oder medizinische Indikatoren hinweg. Jedes Backbone passt; wähle ResNet/EfficientNet für Genauigkeit oder das leichtere Trio für Geschwindigkeit und Größe. Produziert saubere Booleans wie hat_menschen=true, nacht=false, die einfach in Regeln einzubinden sind."
    },
    "multilabel_probability": {
      "name": "Multi-Label-Klassifizierung (Wahrscheinlichkeitsscores)",
      "description": "Multi-Label-Variante, die Wahrscheinlichkeiten für jedes Tag anstelle von harten Booleans behält. Lässt dich Schwellenwerte pro Label abstimmen oder Tags nach Relevanz ordnen. Praktisch für Empfehlungen, Emotionen, Ästhetik, Hashtags oder Multi-Attribut-Scoring im Handel. Genauigkeit und Kalibrierung verbessern sich mit ResNet/ResNeXt/EfficientNet; leichtere Modelle tauschen das gegen Geschwindigkeit. Gibt Wörterbücher von Scores aus, die du nachbearbeiten kannst, um zu deiner Produktlogik zu passen."
    },
    "resnet_deep_learning": {
      "name": "ResNet-Familie - Deep Feature Learning",
      "description": "Standard-ResNet-Familie mit Residual-Skip-Connections, die tiefes Training stabil machen. Hervorragende Balance von Genauigkeit, Geschwindigkeit und Reife mit reichlich vortrainierten Gewichten. Beginne mit ResNet50; gehe runter auf 18/34 für Latenzbudgets oder klettere auf 101/152, wenn Genauigkeit regiert. Passt gleichermaßen zu allgemeiner Klassifizierung, Transfer-Learning, Vision-Suche, Inspektion und medizinischer Bildgebung. Eine zuverlässige Baseline, wenn du vorhersehbares Verhalten und breite Community-Unterstützung möchtest."
    },
    "resnext_aggregated_networks": {
      "name": "ResNeXt-Familie - Aggregierte Residual-Netzwerke",
      "description": "ResNeXt fügt dem ResNet-Rezept gruppierte Faltungen und Kardinalität für reichhaltigere Merkmale hinzu. Liefert einen kleinen Genauigkeitsschub gegenüber äquivalenten ResNets bei ähnlichem Rechenaufwand. Großartig für feinkörnige, Multi-Attribut-, Mode-, Fahrzeug-, Lebensmittel- oder texturlastige Aufgaben. Verwende 32x4d für die beste Balance; größere Kardinalitäten treiben die Genauigkeit weiter, wenn du dir die Kosten leisten kannst. Wähle es, wenn einfaches ResNet abflacht, du aber vertraute Trainingsdynamik möchtest."
    },
    "shufflenet_lightweight_speed": {
      "name": "ShuffleNet - Leichtgewichts-Geschwindigkeitsmeister",
      "description": "ShuffleNet V2 konzentriert sich auf Channel-Shuffle-Effizienz, um Latenz auf CPUs und kleinen GPUs zu minimieren. Ideal für Robotik, Wearables, Smart-Kameras und jeden Edge-Job mit strengen Budgets. Varianten von x0.5 bis x2.0 lassen dich Kapazität wählen, ohne Geschwindigkeit zu verlieren. Erwarte rasante Inferenz, aber schwächere Feindetailgenauigkeit, also vermeide es für Aufgaben mit hohem Einsatz oder vielen Nuancen. Kombiniere mit starker Augmentation und Early Stopping auf winzigen Datensätzen.",
      "configs": {
        "tiny": "Sehr kleine Datensätze (50-500 Bilder). Starke Regularisierung, aggressive Augmentation, kleinste ShuffleNet-Variante. Hohes Risiko von Overfitting - Early Stopping unerlässlich.",
        "large": "Große Datensätze (10k-30k Bilder). Reduzierte Regularisierung, größere ShuffleNet-Varianten machbar. Höhere Lernraten und größere Batches effektiv.",
        "huge": "Riesige Datensätze (30k-50k Bilder). Minimale Regularisierung erforderlich. Größere ShuffleNet-Varianten trainieren effektiv.",
        "massive": "Massive Datensätze (50k-100k Bilder). Schnelle Lernraten, große Batches, minimale Regularisierung. ShuffleNet x1.5 oder x2.0 empfohlen.",
        "giant": "Gigantische Datensätze (100k+ Bilder). Maximale ShuffleNet-Kapazität (x2.0). Kann von Grund auf trainieren oder mit aggressiven Einstellungen feinabstimmen."
      }
    },
    "small_dataset_fewshot": {
      "name": "Kleiner Datensatz / Few-Shot Learning",
      "description": "Abgestimmt auf knappe Daten, gestützt auf vortrainierte Gewichte, Regularisierung und sorgfältige Zeitpläne. Großartig für Prototypen, seltene Klassen, Nischen-Unternehmenssets oder Produkte im Frühstadium. ResNet18/34 und EfficientNet-B0/B1 sind sichere Wetten; MobileNetV3-Small hilft, wenn Geschwindigkeit zählt. Halte Augmentation stark und überwache Overfitting genau, da die Varianz hoch ist. Ziele zuerst auf angemessene Genauigkeit ab, sammle dann mehr Daten, um höher zu klettern."
    },
    "squeezenet_ultra_compact": {
      "name": "SqueezeNet - Ultra-Kompakte Netzwerke",
      "description": "Extrem kompaktes Fire-Module-Netzwerk für Umgebungen, in denen jedes Megabyte zählt. Tauscht Genauigkeit gegen winzige Modelle, die auf Mikrocontrollern, FPGAs und Geräten mit begrenzter Bandbreite laufen. Gut, wenn du unter engen Speicher- oder Stromobergrenzen bleiben musst und trotzdem grundlegende Vision benötigst. Regularisierung und Early Stopping sind wichtig, da die Kapazität begrenzt ist. Passt nicht für komplexe Aufgaben oder sehr große Datensätze – erwäge größere Backbones, wenn Genauigkeit zählt.",
      "configs": {
        "tiny": "Sehr kleine Datensätze (50-500 Bilder). Starke Regularisierung unerlässlich für diese bereits kompakte Architektur. Early Stopping kritisch, um Overfitting zu verhindern.",
        "small": "Kleine Datensätze (500-2,5k Bilder). Moderate Regularisierung mit vortrainierten Fire-Modulen. SqueezeNet lernt effizient aus begrenzten Daten.",
        "medium": "Mittlere Datensätze (2,5k-10k Bilder). Standard-Hyperparameter funktionieren gut. SqueezeNets kompakte Größe ermöglicht größere Batch-Größen.",
        "large": "Große Datensätze (10k-30k Bilder). Reduzierte Regularisierung. SqueezeNet 1.0 kann für etwas mehr Kapazität verwendet werden.",
        "huge": "Riesige Datensätze (30k-50k Bilder). Minimale Regularisierung. SqueezeNet erreicht hier seine Kapazitätsgrenzen - erwäge größere Architekturen für bessere Genauigkeit.",
        "massive": "Massive Datensätze (50k-100k Bilder). SqueezeNet könnte underfitten - diese Voreinstellung treibt die Architektur an ihre Grenzen. Erwäge EfficientNet für bessere Ergebnisse.",
        "giant": "Gigantische Datensätze (100k+ Bilder). SqueezeNet wird für Datensätze dieser Größe NICHT empfohlen - begrenzte Kapazität führt zu Underfitting. Nur verwenden, wenn Modellgröße absolut kritisch ist."
      }
    },
    "style_aesthetic_classification": {
      "name": "Stil- / Ästhetik-Klassifizierung",
      "description": "Klassifiziert Stil, Stimmung und ästhetische Qualitäten anstelle von konkreten Objekten. Schaut auf Palette, Komposition und Textur, um zu entscheiden, wie sich ein Bild anfühlt oder zu welchem Stil es passt. Nützlich für Kuration, Empfehlungen, Fotoqualitätssortierung, Kunststil-Tagging oder Interieur-/Mode-Stilerkennung. EfficientNet und ResNeXt erfassen globale Muster gut, mit ResNet als solidem Fallback. Gibt Stil-Labels oder Qualitäts-Scores aus, die du in kreative Workflows einspeisen kannst."
    },
    "configs": {
      "tiny": "Sehr kleine Datensätze (50-500 Bilder). Starke Regularisierung, aggressive Augmentation, kleinere Modelle. Hohes Risiko von Overfitting - Early Stopping unerlässlich.",
      "small": "Kleine Datensätze (500-2,5k Bilder). Moderate Regularisierung mit vortrainierten Gewichten. Balance zwischen Lernkapazität und Overfitting-Prävention.",
      "medium": "Mittlere Datensätze (2,5k-10k Bilder). Standard-Hyperparameter mit guter Augmentation. Ausgewogener Trainingsansatz funktioniert gut.",
      "large": "Große Datensätze (10k-30k Bilder). Reduzierte Regularisierung, größere Modelle machbar. Höhere Lernraten und größere Batches effektiv.",
      "huge": "Riesige Datensätze (30k-50k Bilder). Minimale Regularisierung erforderlich. Tiefe Netzwerke trainieren effektiv mit Standard-Augmentation.",
      "massive": "Massive Datensätze (50k-100k Bilder). Sehr tiefe Netzwerke voll unterstützt. Schnelle Lernraten, große Batches, minimale Regularisierung.",
      "giant": "Gigantische Datensätze (100k+ Bilder). Maximale Modellkapazität genutzt. Kann von Grund auf trainieren oder mit aggressiven Einstellungen feinabstimmen."
    }
  }
}
