{
  "language_name": "Français",
  "activations": {
    "not_supported": "Activation non prise en charge : {activation}. Options disponibles : {available}",
    "created": "Fonction d'activation créée avec succès : {activation} avec les paramètres {params}",
    "creation_failed": "Échec de la création de la fonction d'activation : {error}",
    "invalid_params": "Paramètres invalides pour la fonction d'activation : {error}",
    "config_missing_type": "Champ 'type' manquant dans la configuration d'activation",
    "recommendations_removed": "Les recommandations d'activation ont été retirées du système"
  },
  "augmentation": {
    "not_supported": "Augmentation non prise en charge : {aug}. Options disponibles : {available}",
    "created": "Augmentation créée avec succès : {aug} avec les paramètres {params}",
    "creation_failed": "Échec de la création de l'augmentation : {error}",
    "invalid_params": "Paramètres invalides pour l'augmentation : {error}",
    "config_missing_type": "Champ 'type' manquant dans la configuration d'augmentation",
    "preview_invalid_phase": "Phase d'augmentation invalide : {phase}",
    "preview_no_images": "Aucune image du projet {project} n'est disponible pour la prévisualisation d'augmentation.",
    "preview_failed": "Échec de la génération de la prévisualisation d'augmentation : {error}",
    "preview_generated": "Prévisualisation d'augmentation générée pour la phase {phase}"
  },
  "coordinator_settings": {
    "user_settings_saved": "Paramètres utilisateur enregistrés dans {path}",
    "user_settings_save_failed": "Échec de l'enregistrement des paramètres utilisateur : {error}"
  },
  "recommendations": {
    "critical_shortage": "Pénurie critique de données détectée dans : {labels}",
    "reduce_oversampled": "Pense à réduire les labels suréchantillonnés : {labels}",
    "augment_undersampled": "Pense à augmenter les labels sous-échantillonnés : {labels}",
    "weighted_loss": "Pense à utiliser des fonctions de perte pondérées",
    "stratified_sampling": "Pense à utiliser un échantillonnage stratifié",
    "hierarchical_imbalance": "Déséquilibre hiérarchique détecté dans : {categories}",
    "small_dataset": "Jeu de données réduit détecté – songe à faire de l'augmentation",
    "tiny_dataset": "Jeu de données très réduit – risque élevé de surapprentissage"
  },
  "losses": {
    "not_supported": "Fonction de perte non prise en charge : {loss}. Options disponibles : {available}",
    "created": "Fonction de perte créée avec succès : {loss} avec les paramètres {params}",
    "creation_failed": "Échec de la création de la fonction de perte : {error}",
    "invalid_params": "Paramètres invalides pour la fonction de perte : {error}",
    "config_missing_type": "Champ 'type' manquant dans la configuration de perte",
    "recommendations_removed": "Les recommandations de pertes ont été retirées du système"
  },
  "normalization": {
    "not_supported": "Normalisation non prise en charge : {norm}. Options disponibles : {available}",
    "missing_num_features": "Paramètre 'num_features' manquant pour {norm}",
    "missing_num_channels": "Paramètre 'num_channels' manquant pour {norm}",
    "missing_normalized_shape": "Paramètre 'normalized_shape' manquant pour {norm}",
    "created": "Couche de normalisation créée avec succès : {norm} avec les paramètres {params}",
    "creation_failed": "Échec de la création de la couche de normalisation : {error}",
    "invalid_params": "Paramètres invalides pour la couche de normalisation : {error}",
    "config_missing_type": "Champ 'type' manquant dans la configuration de normalisation",
    "recommendations_removed": "Les recommandations de normalisation ont été retirées du système"
  },
  "optimizers": {
    "not_supported": "Optimiseur non pris en charge : {optimizer}. Options disponibles : {available}",
    "created": "Optimiseur créé avec succès : {optimizer} avec les paramètres {params}",
    "creation_failed": "Échec de la création de l'optimiseur : {error}",
    "invalid_params": "Paramètres invalides pour l'optimiseur : {error}",
    "config_missing_type": "Champ 'type' manquant dans la configuration de l'optimiseur",
    "recommendations_removed": "Les recommandations d'optimiseur ont été retirées du système"
  },
  "pooling": {
    "not_supported": "Couche de pooling non prise en charge : {pool}. Options disponibles : {available}",
    "created": "Couche de pooling créée avec succès : {pool} avec les paramètres {params}",
    "creation_failed": "Échec de la création de la couche de pooling : {error}",
    "invalid_params": "Paramètres invalides pour la couche de pooling : {error}",
    "config_missing_type": "Champ 'type' manquant dans la configuration de pooling",
    "recommendations_removed": "Les recommandations de pooling ont été retirées du système"
  },
  "regularization": {
    "not_supported": "Régularisation non prise en charge : {reg}. Options disponibles : {available}",
    "created": "Couche de régularisation créée avec succès : {reg} avec les paramètres {params}",
    "creation_failed": "Échec de la création de la couche de régularisation : {error}",
    "invalid_params": "Paramètres invalides pour la couche de régularisation : {error}",
    "config_missing_type": "Champ 'type' manquant dans la configuration de régularisation",
    "recommendations_removed": "Les recommandations de régularisation ont été retirées du système"
  },
  "schedulers": {
    "not_supported": "Scheduler non pris en charge : {scheduler}. Options disponibles : {available}",
    "created": "Scheduler créé avec succès : {scheduler} avec les paramètres {params}",
    "creation_failed": "Échec de la création du scheduler : {error}",
    "invalid_params": "Paramètres invalides pour le scheduler : {error}",
    "config_missing_type": "Champ 'type' manquant dans la configuration du scheduler",
    "recommendations_removed": "Les recommandations de scheduler ont été retirées du système"
  },
  "weight_init": {
    "not_supported": "Initialisation de poids non prise en charge : {init}. Options disponibles : {available}",
    "applied": "Initialisation appliquée avec succès : {init} sur {module} avec les paramètres {params}",
    "application_failed": "Échec de l'application de l'initialisation des poids : {error}",
    "invalid_params": "Paramètres invalides pour l'initialisation des poids : {error}",
    "recommendations_removed": "Les recommandations d'initialisation des poids ont été retirées du système"
  },
  "heatmap": {
    "no_images": "Aucune image trouvée pour le projet {project}",
    "checkpoint_missing": "Checkpoint de modèle introuvable dans le dossier : {dir}",
    "project_or_dataset_missing": "Projet {project} ou dataset introuvable",
    "generated": "Heatmap générée pour {project} avec l'image {image} (classe {clazz})"
  },
  "app": {
    "brand": "Hootsight"
  },
  "nav": {
    "training_group": "Entraînement",
    "projects": "Projets",
    "dataset": "Jeu de données",
    "training_setup": "Préparation",
    "augmentation": "Augmentation",
    "status_group": "Statut",
    "status": "Statut",
    "heatmap": "Heatmap",
    "memory": "Mémoire",
    "system_group": "Système",
    "updates": "Mises à jour",
    "about": "À propos"
  },
  "page": {
    "projects": "Projets",
    "dataset": "Jeu de données",
    "training": "Préparation",
    "augmentation": "Augmentation",
    "status": "Statut",
    "heatmap": "Heatmap",
    "memory": "Mémoire",
    "updates": "Mises à jour",
    "about": "À propos"
  },
  "config": {
    "sections": {
      "training": "Entraînement",
      "optimizers": "Optimiseurs",
      "schedulers": "Schedulers",
      "losses": "Pertes",
      "models": "Modèles"
    },
    "entities": {
      "optimizers": {
        "sgd": "SGD (Stochastic Gradient Descent)",
        "adam": "Adam Optimizer",
        "adamw": "AdamW Optimizer",
        "adamax": "AdaMax Optimizer",
        "nadam": "Nesterov Adam",
        "radam": "Rectified Adam",
        "rmsprop": "RMSprop Optimizer",
        "rprop": "Resilient Backpropagation",
        "adagrad": "AdaGrad Optimizer",
        "adadelta": "AdaDelta Optimizer",
        "sparse_adam": "Sparse Adam",
        "lbfgs": "L-BFGS Optimizer",
        "asgd": "Averaged SGD"
      },
      "schedulers": {
        "step_lr": "Step Learning Rate",
        "multi_step_lr": "Multi-Step Learning Rate",
        "exponential_lr": "Exponential Learning Rate",
        "cosine_annealing_lr": "Cosine Annealing",
        "cosine_annealing_warm_restarts": "Cosine Annealing with Warm Restarts",
        "reduce_lr_on_plateau": "Reduce LR on Plateau",
        "cyclic_lr": "Cyclic Learning Rate",
        "one_cycle_lr": "One Cycle Learning Rate",
        "polynomial_lr": "Polynomial Learning Rate",
        "linear_lr": "Linear Learning Rate",
        "lambda_lr": "Lambda Learning Rate",
        "multiplicative_lr": "Multiplicative Learning Rate"
      },
      "losses": {
        "cross_entropy": "Cross-Entropy Loss",
        "nll_loss": "Negative Log-Likelihood",
        "bce_loss": "Binary Cross-Entropy",
        "bce_with_logits": "BCE with Logits",
        "multi_margin": "Multi-Class Margin Loss",
        "multi_label_margin": "Multi-Label Margin Loss",
        "multi_label_soft_margin": "Multi-Label Soft Margin",
        "mse_loss": "Mean Squared Error",
        "l1_loss": "L1 Loss (MAE)",
        "smooth_l1": "Smooth L1 Loss",
        "huber_loss": "Huber Loss",
        "kl_div": "KL Divergence",
        "margin_ranking": "Margin Ranking Loss",
        "hinge_embedding": "Hinge Embedding Loss",
        "triplet_margin": "Triplet Margin Loss",
        "cosine_embedding": "Cosine Embedding Loss",
        "ctc_loss": "CTC Loss",
        "poisson_nll": "Poisson NLL Loss",
        "gaussian_nll": "Gaussian NLL Loss"
      }
    }
  },
  "groups": {
    "model_settings": "Paramètres du modèle",
    "task_configuration": "Configuration de la tâche",
    "training_parameters": "Paramètres d'entraînement",
    "optimizer_settings": "Paramètres de l'optimiseur",
    "scheduler_settings": "Paramètres du scheduler",
    "loss_configuration": "Configuration de la perte",
    "data_loading": "Chargement des données",
    "normalization": "Normalisation",
    "checkpointing": "Checkpoints",
    "weight_initialization": "Initialisation des poids"
  },
  "actions": {
    "save_config": "Enregistrer la config",
    "export": "Exporter",
    "save_training_config": "Enregistrer la config d'entraînement",
    "save_system_settings": "Enregistrer les paramètres globaux"
  },
  "footer": {
    "tagline": "Piloté par la configuration",
    "generated": "",
    "ready": "Prêt"
  },
  "field": {
    "training_model_type": "Type de modèle",
    "training_model_name": "Nom du modèle",
    "training_pretrained": "Pré-entraîné",
    "training_task": "Tâche",
    "training_batch_size": "Taille de batch",
    "training_epochs": "Époques",
    "training_learning_rate": "Taux d'apprentissage",
    "training_weight_decay": "Weight Decay",
    "training_input_size": "Taille d'entrée",
    "training_val_ratio": "Ratio validation",
    "training_optimizer_type": "Type d'optimiseur",
    "training_scheduler_type": "Type de scheduler",
    "training_loss_type": "Type de perte",
    "training_dataloader": "DataLoader",
    "training_dataloader_num_workers": "Nombre de workers",
    "training_dataloader_pin_memory": "Pin Memory",
    "training_dataloader_persistent_workers": "Workers persistants",
    "training_dataloader_prefetch_factor": "Facteur de préchargement",
    "training_normalize": "Normaliser",
    "training_normalize_mean": "Moyenne",
    "training_normalize_std": "Écart-type",
    "training_checkpoint": "Checkpoint",
    "training_checkpoint_save_best_only": "Sauvegarder seulement le meilleur",
    "training_checkpoint_save_frequency": "Fréquence de sauvegarde",
    "training_checkpoint_max_checkpoints": "Max checkpoints",
    "training_checkpoint_checkpoint_dir": "Dossier de checkpoints",
    "training_checkpoint_best_model_filename": "Nom du meilleur modèle",
    "training_checkpoint_training_history_filename": "Nom de l'historique",
    "training_weight_init": "Init des poids",
    "training_weight_init_type": "Type d'init",
    "training_weight_init_params": "Paramètres d'init",
    "training_optimizer_params_adamw_lr": "Taux d'apprentissage",
    "training_optimizer_params_adamw_betas": "Bêtas",
    "training_optimizer_params_adamw_eps": "Eps",
    "training_optimizer_params_adamw_weight_decay": "Weight Decay",
    "training_optimizer_params_adamw_amsgrad": "Amsgrad",
    "training_scheduler_params_step_lr_step_size": "Taille d'étape",
    "training_scheduler_params_step_lr_gamma": "Gamma",
    "training_scheduler_params_step_lr_last_epoch": "Dernière époque",
    "training_loss_params_bce_with_logits_weight": "Poids",
    "training_loss_params_bce_with_logits_size_average": "Moyenne",
    "training_loss_params_bce_with_logits_reduce": "Réduire",
    "training_loss_params_bce_with_logits_reduction": "Réduction",
    "training_loss_params_bce_with_logits_pos_weight": "Poids positif"
  },
  "ui": {
    "generate_heatmap": "Générer la heatmap",
    "no_heatmap_generated": "Aucune heatmap générée pour le moment.",
    "no_data_available": "Aucune donnée disponible.",
    "page_not_implemented": "Page non implémentée",
    "error": "Erreur",
    "schema_not_loaded": "Le schéma n'est pas encore chargé. Patiente...",
    "config_not_loaded": "La configuration n'est pas encore chargée. Patiente...",
    "augmentation_phase": "Augmentation {phase}",
    "add": "Ajouter",
    "remove": "Retirer",
    "transform": "transformer",
    "no_project_loaded": "Aucun projet chargé",
    "load_project_first": "Charge d'abord un projet depuis l'onglet Projets.",
    "go_to_projects": "Ouvre les Projets",
    "dataset_overview": "Aperçu du dataset",
    "balance_analysis": "Analyse d'équilibre",
    "label_distribution": "Distribution des labels (Top 20)",
    "recommendations": "Recommandations",
    "failed_to_load_dataset": "Impossible de charger les informations du dataset.",
    "current_project": "PROJET ACTUEL",
    "load": "Charger",
    "start_training": "Lance l'entraînement",
    "stop_training": "Arrête l'entraînement",
    "stop_training_disabled": "Aucun entraînement actif pour ce projet.",
    "training_in_progress": "Entraînement en cours",
    "memory": "Mémoire",
    "loading": "Chargement...",
    "training_status": "Statut d'entraînement",
    "idle": "Au repos",
    "prediction": "Prédiction",
    "predictions": "Prédictions",
    "no_predictions_above_threshold": "Aucune prédiction au-dessus du seuil",
    "image": "Image",
    "checkpoint": "Checkpoint",
    "auto": "auto",
    "value": "valeur",
    "one_number_per_line": "Un nombre par ligne",
    "empty_object": "Objet vide",
    "language_warning": "Changer la langue recharge le système",
    "language_select_title": "Choisis une langue",
    "not_available": "N/A",
    "unknown": "Inconnu",
    "configuration_empty": "Aucune section de configuration disponible",
    "configuration_schema_missing": "Le schéma de configuration n'est pas encore chargé."
  },
  "augmentation_ui": {
    "page_title": "Augmentation de données",
    "page_description": "Configure des transformations d'images pour améliorer la généralisation et la robustesse du modèle.",
    "train_title": "Augmentations d'entraînement",
    "train_description": "Appliquées pendant l'entraînement pour augmenter la diversité visuelle tout en conservant les labels.",
    "val_title": "Augmentations de validation",
    "val_description": "Appliquées pendant la validation pour garder une évaluation déterministe.",
    "toggle_help": "Active ou désactive une augmentation pour cette phase.",
    "no_options": "Aucune option d'augmentation disponible.",
    "custom_warning": "Les transformations suivantes sont conservées mais ne peuvent pas être éditées ici :",
    "unknown_transform": "Transformation inconnue",
    "random_resized_crop": "Random Resized Crop",
    "random_resized_crop_description": "Recadre et redimensionne aléatoirement l'image à la taille cible tout en respectant l'échelle et le ratio.",
    "random_horizontal_flip": "Random Horizontal Flip",
    "random_horizontal_flip_description": "Retourne l'image horizontalement avec la probabilité configurée pour couvrir les variations gauche/droite.",
    "random_vertical_flip": "Random Vertical Flip",
    "random_vertical_flip_description": "Retourne l'image verticalement pour exposer le modèle aux changements haut/bas.",
    "random_rotation": "Random Rotation",
    "random_rotation_description": "Applique une rotation aléatoire dans l'intervalle défini pour réduire le biais d'orientation.",
    "color_jitter": "Color Jitter",
    "color_jitter_description": "Fait varier aléatoirement la luminosité, le contraste, la saturation et la teinte pour améliorer la robustesse aux couleurs.",
    "random_grayscale": "Random Grayscale",
    "random_grayscale_description": "Convertit les images en niveaux de gris selon la probabilité configurée pour améliorer la perception de luminance.",
    "random_erasing": "Random Erasing",
    "random_erasing_description": "Masque aléatoirement des régions rectangulaires pour encourager la robustesse spatiale et la complétude des objets.",
    "random_perspective": "Random Perspective",
    "random_perspective_description": "Applique une transformation de perspective aléatoire avec la distorsion et la probabilité configurées.",
    "center_crop": "Center Crop",
    "center_crop_description": "Recadre la zone centrale à la taille cible pour une validation cohérente.",
    "random_resized_crop.size_label": "Taille de sortie",
    "random_resized_crop.size_description": "Longueur de bord finale en pixels après redimensionnement.",
    "random_resized_crop.scale_min_label": "Échelle minimale",
    "random_resized_crop.scale_min_description": "Borne inférieure pour l'échelle de surface aléatoire par rapport à l'image originale (0-1).",
    "random_resized_crop.scale_max_label": "Échelle maximale",
    "random_resized_crop.scale_max_description": "Borne supérieure pour l'échelle de surface aléatoire par rapport à l'image originale.",
    "random_resized_crop.ratio_min_label": "Ratio minimal",
    "random_resized_crop.ratio_min_description": "Borne inférieure du ratio avant redimensionnement.",
    "random_resized_crop.ratio_max_label": "Ratio maximal",
    "random_resized_crop.ratio_max_description": "Borne supérieure du ratio avant redimensionnement.",
    "random_horizontal_flip.p_label": "Probabilité de flip",
    "random_horizontal_flip.p_description": "Chance qu'une image soit miroirée horizontalement.",
    "random_vertical_flip.p_label": "Probabilité de flip",
    "random_vertical_flip.p_description": "Chance qu'une image soit retournée verticalement.",
    "random_rotation.min_label": "Degrés minimum",
    "random_rotation.min_description": "Borne inférieure en degrés (valeurs négatives = rotation horaire).",
    "random_rotation.max_label": "Degrés maximum",
    "random_rotation.max_description": "Borne supérieure en degrés (valeurs positives = rotation antihoraire).",
    "color_jitter.brightness_label": "Variation de luminosité",
    "color_jitter.brightness_description": "Écart maximal appliqué à chaque canal.",
    "color_jitter.contrast_label": "Variation de contraste",
    "color_jitter.contrast_description": "Mise à l'échelle maximale du contraste appliquée à l'image.",
    "color_jitter.saturation_label": "Variation de saturation",
    "color_jitter.saturation_description": "Variation maximale de saturation appliquée en HSV.",
    "color_jitter.hue_label": "Variation de teinte",
    "color_jitter.hue_description": "Amplitude maximale du décalage de teinte (0-0,5).",
    "random_grayscale.p_label": "Probabilité de niveaux de gris",
    "random_grayscale.p_description": "Chance qu'une image soit convertie en niveaux de gris.",
    "random_erasing.p_label": "Probabilité d'effacement",
    "random_erasing.p_description": "Chance qu'une zone aléatoire soit masquée par image.",
    "random_erasing.scale_min_label": "Échelle minimale",
    "random_erasing.scale_min_description": "Borne inférieure de la zone effacée par rapport à l'image entière.",
    "random_erasing.scale_max_label": "Échelle maximale",
    "random_erasing.scale_max_description": "Borne supérieure de la zone effacée par rapport à l'image entière.",
    "random_erasing.ratio_min_label": "Ratio minimum",
    "random_erasing.ratio_min_description": "Borne inférieure du ratio du patch effacé.",
    "random_erasing.ratio_max_label": "Ratio maximum",
    "random_erasing.ratio_max_description": "Borne supérieure du ratio du patch effacé.",
    "random_erasing.value_label": "Valeur de remplissage",
    "random_erasing.value_description": "Valeur de pixel utilisée pour remplir la zone effacée (0-1).",
    "random_erasing.inplace_label": "In-place",
    "random_erasing.inplace_description": "Applique l'effacement directement sur le tenseur d'entrée sans copie.",
    "random_perspective.distortion_scale_label": "Échelle de distorsion",
    "random_perspective.distortion_scale_description": "Contrôle la force de la distorsion de perspective (0-1).",
    "random_perspective.p_label": "Probabilité de perspective",
    "random_perspective.p_description": "Chance qu'un warp de perspective aléatoire soit appliqué.",
    "center_crop.size_label": "Taille du recadrage",
    "center_crop.size_description": "Longueur de bord cible en pixels pour le recadrage centré.",
    "preview_section_title": "Prévisualisation",
    "preview_description": "Applique le pipeline actuel à une image aléatoire du dataset.",
    "preview_button": "Lance la prévisualisation",
    "preview_idle": "Clique sur Lance la prévisualisation pour voir l'image augmentée.",
    "preview_loading": "Génération de la prévisualisation...",
    "preview_no_project": "Charge un projet pour prévisualiser les augmentations.",
    "preview_empty_pipeline": "Configure au moins une transformation pour prévisualiser.",
    "preview_generic_error": "Échec de la prévisualisation.",
    "preview_original_label": "Original",
    "preview_augmented_label": "Augmentée",
    "preview_image_path_label": "Chemin de l'image"
  },
  "about_ui": {
    "page_title": "À propos de Hootsight",
    "page_description": "Comprends la mission, l'architecture centrale et les principes de développement qui façonnent Hootsight.",
    "card_title": "Boîte à outils d'augmentation d'images pour un entraînement offline-first",
    "intro": "Hootsight est une boîte à outils de classification d'images offline-first qui associe un entraînement PyTorch à un backend FastAPI et une interface pilotée par la configuration.",
    "content_markdown": "## À propos de Hootsight\n\nSalut, je suis Tanathy ! La développeuse solo qui garde Hootsight en état. Je l'ai construit parce que je voulais une boîte à outils de classification d'images fiable, offline-first, utilisable sur mon propre matériel, et je me suis dit que d'autres méritaient cette même liberté.\n\n### Philosophie\n- Tes données ne quittent jamais ta machine à moins que tu ne les déplaces toi-même. Pas de synchro en arrière-plan, pas d'appels cloud surprises.\n- Je refuse d'intégrer de la télémétrie ou des hooks de suivi. Les diagnostics restent locaux, et c'est toi qui choisis ce que tu partages.\n- Chaque réglage vit dans du JSON. Versionne-le, diff-le, balance-le sur Git — choisis ce qui garde ton flux de travail honnête.\n- L'installateur configure un environnement virtuel isolé pour garder ton Python global propre.\n- Les poids pré-entraînés vivent dans `cache/`, tu peux les sauvegarder, les auditer ou les supprimer en quelques secondes.\n- La roadmap suit la vraie vie. Les releases arrivent quand j'ai du temps, pas parce qu'un tableau de sprint l'exige.\n- Les outils sont neutres ; leur impact dépend de toi. Je m'attends à ce que tout le monde, moi comprise, les manipule avec soin.\n\n>Disclaimer : Chaque dataset que tu ingères, chaque label que tu prédis et chaque modèle que tu exportes est sous ta responsabilité. Pense au consentement, à la légalité et aux personnes impactées par ton travail.\n\n### État du développement\n- Hootsight est clairement en alpha. Attends-toi à des mises à jour, des expérimentations et quelques aspérités.\n- ResNet est validé de bout en bout. ResNeXt, EfficientNet et les autres architectures passent encore par des tests de longue durée quand j'ai du temps.\n- Tu as trouvé un bug ? Ouvre un ticket sur [GitHub Issues](https://github.com/Tanathy/HootSight/issues). Des rapports clairs m'aident à corriger plus vite.\n\n### Fondations techniques\n- **Backend** : des services FastAPI coordonnent la découverte du dataset, l'orchestration de l'entraînement et les endpoints de statut.\n- **Noyau ML** : PyTorch gère les boucles d'entraînement, l'inférence et les pipelines d'augmentation.\n- **Frontend** : une interface HTML/JS/CSS légère propulsée par une petite librairie (`qte.js`) au lieu d'un framework lourd.\n- **Configuration** : tout est piloté par la configuration — pas de valeurs par défaut cachées dans le code.\n- **Fonctionnement hors ligne** : l'app fonctionne sans connexion internet. Les vérifications de mise à jour sont optionnelles et ne contactent GitHub que quand tu le demandes.\n- **Gestion mémoire** : des utilitaires sur mesure règlent la taille des batchs et surveillent l'utilisation GPU/CPU pour éviter les crashs out-of-memory.\n- **Gestion des données** : Projets, datasets, checkpoints et logs restent sous ton contrôle sur le système de fichiers. Pas de synchro automatique ni de miroirs distants.\n\n### Vie privée & conformité\n- Conçu avec les attentes RGPD en tête : aucune donnée perso ne quitte ton environnement par défaut.\n- Tu décides de ce que tu importes, edits, exportes ou supprimes.\n- Configurations, logs et checkpoints restent sur disque tant que tu ne les partages pas consciemment.\n- Les vérifications de mise à jour sont opt-in et n'envoient que des métadonnées de requête ; le contenu du projet ne part jamais avec.\n- Si tu manipules des catégories sensibles (biométrie, médical, données réglementées), aligne-toi sur tes obligations avant d'entraîner.\n- Aucun SDK d'analytics, crash reporter ou tracker tiers n'est embarqué dans l'app.\n\n### Support\nJe suis ravie de partager ce projet pour que tu en profites librement. Si tu veux soutenir mon travail, tu peux m'offrir un café sur [ko-fi.com/tanathy](https://ko-fi.com/tanathy).\n\n### Licence & crédits\nHootsight inclut la police [Roboto](https://fonts.google.com/specimen/Roboto/license), distribuée sous la SIL Open Font License, Version 1.1."
  },
  "training_ui": {
    "page_title": "Préparation de l'entraînement",
    "page_description": "Configure l'architecture du modèle, les paramètres d'entraînement et les réglages d'optimisation.",
    "optimizer_params_title": "Paramètres de l'optimiseur",
    "scheduler_params_title": "Paramètres du scheduler",
    "loss_params_title": "Paramètres de la perte",
    "select_type_first": "Choisis d'abord un type pour voir les paramètres.",
    "no_extra_params": "Pas de paramètres supplémentaires pour ce choix."
  },
  "dataset_ui": {
    "page_title": "Jeu de données",
    "page_description": "Explore et analyse la structure de ton dataset, ses labels et la distribution des données.",
    "summary": {
      "project": "Projet",
      "dataset_type": "Type de dataset",
      "total_images": "Total d'images",
      "total_labels": "Total de labels",
      "balance_status": "Statut d'équilibre",
      "balance_score": "Score d'équilibre",
      "images_per_label_ideal": "Images par label (idéal)",
      "min_images": "Images min",
      "max_images": "Images max",
      "max_min_ratio": "Ratio Max/Min"
    },
    "table": {
      "label": "Label",
      "count": "Compte",
      "percentage": "Pourcentage"
    }
  },
  "projects_ui": {
    "page_title": "Projets",
    "page_description": "Gère et bascule entre différents projets et datasets de machine learning.",
    "card": {
      "images": "Images",
      "labels": "Labels",
      "balance_score": "Score d'équilibre",
      "balance_status": "Équilibre",
      "dataset_type": "Type de dataset",
      "status": {
        "balanced": "Équilibré",
        "imbalanced": "Déséquilibré",
        "critical": "Critique",
        "warning": "Avertissement",
        "good": "Bon",
        "poor": "Faible",
        "excellent": "Excellent",
        "fair": "Correct",
        "ok": "OK",
        "unstable": "Instable"
      }
    }
  },
  "status_ui": {
    "page_title": "Statut",
    "page_description": "Suis la progression de l'entraînement, l'état du système et les métriques en temps réel."
  },
  "heatmap_ui": {
    "page_title": "Heatmap",
    "page_description": "Génère et visualise les cartes d'attention du modèle pour comprendre où il focalise ses prédictions."
  },
  "memory_ui": {
    "page_title": "Mémoire",
    "page_description": "Suis l'utilisation mémoire du système et ajuste les tailles de batch pour un entraînement efficace."
  },
  "environment": {
    "venv_creating": "Création de l'environnement virtuel Python à {path}...",
    "venv_created": "Environnement virtuel prêt.",
    "venv_create_failed": "Échec de la création de l'environnement virtuel : {error}",
    "venv_exists": "Un environnement virtuel est déjà présent.",
    "pip_upgrading": "Mise à niveau de pip dans l'environnement virtuel...",
    "pip_upgraded": "Mise à niveau de pip terminée.",
    "pip_upgrade_failed": "Échec de la mise à niveau de pip : {error}",
    "cuda_debug_nvcc": "Sortie de nvcc --version :\n{output}",
    "cuda_debug_nvcc_error": "Impossible d'interroger nvcc : {error}",
    "cuda_debug_nvidia_smi": "Sortie de nvidia-smi :\n{output}",
    "cuda_debug_nvidia_smi_error": "Impossible d'interroger nvidia-smi : {error}",
    "cuda_debug_detected": "Version CUDA détectée : {version}",
    "pytorch_install": "Installation de PyTorch pour CUDA {cuda} sur {platform}...",
    "pytorch_installed": "Installation de PyTorch terminée.",
    "pytorch_install_failed": "Échec de l'installation de PyTorch : {error}",
    "xformers_already_installed": "xFormers est déjà installé et à jour.",
    "xformers_installing": "Installation de xFormers (CUDA {cuda_version})...",
    "xformers_installed": "Installation de xFormers terminée.",
    "xformers_install_failed": "Échec de l'installation de xFormers : {error}",
    "pytorch_skip": "Installation de PyTorch ignorée (CUDA={cuda}, plateforme={platform} détectés).",
    "config_loading": "Chargement de la configuration d'environnement...",
    "config_loaded": "Configuration d'environnement chargée.",
    "using_compatible_xformers": "Utilisation de l'index CUDA {cuda_version} pour xFormers.",
    "env_packages_all_installed": "Les packages de l'environnement sont déjà installés.",
    "env_packages_progress_desc": "Installation des packages d'environnement",
    "env_package_installing": "Installation du package d'environnement {package}...",
    "env_package_installed": "Package d'environnement installé : {package}",
    "env_package_install_failed": "Échec de l'installation du package {package} : {error}",
    "env_vars_configured": "Préparation de {count} variable(s) d'environnement pour le processus d'entraînement.",
    "env_vars_config_failed": "Échec de la configuration des variables d'environnement : {error}",
    "entry_not_found": "Script d'entrée introuvable à {path}.",
    "venv_python_not_found": "Exécutable Python de l'environnement virtuel manquant : {path}.",
    "venv_python_test_failed": "Le Python de l'environnement virtuel a échoué au test --version : {error}",
    "re_exec_starting": "Lancement de l'entrée d'entraînement via {venv_python} -> {entry_py} (racine {root}).",
    "re_exec_timeout": "Ré-exécution expirée.",
    "re_exec_failed": "Échec du lancement du processus d'entraînement : {error}",
    "re_exec_unexpected_error": "Erreur inattendue lors du lancement du processus d'entraînement : {error}"
  },
  "updates_ui": {
    "page_title": "Mises à jour système",
    "page_description": "Garde ton installation alignée sur le dépôt amont sans écraser tes overrides spécifiques.",
    "card_title": "Gestionnaire de mises à jour",
    "intro": "Compare les fichiers locaux avec le dépôt de référence et synchronise les correctifs manquants sans toucher à config.json.",
    "check_button": "Cherche des mises à jour",
    "apply_button": "Applique les mises à jour",
    "apply_disabled_hint": "Lance une recherche pour activer la mise à jour.",
    "status_idle": "Aucun contrôle de mise à jour lancé pour l'instant.",
    "status_checking": "Recherche des mises à jour...",
    "status_ready": "Résumé des mises à jour prêt.",
    "status_up_to_date": "Tout est déjà à jour.",
    "status_failed": "La recherche de mises à jour a échoué.",
    "status_applying": "Mise à jour des fichiers...",
    "status_applied": "Mises à jour appliquées avec succès.",
    "status_apply_failed": "Certaines mises à jour ont échoué.",
    "table_header_file": "Fichier",
    "table_header_status": "Statut",
    "table_header_local": "Local",
    "table_header_remote": "Distant",
    "table_row_missing": "Manque localement",
    "table_row_outdated": "Checksum différent",
    "table_footnote": "Les hachages sont tronqués pour la lisibilité.",
    "no_updates": "Tous les fichiers suivis sont à jour.",
    "hash_missing": "—",
    "orphaned_title": "Fichiers locaux non suivis",
    "orphaned_none": "Aucun fichier local supplémentaire détecté."
  },
  "schema": {
    "description": "Schéma JSON pour config.json de Hootsight – définit types, plages et structure hiérarchique de tous les réglages configurables",
    "general_description": "Paramètres généraux de l'application",
    "general_language_description": "Code de langue de l'UI",
    "api_description": "Configuration du serveur API",
    "api_host_description": "Hôte du serveur API",
    "api_port_description": "Port du serveur API",
    "ui_description": "Paramètres de l'interface utilisateur",
    "ui_title_description": "Titre de la fenêtre",
    "ui_width_description": "Largeur de la fenêtre en pixels",
    "ui_height_description": "Hauteur de la fenêtre en pixels",
    "ui_resizable_description": "Si la fenêtre peut être redimensionnée",
    "system_description": "Paramètres système",
    "system_max_threads_description": "Nombre maximal de threads",
    "system_fallback_batch_size_description": "Taille de batch de secours quand le calcul auto échoue",
    "system_memory_cleanup_interval_description": "Intervalle de nettoyage mémoire en secondes",
    "system_thread_pool_timeout_description": "Expiration du pool de threads en secondes",
    "system_startup_wait_seconds_description": "Temps d'attente au démarrage en secondes",
    "memory_description": "Paramètres de gestion mémoire",
    "memory_target_memory_usage_description": "Ratio cible d'utilisation mémoire (0,0-1,0)",
    "memory_safety_margin_description": "Marge de sécurité pour les calculs mémoire (0,0-1,0)",
    "memory_augmentation_threads_description": "Nombre de threads pour l'augmentation",
    "training_description": "Configuration d'entraînement",
    "training_model_type_description": "Type de modèle",
    "training_model_name_description": "Nom spécifique du modèle",
    "training_pretrained_description": "Initialise le réseau avec des poids pré-entraînés ImageNet si disponibles ; désactive pour partir de zéro",
    "training_task_description": "Type de tâche de machine learning",
    "training_batch_size_description": "Taille de batch pour l'entraînement",
    "training_epochs_description": "Nombre d'époques",
    "training_learning_rate_description": "Taux d'apprentissage",
    "training_weight_decay_description": "Weight Decay (régularisation L2)",
    "training_input_size_description": "Longueur du bord en pixels pour le tenseur d'entrée carré (doit rester cohérente avec le redimensionnement de tes augmentations)",
    "training_normalize_description": "Paramètres de normalisation d'image",
    "training_normalize_mean_description": "Valeurs moyennes pour les canaux RGB",
    "training_normalize_std_description": "Écarts-types pour les canaux RGB",
    "training_val_ratio_description": "Ratio de validation (0,0-1,0)",
    "training_dataloader_description": "Configuration du DataLoader",
    "training_dataloader_num_workers_description": "Nombre de processus worker",
    "training_dataloader_pin_memory_description": "Pin mémoire pour accélérer le transfert GPU",
    "training_dataloader_persistent_workers_description": "Garder les workers actifs entre les époques",
    "training_dataloader_prefetch_factor_description": "Nombre de batchs préchargés par worker",
    "training_augmentation_description": "Configuration des augmentations",
    "training_augmentation_train_description": "Augmentations d'entraînement",
    "training_augmentation_val_description": "Augmentations de validation",
    "training_optimizer_type_description": "Type d'optimiseur",
    "training_optimizer_params_description": "Paramètres de l'optimiseur",
    "training_scheduler_type_description": "Type de scheduler de learning rate",
    "training_scheduler_params_description": "Paramètres du scheduler",
    "training_loss_type_description": "Type de fonction de perte",
    "training_loss_params_description": "Paramètres de la perte",
    "training_weight_init_description": "Configuration d'initialisation des poids",
    "training_checkpoint_description": "Configuration des checkpoints",
    "training_early_stopping_description": "Configuration de l'early stopping",
    "training_gradient_description": "Configuration du gradient",
    "training_runtime_description": "Réglages d'optimisation des performances runtime",
    "training_runtime_mixed_precision_description": "Active le mixed precision automatique",
    "training_runtime_channels_last_description": "Utilise le format mémoire channels-last pour mieux exploiter le GPU",
    "training_runtime_allow_tf32_description": "Active TF32 pour accélérer les opérations sur GPU Ampere+",
    "training_runtime_cudnn_benchmark_description": "Active le benchmark cuDNN pour choisir les convolutions optimales",
    "dataset_description": "Configuration du dataset",
    "dataset_image_extensions_description": "Extensions d'image supportées",
    "optimizers_description": "Override des valeurs par défaut des optimiseurs",
    "optimizers_defaults_description": "Paramètres par défaut des optimiseurs",
    "schedulers_description": "Override des valeurs par défaut des schedulers",
    "schedulers_defaults_description": "Paramètres par défaut des schedulers",
    "schedulers_defaults_lambda_lr_lr_lambda_description": "Fonction lambda en chaîne, par ex. 'lambda epoch: 0.95 ** epoch'",
    "schedulers_defaults_multiplicative_lr_lr_lambda_description": "Fonction lambda en chaîne, par ex. 'lambda epoch: 0.95'",
    "losses_description": "Override des pertes par défaut",
    "losses_defaults_description": "Paramètres par défaut des pertes",
    "models_description": "Configurations des modèles",
    "models_resnet_description": "Réglages de la famille ResNet",
    "models_resnet_variants_description": "Configuration des variantes ResNet",
    "models_resnext_description": "Réglages de la famille ResNeXt",
    "models_resnext_variants_description": "Configuration des variantes ResNeXt",
    "models_mobilenet_description": "Réglages de la famille MobileNet",
    "models_mobilenet_variants_description": "Configuration des variantes MobileNet",
    "models_shufflenet_description": "Réglages de la famille ShuffleNet",
    "models_shufflenet_variants_description": "Configuration des variantes ShuffleNet",
    "models_squeezenet_description": "Réglages de la famille SqueezeNet",
    "models_squeezenet_variants_description": "Configuration des variantes SqueezeNet",
    "models_efficientnet_description": "Réglages de la famille EfficientNet",
    "models_efficientnet_variants_description": "Configuration des variantes EfficientNet",
    "models_supported_types_description": "Types de modèles pris en charge",
    "general_language_enum_descriptor": {
      "en": "Langue anglaise – Contrôle toute la localisation : menus, erreurs, info-bulles et textes de validation. Affecte tous les textes de l'interface web et les réponses API. Détermine le chargement du pack linguistique au démarrage. Pour l'instant la seule option supportée, donc valeur par défaut."
    },
    "system_max_threads_enum_descriptor": {
      "auto": "Nombre de threads automatique – Calcule dynamiquement la taille optimale du pool selon les cœurs CPU (souvent cœurs - 1). Impacte le chargement des données en parallèle, le prétraitement, le batching d'inférence et les requêtes HTTP simultanées. Ajuste aussi l'utilisation mémoire."
    },
    "memory_augmentation_threads_enum_descriptor": {
      "auto": "Threads d'augmentation automatiques – Calcule le nombre optimal selon les cœurs CPU et la RAM. Accélère la transformation d'images (rotation, redimensionnement, jitter). Gère la mémoire tampon pour éviter la surcharge."
    },
    "training_model_type_enum_descriptor": {
      "resnet": "ResNet (Residual Network) – Réseau convolutif profond avec connexions de saut pour entraîner des modèles très profonds (18-152 couches). Influence le flux de gradient, la stabilité et la profondeur de représentation. Contrôle la complexité (11M à 60M de paramètres) et l'utilisation mémoire.",
      "resnext": "ResNeXt (Transformations résiduelles agrégées) – Évolution de ResNet utilisant la cardinalité (convolutions groupées). Augmente la capacité sans gonfler les paramètres. Impacte la diversité de features, la mémoire GPU et la durée d'entraînement tout en gagnant en précision.",
      "mobilenet": "MobileNet – CNN léger utilisant des convolutions separables en profondeur pour réduire taille et coût. Influence la latence d'inférence, la consommation et la compatibilité edge. Contrôle le compromis précision/efficacité via width multiplier et résolution.",
      "shufflenet": "ShuffleNet – CNN ultra efficace avec opérations de shuffle de canaux et convolutions en groupes. Optimisé pour appareils à faible puissance. Impacte l'utilisation de bande passante mémoire, la taille du modèle et la vitesse temps réel.",
      "squeezenet": "SqueezeNet – CNN ultra compact avec modules Fire (squeeze + expand) pour atteindre la précision d'AlexNet avec 50× moins de paramètres. Réduit drastiquement l'empreinte disque tout en gardant une précision correcte.",
      "efficientnet": "EfficientNet – CNN à mise à l'échelle composée qui équilibre profondeur, largeur et résolution par search automatique. Offre un compromis précision/efficacité exceptionnel tout en contrôlant la complexité modèle."
    },
    "training_task_enum_descriptor": {
      "classification": "Classification mono-label – Assigne exactement une classe par image via softmax et cross-entropy. Exige un dataset équilibré et des classes bien séparées.",
      "multi_label": "Classification multi-label – Assigne zéro ou plusieurs étiquettes via sigmoid par classe et BCE. Nécessite un seuil pour les prédictions positives et gère les corrélations de labels.",
      "detection": "Détection d'objets – Localise et classe plusieurs instances via boîtes englobantes. Demande une architecture complexe, des annotations précises et du post-traitement (NMS).",
      "segmentation": "Segmentation sémantique – Classe chaque pixel. Requiert beaucoup de mémoire, des architectures encodeur-décodeur et des pertes adaptées (cross-entropy pixel-wise, focal)."
    },
    "training_epochs_enum_descriptor": {
      "auto": "Détermination automatique des époques – Suit la perte/accuracy de validation pour couper l'entraînement via early stopping quand la progression stagne. Équilibre durée et overfitting."
    },
    "training_optimizer_type_enum_descriptor": {
      "sgd": "Stochastic Gradient Descent – Pas déterministe avec momentum optionnel et Nesterov. Idéal quand tu veux planifier un scheduler et garder la main sur la généralisation. Combine-le avec un scheduler cosinus ou step.",
      "adam": "Adam Optimizer – Méthode adaptative stockant la moyenne des gradients (beta1) et carrés (beta2). Parfait pour démarrer sur des tâches bruitées. Attention aux convergences molles si le weight decay est couplé.",
      "adamw": "AdamW Optimizer – Découple le weight decay pour une régularisation propre. Idéal pour fine-tuner ResNet, ViT ou modèles sensibles à la régularisation.",
      "adamax": "AdaMax Optimizer – Variante d'Adam utilisant la norme infinie pour le second moment. Plus robuste aux gradients explosifs.",
      "nadam": "Nadam – Ajoute le momentum de Nesterov pour resserrer la convergence. Prévois un coût calcul légèrement supérieur et un learning rate plus bas.",
      "radam": "Rectified Adam – Ajoute un warmup automatique basé sur la variance. Idéal quand les premières itérations sont délicates.",
      "rmsprop": "RMSprop – Maintient une moyenne exponentielle des gradients au carré pour normaliser les mises à jour. Très bon quand les gradients oscillent ou en RL.",
      "rprop": "Resilient Backpropagation – Optimiseur basé sur le signe, adapté aux mises à jour full-batch. À réserver aux petits datasets déterministes.",
      "adagrad": "Adagrad – Accumule les gradients au carré et réduit le learning rate des poids fréquemment mis à jour. Excellent pour features clairsemées.",
      "adadelta": "Adadelta – Corrige la décroissance d'Adagrad avec une fenêtre glissante. Peu de réglages, utile quand Adam est trop agressif.",
      "sparse_adam": "Sparse Adam – Version d'Adam pour embeddings clairsemés, n'update que les indices touchés. Indispensable en NLP, inutile pour CNN denses.",
      "lbfgs": "L-BFGS – Méthode quasi-Newton à mémoire limitée avec line search. Exige des gradients full-batch et une closure. Génial pour petits modèles à affiner.",
      "asgd": "ASGD – Moyenne les paramètres pour amortir les oscillations de SGD quand les gradients sont bruités. Gardes le learning rate constant ou décroissant lentement."
    },
    "training_scheduler_type_enum_descriptor": {
      "step_lr": "Step LR – Multiplie le learning rate par gamma toutes les step_size époques. Top quand tu connais les paliers (30/60/90).",
      "multi_step_lr": "Multi-Step LR – Généralise le step avec une liste de milestones. Utile pour reproduire les schedules publiés.",
      "exponential_lr": "Exponential LR – Applique lr_t = lr_0 * gamma^t pour une décroissance lisse. Choisis gamma entre 0.97 et 0.995.",
      "cosine_annealing_lr": "Cosine Annealing – Suit une courbe cosinus sur T_max époques, souvent meilleur pour la précision finale.",
      "cosine_annealing_warm_restarts": "Cosine avec redémarrages – Répète les cycles cosinus pour échapper aux minima peu profonds.",
      "reduce_lr_on_plateau": "Reduce on Plateau – Surveille une métrique (souvent val_loss) et baisse le LR quand ça stagne.",
      "cyclic_lr": "Cyclic LR – Fait osciller le LR entre base_lr et max_lr pour converger rapidement ou tester un range.",
      "one_cycle_lr": "One Cycle – Monte le LR jusqu'à max_lr puis redescend tout en inversant le momentum. Top quand tu connais le nombre total d'étapes.",
      "polynomial_lr": "Polynomial LR – Décroît vers zéro selon (1 - t/T)^power. Parfait pour segmentation/détection.",
      "linear_lr": "Linear LR – Interpole linéairement entre start_factor et end_factor. Idéal pour warmup ou cool-down.",
      "lambda_lr": "Lambda LR – Applique une fonction lambda(epoch) personnalisée. Liberté totale, mais teste-la bien.",
      "multiplicative_lr": "Multiplicative LR – Similaire à lambda mais table sur un callable renvoyant un multiplicateur par étape."
    },
    "training_loss_type_enum_descriptor": {
      "cross_entropy": "Cross-Entropy – Softmax + NLL. Classique pour mono-label. Accessible via options weight ou label_smoothing.",
      "nll_loss": "NLL Loss – Même math que cross-entropy mais tu fournis log_softmax toi-même.",
      "bce_loss": "BCE – Travaille sur probabilités [0,1], donc pense au sigmoid. Sensible aux underflows.",
      "bce_with_logits": "BCE with Logits – Version stable numériquement avec sigmoid interne. Gère pos_weight pour l'équilibrage.",
      "multi_margin": "Multi-Class Margin – Pousse la classe vraie au-dessus des autres avec une marge. Peut converger plus lentement.",
      "multi_label_margin": "Multi-Label Margin – Étend la marge au multi-label via un tri des indices positifs. Complexe à intégrer.",
      "multi_label_soft_margin": "Multi-Label Soft Margin – Formulation soft sur sigmoid. Gère mieux les labels qui se chevauchent.",
      "mse_loss": "MSE – Pénalisation L2 classique. Sensible aux outliers.",
      "l1_loss": "L1 (MAE) – Pénalité linéaire robuste aux outliers mais convergence plus lente proche de zéro.",
      "smooth_l1": "Smooth L1 – Style Huber avec zone quadratique. Standard pour la régression de boîtes.",
      "huber_loss": "Huber – Paramétré par delta, contrôle le point de bascule L2/L1. Idéal quand il y a quelques outliers.",
      "kl_div": "KL Divergence – Mesure la divergence entre distribution prédite et cible. Attention aux logarithmes.",
      "margin_ranking": "Margin Ranking – Travail sur paires (x1, x2) et ordonnancement. Besoin d'un sampling soigné.",
      "hinge_embedding": "Hinge Embedding – Pour apprentissage de similarité avec labels ±1. Pénalise les marges violées.",
      "triplet_margin": "Triplet Margin – Utilise anchor/positive/negative. Nécessite un mining efficace pour être utile.",
      "cosine_embedding": "Cosine Embedding – Optimise la similarité cosinus, adapté aux vecteurs normalisés.",
      "ctc_loss": "CTC – Aligne des séquences sans alignement frame. Exige des log-probas (T, N, C).",
      "poisson_nll": "Poisson NLL – Pour données de comptage non négatives. Gère log_input ou full logits.",
      "gaussian_nll": "Gaussian NLL – Entraîne mean + variance pour cibles continues. Idéal pour la régression avec incertitude."
    },
    "training_loss_reduction_enum_descriptor": {
      "mean": "Réduction moyenne – Moyenne la perte sur le batch pour garder des gradients stables et indépendants de la taille.",
      "sum": "Réduction somme – Additionne toutes les pertes sans normalisation. Nécessite d'ajuster le learning rate selon la taille du batch.",
      "none": "Sans réduction – Retourne la perte par échantillon pour pondération ou analyse personnalisée."
    },
    "training_early_stopping_monitor_enum_descriptor": {
      "val_loss": "Suivi de la perte de validation – Coupe l'entraînement quand la perte ne s'améliore plus après patience époques.",
      "val_accuracy": "Suivi de l'accuracy de validation – Coupe quand l'accuracy plafonne, utile pour tâches de classification équilibrées."
    },
    "optimizers_defaults_lbfgs_line_search_fn_oneOf[1]_enum_descriptor": {
      "strong_wolfe": "Recherche linéaire Strong Wolfe – Garantit les conditions de décroissance suffisante et de courbure pour L-BFGS. Assure des pas robustes sans sacrifier l'efficacité."
    },
    "schedulers_defaults_reduce_lr_on_plateau_mode_enum_descriptor": {
      "min": "Mode minimum – Surveille des métriques qui doivent diminuer (val_loss). Baisse le LR quand la perte n'arrive plus à descendre.",
      "max": "Mode maximum – Surveille des métriques qui doivent augmenter (val_accuracy). Réduit le LR quand l'accuracy stagne."
    },
    "schedulers_defaults_reduce_lr_on_plateau_threshold_mode_enum_descriptor": {
      "rel": "Seuil relatif – Définit l'amélioration en pourcentage de la meilleure valeur. De plus en plus strict quand le modèle s'améliore.",
      "abs": "Seuil absolu – Valeur fixe à dépasser, peu importe le niveau actuel. Maintient un standard constant."
    },
    "schedulers_defaults_cyclic_lr_mode_enum_descriptor": {
      "triangular": "Mode triangulaire – Crée des cycles linéaires entre base_lr et max_lr avec amplitude constante.",
      "triangular2": "Triangular2 – Même cycle mais amplitude divisée par deux après chaque cycle complet.",
      "exp_range": "Plage exponentielle – Module l'amplitude via gamma pour augmenter ou réduire le cycle dynamiquement."
    },
    "schedulers_defaults_cyclic_lr_scale_mode_enum_descriptor": {
      "cycle": "Scaling par cycle – Applique la fonction de scaling à la fin de chaque cycle complet.",
      "iterations": "Scaling par itérations – Applique le scaling à chaque itération pour une évolution continue."
    },
    "schedulers_defaults_one_cycle_lr_anneal_strategy_enum_descriptor": {
      "cos": "Stratégie cosinus – Transitions lisses avec accélérations/décélérations naturelles.",
      "linear": "Stratégie linéaire – Transitions à vitesse constante, simple et prévisible."
    },
    "losses_defaults_multi_margin_p_enum_descriptor": {
      "1": "Norme L1 (distance Manhattan) – Pénalisation linéaire moins sensible aux outliers.",
      "2": "Norme L2 (distance Euclidienne) – Pénalisation quadratique qui sanctionne fortement les grosses erreurs."
    },
    "losses_defaults_kl_div_reduction_enum_descriptor": {
      "none": "Sans réduction – Retourne la divergence KL par échantillon pour traitement custom.",
      "mean": "Moyenne – Moyenne la divergence sur tous les éléments (y compris dimensions spatiales).",
      "sum": "Somme – Additionne toutes les divergences, gradients plus grands pour gros batchs ou hautes résolutions.",
      "batchmean": "Moyenne par batch – Moyenne sur la dimension batch tout en conservant la contribution spatiale totale."
    },
    "models_resnet_default_optimizer_type_enum_descriptor": {
      "adamw": "AdamW pour ResNet – Découple le weight decay pour une régularisation efficace et stable.",
      "adam": "Adam pour ResNet – Méthode adaptative qui automatise le scaling des LR par paramètre.",
      "sgd": "SGD + momentum pour ResNet – Classique, nécessite un scheduler soigné pour de bons résultats."
    },
    "models_resnet_default_scheduler_type_enum_descriptor": {
      "step_lr": "Step LR pour ResNet – Décroissance par paliers aux époques clés.",
      "cosine_annealing_lr": "Cosine Annealing pour ResNet – Décroissance lisse qui améliore souvent la précision finale.",
      "reduce_lr_on_plateau": "Scheduling adaptatif pour ResNet – Baisse automatique du LR quand les progrès stagnent."
    },
    "paths_description": "Configuration des chemins",
    "paths_projects_dir_description": "Dossier contenant les projets",
    "paths_ui_dir_description": "Dossier contenant les assets UI",
    "paths_config_dir_description": "Dossier contenant les configurations",
    "paths_localizations_dir_description": "Dossier des fichiers de localisation",
    "paths_packages_file_description": "Chemin vers packages.jsonc",
    "paths_mappings_file_description": "Chemin vers le fichier de mappings",
    "paths_cache_dir_description": "Dossier pour le cache"
  },
  "status_graph": {
    "epoch_accuracy": "Précision par époque",
    "epoch_loss": "Perte par époque",
    "step_loss": "Perte par étape",
    "learning_rate": "Taux d'apprentissage",
    "loss": "Perte",
    "no_data": "En attente de mises à jour",
    "no_training": "Aucun entraînement actif.",
    "active_count": "Entraînements actifs : {count}",
    "label_training_id": "ID d'entraînement",
    "label_status": "Statut",
    "label_phase": "Phase",
    "label_epoch": "Époque",
    "label_step": "Étape",
    "badge_training": "Entraînement : {project}",
    "footer_training": "Entraînement {project} — Époque {epoch} • Étape {step}"
  },
  "updates": {
    "log": {
      "check_started": "Vérification des checksums amont...",
      "check_complete": "Contrôle terminé. Fichiers en attente : {count}",
      "check_failed": "Échec de la vérification : {error}",
      "remote_config_failed": "Impossible de télécharger config.json distant : {error}",
      "remote_checksum_failed": "Impossible de télécharger le manifeste de checksums distant : {error}",
      "remote_payload_invalid": "Le payload distant depuis {url} n'était pas un mapping.",
      "local_checksum_missing": "checksum.json local manquant ; manifeste supposé vide.",
      "local_checksum_invalid": "Impossible d'analyser checksum.json local : {error}",
      "path_escape": "Chemin dangereux bloqué {path}",
      "apply_started": "Application des mises à jour...",
      "apply_failed": "Échec de l'application : {error}",
      "apply_nothing": "Aucune mise à jour requise.",
      "apply_file_success": "Mis à jour {path}",
      "apply_file_failed": "Échec de la mise à jour {path} : {error}",
      "apply_partial": "{updated} mises à jour appliquées avec {failed} échecs.",
      "apply_complete": "{count} mises à jour appliquées."
    },
    "api": {
      "check_success": "Contrôle terminé. {count} fichier(s) en attente.",
      "check_no_updates": "Tout est déjà à jour.",
      "check_failed": "Contrôle échoué : {error}",
      "apply_success": "Mises à jour appliquées avec succès. {updated} fichier(s) mis à jour.",
      "apply_partial": "Mises à jour appliquées avec {updated} succès et {failed} échec(s).",
      "apply_failed": "Échec de l'application des mises à jour : {error}",
      "apply_nothing": "Aucune mise à jour nécessaire."
    },
    "status": {
      "missing": "Manque localement",
      "outdated": "Checksum différent"
    }
  },
  "status": {
    "project_load_failed": "Échec du chargement du projet",
    "project_loading": "Chargement du projet {projectName}...",
    "project_loaded_custom": "Projet {projectName} chargé avec config personnalisée",
    "project_loaded_defaults": "Projet {projectName} chargé avec les valeurs globales",
    "project_load_error": "Impossible de charger le projet {projectName} : {error}",
    "no_project_loaded": "Aucun projet chargé",
    "validation_errors": "Corrige les erreurs de validation avant d'enregistrer",
    "saving_training_config": "Enregistrement de la config d'entraînement...",
    "training_config_saved": "Config d'entraînement enregistrée",
    "save_failed": "Échec de l'enregistrement",
    "loading_schema": "Chargement du schéma et de la config...",
    "init_failed": "Initialisation ratée",
    "memory_load_failed": "Échec du chargement mémoire",
    "checking_updates": "Recherche des mises à jour...",
    "updates_ready": "Mises à jour disponibles",
    "updates_none": "Aucune mise à jour disponible",
    "updates_check_failed": "Échec de la recherche de mises à jour",
    "updates_applying": "Application des mises à jour...",
    "updates_applied": "Mises à jour appliquées",
    "updates_apply_failed": "Échec des mises à jour",
    "generating_heatmap": "Génération de la heatmap...",
    "heatmap_generated": "Heatmap générée",
    "heatmap_generation_failed": "Échec de la génération de la heatmap",
    "saving_system_settings": "Enregistrement des paramètres système...",
    "system_settings_saved": "Paramètres système enregistrés",
    "starting_training": "Démarrage de l'entraînement...",
    "training_started": "Entraînement démarré",
    "training_stopping": "Arrêt de l'entraînement...",
    "training_stop_requested": "Arrêt demandé",
    "training_stop_failed": "Échec de l'arrêt",
    "training_start_failed": "Échec du démarrage",
    "switching_language": "Changement de langue...",
    "language_switched": "Langue changée",
    "language_switch_failed": "Échec du changement de langue",
    "augmentation_preview_ready": "Prévisualisation d'augmentation générée"
  }
}
